{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   object \n",
      "dtypes: float64(11), object(1)\n",
      "memory usage: 150.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wine.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol  \n",
       "count  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983  \n",
       "std       0.154386     0.169507     1.065668  \n",
       "min       2.740000     0.330000     8.400000  \n",
       "25%       3.210000     0.550000     9.500000  \n",
       "50%       3.310000     0.620000    10.200000  \n",
       "75%       3.400000     0.730000    11.100000  \n",
       "max       4.010000     2.000000    14.900000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='quality', ylabel='Count'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df, x=\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "1    0.534709\n",
       "0    0.465291\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'] = df['quality'].map({\"bad\":0,\"good\":1})\n",
    "df['quality'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(df.drop('quality', axis=1).to_numpy()).to(torch.float32)\n",
    "y = torch.from_numpy(df['quality'].to_numpy()).to(torch.float32)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([1279, 11]), valid: 320\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {X_train.shape}, valid: {X_valid.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.,  ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=X_train.shape[0]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_dataset = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(11,64)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(64, 32)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(32, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "\n",
    "        return x.squeeze()\n",
    "\n",
    "mymodel = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (linear1): Linear(in_features=11, out_features=64, bias=True)\n",
      "  (activation1): ReLU()\n",
      "  (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (activation2): ReLU()\n",
      "  (linear3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Linear Layer 2 params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0504,  0.1183,  0.1000,  ..., -0.0721,  0.0233,  0.0723],\n",
      "        [ 0.1151, -0.0083, -0.1086,  ...,  0.0338,  0.1017, -0.0401],\n",
      "        [ 0.0123, -0.0888,  0.0281,  ..., -0.0214, -0.0678,  0.1020],\n",
      "        ...,\n",
      "        [-0.0692, -0.0308, -0.0023,  ...,  0.0953,  0.0553,  0.0252],\n",
      "        [-0.0767, -0.0482, -0.0612,  ..., -0.0657, -0.1170,  0.0529],\n",
      "        [ 0.0341, -0.0964,  0.0221,  ...,  0.0353, -0.0995,  0.1034]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0992, -0.0535,  0.0528, -0.0542, -0.0768, -0.0628,  0.0263, -0.0018,\n",
      "        -0.0015,  0.0080, -0.0367, -0.0471, -0.0436,  0.0236,  0.0953,  0.0974,\n",
      "        -0.1007, -0.0762, -0.0253,  0.1164, -0.0547,  0.0129, -0.1061,  0.0269,\n",
      "        -0.0647,  0.0334,  0.0818,  0.0827, -0.0120,  0.0035,  0.0520,  0.1186],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nLinear Layer 2 params:')\n",
    "for param in mymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, the nn.Linear module's weights are initialized by default using a method \"He initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss = 0.6786924004554749, valid_loss= 1.6285927295684814, accuracy= 49.6875\n",
      "Epoch 1: train_loss = 1.7433173656463623, valid_loss= 4.869925022125244, accuracy= 50.31250000000001\n",
      "Epoch 2: train_loss = 4.55788516998291, valid_loss= 0.7162349820137024, accuracy= 45.9375\n",
      "Epoch 3: train_loss = 0.7090427875518799, valid_loss= 0.6966702342033386, accuracy= 45.0\n",
      "Epoch 4: train_loss = 0.6939703226089478, valid_loss= 0.6945050954818726, accuracy= 51.87500000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss = 0.6923202872276306, valid_loss= 0.693674623966217, accuracy= 51.5625\n",
      "Epoch 6: train_loss = 0.6913658976554871, valid_loss= 0.6931574940681458, accuracy= 51.24999999999999\n",
      "Epoch 7: train_loss = 0.6903111338615417, valid_loss= 0.6920751333236694, accuracy= 51.87500000000001\n",
      "Epoch 8: train_loss = 0.6890570521354675, valid_loss= 0.6908861994743347, accuracy= 52.5\n",
      "Epoch 9: train_loss = 0.6874680519104004, valid_loss= 0.688896894454956, accuracy= 52.5\n",
      "Epoch 10: train_loss = 0.6855456233024597, valid_loss= 0.6870690584182739, accuracy= 52.1875\n",
      "Epoch 11: train_loss = 0.6833567023277283, valid_loss= 0.684404730796814, accuracy= 54.0625\n",
      "Epoch 12: train_loss = 0.6808629631996155, valid_loss= 0.6818569898605347, accuracy= 55.00000000000001\n",
      "Epoch 13: train_loss = 0.6781813502311707, valid_loss= 0.6789230108261108, accuracy= 55.93749999999999\n",
      "Epoch 14: train_loss = 0.6753289103507996, valid_loss= 0.6761124730110168, accuracy= 58.4375\n",
      "Epoch 15: train_loss = 0.6724833250045776, valid_loss= 0.6735697984695435, accuracy= 60.0\n",
      "Epoch 16: train_loss = 0.6696459650993347, valid_loss= 0.6709026098251343, accuracy= 59.68750000000001\n",
      "Epoch 17: train_loss = 0.666750967502594, valid_loss= 0.6688676476478577, accuracy= 62.5\n",
      "Epoch 18: train_loss = 0.6638555526733398, valid_loss= 0.666174054145813, accuracy= 63.125\n",
      "Epoch 19: train_loss = 0.6610051393508911, valid_loss= 0.6651862859725952, accuracy= 62.18749999999999\n",
      "Epoch 20: train_loss = 0.6582822203636169, valid_loss= 0.6619436144828796, accuracy= 62.81250000000001\n",
      "Epoch 21: train_loss = 0.6557560563087463, valid_loss= 0.6625016927719116, accuracy= 62.81250000000001\n",
      "Epoch 22: train_loss = 0.6534909605979919, valid_loss= 0.6579626798629761, accuracy= 62.5\n",
      "Epoch 23: train_loss = 0.6516760587692261, valid_loss= 0.6614922285079956, accuracy= 61.25000000000001\n",
      "Epoch 24: train_loss = 0.6500691175460815, valid_loss= 0.6547231078147888, accuracy= 62.81250000000001\n",
      "Epoch 25: train_loss = 0.6488245129585266, valid_loss= 0.660829484462738, accuracy= 62.18749999999999\n",
      "Epoch 26: train_loss = 0.6476960778236389, valid_loss= 0.65217125415802, accuracy= 62.5\n",
      "Epoch 27: train_loss = 0.6472711563110352, valid_loss= 0.6639288663864136, accuracy= 60.3125\n",
      "Epoch 28: train_loss = 0.6475147008895874, valid_loss= 0.6504732370376587, accuracy= 62.18749999999999\n",
      "Epoch 29: train_loss = 0.6496737003326416, valid_loss= 0.6686925292015076, accuracy= 60.0\n",
      "Epoch 30: train_loss = 0.6492605805397034, valid_loss= 0.650810718536377, accuracy= 62.5\n",
      "Epoch 31: train_loss = 0.6517820954322815, valid_loss= 0.6664942502975464, accuracy= 60.9375\n",
      "Epoch 32: train_loss = 0.6479107141494751, valid_loss= 0.6493427753448486, accuracy= 62.18749999999999\n",
      "Epoch 33: train_loss = 0.6474549174308777, valid_loss= 0.6604426503181458, accuracy= 61.875\n",
      "Epoch 34: train_loss = 0.6444568037986755, valid_loss= 0.6484342217445374, accuracy= 62.18749999999999\n",
      "Epoch 35: train_loss = 0.6439080834388733, valid_loss= 0.6570691466331482, accuracy= 61.5625\n",
      "Epoch 36: train_loss = 0.642336905002594, valid_loss= 0.6478643417358398, accuracy= 63.4375\n",
      "Epoch 37: train_loss = 0.6422708034515381, valid_loss= 0.6563555002212524, accuracy= 61.25000000000001\n",
      "Epoch 38: train_loss = 0.6414610743522644, valid_loss= 0.6473429799079895, accuracy= 63.74999999999999\n",
      "Epoch 39: train_loss = 0.641676664352417, valid_loss= 0.6566905379295349, accuracy= 61.5625\n",
      "Epoch 40: train_loss = 0.6412301063537598, valid_loss= 0.6467543840408325, accuracy= 62.5\n",
      "Epoch 41: train_loss = 0.6417911648750305, valid_loss= 0.6571682691574097, accuracy= 61.875\n",
      "Epoch 42: train_loss = 0.6412689685821533, valid_loss= 0.6465681195259094, accuracy= 63.125\n",
      "Epoch 43: train_loss = 0.6418448686599731, valid_loss= 0.6580773591995239, accuracy= 62.18749999999999\n",
      "Epoch 44: train_loss = 0.6415426135063171, valid_loss= 0.6464962959289551, accuracy= 63.4375\n",
      "Epoch 45: train_loss = 0.6423150897026062, valid_loss= 0.6596130728721619, accuracy= 62.5\n",
      "Epoch 46: train_loss = 0.6421754360198975, valid_loss= 0.646659255027771, accuracy= 63.125\n",
      "Epoch 47: train_loss = 0.6436542272567749, valid_loss= 0.6616035103797913, accuracy= 62.5\n",
      "Epoch 48: train_loss = 0.6431949138641357, valid_loss= 0.6469058990478516, accuracy= 63.125\n",
      "Epoch 49: train_loss = 0.6449341773986816, valid_loss= 0.6613221764564514, accuracy= 62.18749999999999\n",
      "Epoch 50: train_loss = 0.6431452631950378, valid_loss= 0.6464812159538269, accuracy= 63.125\n",
      "Epoch 51: train_loss = 0.6433563232421875, valid_loss= 0.6593328714370728, accuracy= 62.5\n",
      "Epoch 52: train_loss = 0.6420459747314453, valid_loss= 0.6461647152900696, accuracy= 63.4375\n",
      "Epoch 53: train_loss = 0.6419243216514587, valid_loss= 0.658227264881134, accuracy= 62.81250000000001\n",
      "Epoch 54: train_loss = 0.6413248777389526, valid_loss= 0.6458835601806641, accuracy= 63.4375\n",
      "Epoch 55: train_loss = 0.6412256956100464, valid_loss= 0.6575561165809631, accuracy= 62.81250000000001\n",
      "Epoch 56: train_loss = 0.6408529281616211, valid_loss= 0.6456701159477234, accuracy= 63.74999999999999\n",
      "Epoch 57: train_loss = 0.6410514116287231, valid_loss= 0.6573951840400696, accuracy= 62.81250000000001\n",
      "Epoch 58: train_loss = 0.6406587362289429, valid_loss= 0.6454830169677734, accuracy= 63.74999999999999\n",
      "Epoch 59: train_loss = 0.6410214900970459, valid_loss= 0.6572154760360718, accuracy= 62.5\n",
      "Epoch 60: train_loss = 0.6404639482498169, valid_loss= 0.6453245282173157, accuracy= 63.74999999999999\n",
      "Epoch 61: train_loss = 0.6407859325408936, valid_loss= 0.6569255590438843, accuracy= 62.5\n",
      "Epoch 62: train_loss = 0.6402277946472168, valid_loss= 0.6451839208602905, accuracy= 63.74999999999999\n",
      "Epoch 63: train_loss = 0.6406124234199524, valid_loss= 0.6569291949272156, accuracy= 62.5\n",
      "Epoch 64: train_loss = 0.6401047110557556, valid_loss= 0.6450203061103821, accuracy= 63.74999999999999\n",
      "Epoch 65: train_loss = 0.6403988003730774, valid_loss= 0.6570262312889099, accuracy= 62.5\n",
      "Epoch 66: train_loss = 0.6400063037872314, valid_loss= 0.6448553800582886, accuracy= 63.74999999999999\n",
      "Epoch 67: train_loss = 0.6403891444206238, valid_loss= 0.6579321026802063, accuracy= 62.81250000000001\n",
      "Epoch 68: train_loss = 0.6403188109397888, valid_loss= 0.6449182629585266, accuracy= 63.125\n",
      "Epoch 69: train_loss = 0.6414044499397278, valid_loss= 0.6596750020980835, accuracy= 62.81250000000001\n",
      "Epoch 70: train_loss = 0.6411232948303223, valid_loss= 0.6452275514602661, accuracy= 63.125\n",
      "Epoch 71: train_loss = 0.6428207159042358, valid_loss= 0.6616326570510864, accuracy= 62.81250000000001\n",
      "Epoch 72: train_loss = 0.6421672701835632, valid_loss= 0.6454724073410034, accuracy= 63.125\n",
      "Epoch 73: train_loss = 0.6436328291893005, valid_loss= 0.6592998504638672, accuracy= 63.125\n",
      "Epoch 74: train_loss = 0.6411092877388, valid_loss= 0.6448062062263489, accuracy= 63.4375\n",
      "Epoch 75: train_loss = 0.6409291625022888, valid_loss= 0.6580362915992737, accuracy= 62.81250000000001\n",
      "Epoch 76: train_loss = 0.6401962637901306, valid_loss= 0.6445335149765015, accuracy= 64.0625\n",
      "Epoch 77: train_loss = 0.6403043866157532, valid_loss= 0.656708300113678, accuracy= 62.81250000000001\n",
      "Epoch 78: train_loss = 0.6395013332366943, valid_loss= 0.6442946195602417, accuracy= 63.74999999999999\n",
      "Epoch 79: train_loss = 0.6395884156227112, valid_loss= 0.6559412479400635, accuracy= 62.81250000000001\n",
      "Epoch 80: train_loss = 0.6390435695648193, valid_loss= 0.6440855264663696, accuracy= 63.74999999999999\n",
      "Epoch 81: train_loss = 0.6392428874969482, valid_loss= 0.6560927033424377, accuracy= 62.81250000000001\n",
      "Epoch 82: train_loss = 0.6389699578285217, valid_loss= 0.6439262628555298, accuracy= 63.74999999999999\n",
      "Epoch 83: train_loss = 0.6392796635627747, valid_loss= 0.6567400097846985, accuracy= 62.5\n",
      "Epoch 84: train_loss = 0.6391626596450806, valid_loss= 0.6438786387443542, accuracy= 64.0625\n",
      "Epoch 85: train_loss = 0.6398913264274597, valid_loss= 0.658183217048645, accuracy= 63.125\n",
      "Epoch 86: train_loss = 0.6398082375526428, valid_loss= 0.6440848112106323, accuracy= 63.125\n",
      "Epoch 87: train_loss = 0.6410154104232788, valid_loss= 0.659447431564331, accuracy= 63.125\n",
      "Epoch 88: train_loss = 0.6404336094856262, valid_loss= 0.6442928314208984, accuracy= 62.81250000000001\n",
      "Epoch 89: train_loss = 0.6420642137527466, valid_loss= 0.6605819463729858, accuracy= 62.81250000000001\n",
      "Epoch 90: train_loss = 0.6410314440727234, valid_loss= 0.6441794633865356, accuracy= 62.81250000000001\n",
      "Epoch 91: train_loss = 0.6419404745101929, valid_loss= 0.6585812568664551, accuracy= 63.125\n",
      "Epoch 92: train_loss = 0.6400080919265747, valid_loss= 0.6436589956283569, accuracy= 63.4375\n",
      "Epoch 93: train_loss = 0.6399083733558655, valid_loss= 0.6566451191902161, accuracy= 63.125\n",
      "Epoch 94: train_loss = 0.6389119029045105, valid_loss= 0.6433448195457458, accuracy= 64.0625\n",
      "Epoch 95: train_loss = 0.6390224695205688, valid_loss= 0.6556941270828247, accuracy= 62.81250000000001\n",
      "Epoch 96: train_loss = 0.6383379101753235, valid_loss= 0.6430873870849609, accuracy= 64.0625\n",
      "Epoch 97: train_loss = 0.6384989619255066, valid_loss= 0.655545711517334, accuracy= 63.125\n",
      "Epoch 98: train_loss = 0.6381489634513855, valid_loss= 0.6428877711296082, accuracy= 64.0625\n",
      "Epoch 99: train_loss = 0.6384801268577576, valid_loss= 0.6560314893722534, accuracy= 63.125\n",
      "Epoch 100: train_loss = 0.6382759809494019, valid_loss= 0.6428634524345398, accuracy= 64.0625\n",
      "Epoch 101: train_loss = 0.6390705108642578, valid_loss= 0.657509982585907, accuracy= 63.125\n",
      "Epoch 102: train_loss = 0.6389369368553162, valid_loss= 0.6430951356887817, accuracy= 63.125\n",
      "Epoch 103: train_loss = 0.6401849389076233, valid_loss= 0.658943235874176, accuracy= 63.125\n",
      "Epoch 104: train_loss = 0.6396466493606567, valid_loss= 0.6433051824569702, accuracy= 62.81250000000001\n",
      "Epoch 105: train_loss = 0.6411802172660828, valid_loss= 0.6607353687286377, accuracy= 62.81250000000001\n",
      "Epoch 106: train_loss = 0.6405899524688721, valid_loss= 0.6437338590621948, accuracy= 63.125\n",
      "Epoch 107: train_loss = 0.6425004601478577, valid_loss= 0.6591652631759644, accuracy= 63.125\n",
      "Epoch 108: train_loss = 0.6398894190788269, valid_loss= 0.6428937315940857, accuracy= 63.4375\n",
      "Epoch 109: train_loss = 0.6396598219871521, valid_loss= 0.6575871109962463, accuracy= 63.125\n",
      "Epoch 110: train_loss = 0.6388311386108398, valid_loss= 0.6425789594650269, accuracy= 63.74999999999999\n",
      "Epoch 111: train_loss = 0.639033317565918, valid_loss= 0.6561778783798218, accuracy= 63.125\n",
      "Epoch 112: train_loss = 0.6380786299705505, valid_loss= 0.6422716379165649, accuracy= 64.0625\n",
      "Epoch 113: train_loss = 0.6382191181182861, valid_loss= 0.6551954746246338, accuracy= 63.125\n",
      "Epoch 114: train_loss = 0.6375111937522888, valid_loss= 0.6420115232467651, accuracy= 64.0625\n",
      "Epoch 115: train_loss = 0.6376729607582092, valid_loss= 0.6553245782852173, accuracy= 63.125\n",
      "Epoch 116: train_loss = 0.6374510526657104, valid_loss= 0.641886830329895, accuracy= 64.0625\n",
      "Epoch 117: train_loss = 0.6380226016044617, valid_loss= 0.6563840508460999, accuracy= 63.4375\n",
      "Epoch 118: train_loss = 0.6379070281982422, valid_loss= 0.6420812606811523, accuracy= 63.74999999999999\n",
      "Epoch 119: train_loss = 0.639056384563446, valid_loss= 0.6573945879936218, accuracy= 63.4375\n",
      "Epoch 120: train_loss = 0.6384159326553345, valid_loss= 0.6421322822570801, accuracy= 63.125\n",
      "Epoch 121: train_loss = 0.639369010925293, valid_loss= 0.6581458449363708, accuracy= 63.125\n",
      "Epoch 122: train_loss = 0.6387507319450378, valid_loss= 0.6422061324119568, accuracy= 63.125\n",
      "Epoch 123: train_loss = 0.6398186087608337, valid_loss= 0.659174382686615, accuracy= 63.125\n",
      "Epoch 124: train_loss = 0.6392618417739868, valid_loss= 0.6424763202667236, accuracy= 62.81250000000001\n",
      "Epoch 125: train_loss = 0.6409258246421814, valid_loss= 0.6604064106941223, accuracy= 62.81250000000001\n",
      "Epoch 126: train_loss = 0.6399305462837219, valid_loss= 0.6426945924758911, accuracy= 63.125\n",
      "Epoch 127: train_loss = 0.6415731906890869, valid_loss= 0.658441424369812, accuracy= 63.125\n",
      "Epoch 128: train_loss = 0.6389826536178589, valid_loss= 0.6418142914772034, accuracy= 63.4375\n",
      "Epoch 129: train_loss = 0.6386703252792358, valid_loss= 0.6557901501655579, accuracy= 63.4375\n",
      "Epoch 130: train_loss = 0.6374227404594421, valid_loss= 0.6413994431495667, accuracy= 64.0625\n",
      "Epoch 131: train_loss = 0.6374351382255554, valid_loss= 0.6542953252792358, accuracy= 63.125\n",
      "Epoch 132: train_loss = 0.6365734338760376, valid_loss= 0.6410893201828003, accuracy= 63.74999999999999\n",
      "Epoch 133: train_loss = 0.6366205215454102, valid_loss= 0.6544643044471741, accuracy= 63.125\n",
      "Epoch 134: train_loss = 0.6364855766296387, valid_loss= 0.6409262418746948, accuracy= 64.0625\n",
      "Epoch 135: train_loss = 0.6370000839233398, valid_loss= 0.6559798717498779, accuracy= 63.4375\n",
      "Epoch 136: train_loss = 0.6371524333953857, valid_loss= 0.6413941979408264, accuracy= 63.125\n",
      "Epoch 137: train_loss = 0.638969898223877, valid_loss= 0.6587148308753967, accuracy= 63.125\n",
      "Epoch 138: train_loss = 0.6386002898216248, valid_loss= 0.6419115662574768, accuracy= 62.81250000000001\n",
      "Epoch 139: train_loss = 0.6405689716339111, valid_loss= 0.6611840724945068, accuracy= 62.5\n",
      "Epoch 140: train_loss = 0.6399469375610352, valid_loss= 0.642689049243927, accuracy= 62.81250000000001\n",
      "Epoch 141: train_loss = 0.6424334645271301, valid_loss= 0.6587833762168884, accuracy= 63.125\n",
      "Epoch 142: train_loss = 0.6388706564903259, valid_loss= 0.6412346959114075, accuracy= 63.125\n",
      "Epoch 143: train_loss = 0.6381030678749084, valid_loss= 0.6560090780258179, accuracy= 63.74999999999999\n",
      "Epoch 144: train_loss = 0.6370853185653687, valid_loss= 0.640807032585144, accuracy= 63.4375\n",
      "Epoch 145: train_loss = 0.6371856331825256, valid_loss= 0.6547357439994812, accuracy= 63.125\n",
      "Epoch 146: train_loss = 0.6363428235054016, valid_loss= 0.640474796295166, accuracy= 64.0625\n",
      "Epoch 147: train_loss = 0.6364643573760986, valid_loss= 0.6543492078781128, accuracy= 63.125\n",
      "Epoch 148: train_loss = 0.6360268592834473, valid_loss= 0.640304684638977, accuracy= 64.0625\n",
      "Epoch 149: train_loss = 0.6364452838897705, valid_loss= 0.6552076935768127, accuracy= 63.74999999999999\n",
      "Epoch 150: train_loss = 0.6363246440887451, valid_loss= 0.6404968500137329, accuracy= 63.4375\n",
      "Epoch 151: train_loss = 0.637520968914032, valid_loss= 0.6574060320854187, accuracy= 63.125\n",
      "Epoch 152: train_loss = 0.6374403834342957, valid_loss= 0.6410572528839111, accuracy= 62.81250000000001\n",
      "Epoch 153: train_loss = 0.6393648386001587, valid_loss= 0.6605928540229797, accuracy= 62.5\n",
      "Epoch 154: train_loss = 0.6391971707344055, valid_loss= 0.642249584197998, accuracy= 62.5\n",
      "Epoch 155: train_loss = 0.6423141956329346, valid_loss= 0.6600755453109741, accuracy= 62.81250000000001\n",
      "Epoch 156: train_loss = 0.639124870300293, valid_loss= 0.6409699320793152, accuracy= 62.81250000000001\n",
      "Epoch 157: train_loss = 0.6388381123542786, valid_loss= 0.6563370227813721, accuracy= 64.0625\n",
      "Epoch 158: train_loss = 0.636928141117096, valid_loss= 0.6402934789657593, accuracy= 63.4375\n",
      "Epoch 159: train_loss = 0.6368293762207031, valid_loss= 0.6542837023735046, accuracy= 63.125\n",
      "Epoch 160: train_loss = 0.6357218027114868, valid_loss= 0.6398671865463257, accuracy= 64.0625\n",
      "Epoch 161: train_loss = 0.6358032822608948, valid_loss= 0.6538169980049133, accuracy= 63.125\n",
      "Epoch 162: train_loss = 0.6353194713592529, valid_loss= 0.6397165060043335, accuracy= 64.0625\n",
      "Epoch 163: train_loss = 0.6358606219291687, valid_loss= 0.654691219329834, accuracy= 63.74999999999999\n",
      "Epoch 164: train_loss = 0.6356532573699951, valid_loss= 0.6397488117218018, accuracy= 63.4375\n",
      "Epoch 165: train_loss = 0.6365385055541992, valid_loss= 0.6565225124359131, accuracy= 63.125\n",
      "Epoch 166: train_loss = 0.6365352869033813, valid_loss= 0.64039546251297, accuracy= 62.81250000000001\n",
      "Epoch 167: train_loss = 0.6386757493019104, valid_loss= 0.6597076058387756, accuracy= 62.81250000000001\n",
      "Epoch 168: train_loss = 0.6383209824562073, valid_loss= 0.6414019465446472, accuracy= 62.81250000000001\n",
      "Epoch 169: train_loss = 0.6412200927734375, valid_loss= 0.6600633263587952, accuracy= 62.81250000000001\n",
      "Epoch 170: train_loss = 0.6386613845825195, valid_loss= 0.6405647993087769, accuracy= 63.125\n",
      "Epoch 171: train_loss = 0.638990581035614, valid_loss= 0.6569122672080994, accuracy= 63.4375\n",
      "Epoch 172: train_loss = 0.6368452310562134, valid_loss= 0.6398323774337769, accuracy= 63.4375\n",
      "Epoch 173: train_loss = 0.6369009613990784, valid_loss= 0.6557844877243042, accuracy= 64.0625\n",
      "Epoch 174: train_loss = 0.6360483765602112, valid_loss= 0.6395948529243469, accuracy= 63.4375\n",
      "Epoch 175: train_loss = 0.6366908550262451, valid_loss= 0.6554818153381348, accuracy= 64.0625\n",
      "Epoch 176: train_loss = 0.6358085870742798, valid_loss= 0.6394902467727661, accuracy= 63.4375\n",
      "Epoch 177: train_loss = 0.6366522312164307, valid_loss= 0.6562455892562866, accuracy= 63.125\n",
      "Epoch 178: train_loss = 0.6361198425292969, valid_loss= 0.6397554278373718, accuracy= 63.125\n",
      "Epoch 179: train_loss = 0.6376487016677856, valid_loss= 0.658250093460083, accuracy= 62.81250000000001\n",
      "Epoch 180: train_loss = 0.6371904015541077, valid_loss= 0.6402902007102966, accuracy= 63.4375\n",
      "Epoch 181: train_loss = 0.6392685770988464, valid_loss= 0.660598874092102, accuracy= 62.5\n",
      "Epoch 182: train_loss = 0.6385015249252319, valid_loss= 0.6410713195800781, accuracy= 63.4375\n",
      "Epoch 183: train_loss = 0.6410573124885559, valid_loss= 0.6593892574310303, accuracy= 62.81250000000001\n",
      "Epoch 184: train_loss = 0.6379573941230774, valid_loss= 0.6399588584899902, accuracy= 63.125\n",
      "Epoch 185: train_loss = 0.6383157968521118, valid_loss= 0.6558969616889954, accuracy= 64.0625\n",
      "Epoch 186: train_loss = 0.6359437108039856, valid_loss= 0.639090895652771, accuracy= 63.4375\n",
      "Epoch 187: train_loss = 0.6358385682106018, valid_loss= 0.6538175940513611, accuracy= 63.74999999999999\n",
      "Epoch 188: train_loss = 0.6346482038497925, valid_loss= 0.6386079788208008, accuracy= 64.0625\n",
      "Epoch 189: train_loss = 0.634728193283081, valid_loss= 0.653856098651886, accuracy= 63.74999999999999\n",
      "Epoch 190: train_loss = 0.6344591379165649, valid_loss= 0.6386265754699707, accuracy= 63.4375\n",
      "Epoch 191: train_loss = 0.6354866623878479, valid_loss= 0.6558972597122192, accuracy= 63.4375\n",
      "Epoch 192: train_loss = 0.6354594230651855, valid_loss= 0.6393173933029175, accuracy= 62.81250000000001\n",
      "Epoch 193: train_loss = 0.6377201080322266, valid_loss= 0.6592190861701965, accuracy= 62.81250000000001\n",
      "Epoch 194: train_loss = 0.6373649835586548, valid_loss= 0.6405576467514038, accuracy= 63.4375\n",
      "Epoch 195: train_loss = 0.6406586170196533, valid_loss= 0.65986567735672, accuracy= 62.81250000000001\n",
      "Epoch 196: train_loss = 0.6378684639930725, valid_loss= 0.6398866176605225, accuracy= 63.125\n",
      "Epoch 197: train_loss = 0.6389301419258118, valid_loss= 0.6563245058059692, accuracy= 63.74999999999999\n",
      "Epoch 198: train_loss = 0.635892391204834, valid_loss= 0.6385787725448608, accuracy= 63.4375\n",
      "Epoch 199: train_loss = 0.635299026966095, valid_loss= 0.6532993316650391, accuracy= 63.74999999999999\n",
      "Epoch 200: train_loss = 0.6340327262878418, valid_loss= 0.6380389928817749, accuracy= 64.0625\n",
      "Epoch 201: train_loss = 0.6340027451515198, valid_loss= 0.6533229351043701, accuracy= 63.74999999999999\n",
      "Epoch 202: train_loss = 0.6338085532188416, valid_loss= 0.6380520462989807, accuracy= 63.4375\n",
      "Epoch 203: train_loss = 0.6348627805709839, valid_loss= 0.655728816986084, accuracy= 63.4375\n",
      "Epoch 204: train_loss = 0.6349791288375854, valid_loss= 0.6389865875244141, accuracy= 63.125\n",
      "Epoch 205: train_loss = 0.6377097964286804, valid_loss= 0.6610532999038696, accuracy= 62.5\n",
      "Epoch 206: train_loss = 0.6380348205566406, valid_loss= 0.6412754058837891, accuracy= 61.875\n",
      "Epoch 207: train_loss = 0.6425144672393799, valid_loss= 0.6605768799781799, accuracy= 62.81250000000001\n",
      "Epoch 208: train_loss = 0.638099730014801, valid_loss= 0.6393013000488281, accuracy= 63.125\n",
      "Epoch 209: train_loss = 0.6380508542060852, valid_loss= 0.6550817489624023, accuracy= 63.74999999999999\n",
      "Epoch 210: train_loss = 0.6349054574966431, valid_loss= 0.6378650665283203, accuracy= 63.74999999999999\n",
      "Epoch 211: train_loss = 0.6341219544410706, valid_loss= 0.6525487899780273, accuracy= 63.74999999999999\n",
      "Epoch 212: train_loss = 0.6332201957702637, valid_loss= 0.6374222040176392, accuracy= 64.0625\n",
      "Epoch 213: train_loss = 0.6333266496658325, valid_loss= 0.6529701948165894, accuracy= 63.74999999999999\n",
      "Epoch 214: train_loss = 0.6332274675369263, valid_loss= 0.6376204490661621, accuracy= 63.4375\n",
      "Epoch 215: train_loss = 0.6347439885139465, valid_loss= 0.6564873456954956, accuracy= 63.125\n",
      "Epoch 216: train_loss = 0.6350439786911011, valid_loss= 0.6392681002616882, accuracy= 63.4375\n",
      "Epoch 217: train_loss = 0.6390720009803772, valid_loss= 0.6612566113471985, accuracy= 62.81250000000001\n",
      "Epoch 218: train_loss = 0.6379386782646179, valid_loss= 0.6406506896018982, accuracy= 61.875\n",
      "Epoch 219: train_loss = 0.6414939165115356, valid_loss= 0.6597980260848999, accuracy= 62.81250000000001\n",
      "Epoch 220: train_loss = 0.6373010277748108, valid_loss= 0.6387103199958801, accuracy= 63.125\n",
      "Epoch 221: train_loss = 0.6372825503349304, valid_loss= 0.6545271277427673, accuracy= 63.74999999999999\n",
      "Epoch 222: train_loss = 0.6342322826385498, valid_loss= 0.6372514963150024, accuracy= 63.74999999999999\n",
      "Epoch 223: train_loss = 0.6332089900970459, valid_loss= 0.6527392268180847, accuracy= 63.74999999999999\n",
      "Epoch 224: train_loss = 0.6328895092010498, valid_loss= 0.6371253132820129, accuracy= 63.74999999999999\n",
      "Epoch 225: train_loss = 0.6338675022125244, valid_loss= 0.6553415656089783, accuracy= 63.4375\n",
      "Epoch 226: train_loss = 0.6341201066970825, valid_loss= 0.6382190585136414, accuracy= 63.4375\n",
      "Epoch 227: train_loss = 0.6371644139289856, valid_loss= 0.660445511341095, accuracy= 62.81250000000001\n",
      "Epoch 228: train_loss = 0.6370959877967834, valid_loss= 0.6403465867042542, accuracy= 61.875\n",
      "Epoch 229: train_loss = 0.6414802670478821, valid_loss= 0.6601387858390808, accuracy= 62.81250000000001\n",
      "Epoch 230: train_loss = 0.6372443437576294, valid_loss= 0.6386841535568237, accuracy= 63.4375\n",
      "Epoch 231: train_loss = 0.6377708315849304, valid_loss= 0.654837965965271, accuracy= 63.4375\n",
      "Epoch 232: train_loss = 0.6341687440872192, valid_loss= 0.6369055509567261, accuracy= 63.74999999999999\n",
      "Epoch 233: train_loss = 0.6330249309539795, valid_loss= 0.652569591999054, accuracy= 63.74999999999999\n",
      "Epoch 234: train_loss = 0.6325356364250183, valid_loss= 0.6367071866989136, accuracy= 63.74999999999999\n",
      "Epoch 235: train_loss = 0.6333580613136292, valid_loss= 0.6545490622520447, accuracy= 63.74999999999999\n",
      "Epoch 236: train_loss = 0.6334128379821777, valid_loss= 0.6375593543052673, accuracy= 62.81250000000001\n",
      "Epoch 237: train_loss = 0.6360852122306824, valid_loss= 0.66023850440979, accuracy= 62.81250000000001\n",
      "Epoch 238: train_loss = 0.636660099029541, valid_loss= 0.6407541036605835, accuracy= 62.5\n",
      "Epoch 239: train_loss = 0.6425014138221741, valid_loss= 0.6615626811981201, accuracy= 62.81250000000001\n",
      "Epoch 240: train_loss = 0.637861430644989, valid_loss= 0.6391719579696655, accuracy= 62.5\n",
      "Epoch 241: train_loss = 0.6390060782432556, valid_loss= 0.6553219556808472, accuracy= 63.4375\n",
      "Epoch 242: train_loss = 0.6342520713806152, valid_loss= 0.6366968750953674, accuracy= 63.74999999999999\n",
      "Epoch 243: train_loss = 0.6329198479652405, valid_loss= 0.6512507200241089, accuracy= 63.74999999999999\n",
      "Epoch 244: train_loss = 0.631683349609375, valid_loss= 0.6361689567565918, accuracy= 63.74999999999999\n",
      "Epoch 245: train_loss = 0.631798505783081, valid_loss= 0.6507319808006287, accuracy= 63.4375\n",
      "Epoch 246: train_loss = 0.6312064528465271, valid_loss= 0.6359856128692627, accuracy= 63.74999999999999\n",
      "Epoch 247: train_loss = 0.6319988369941711, valid_loss= 0.6519635915756226, accuracy= 63.74999999999999\n",
      "Epoch 248: train_loss = 0.6316974759101868, valid_loss= 0.6362925171852112, accuracy= 63.74999999999999\n",
      "Epoch 249: train_loss = 0.6333942413330078, valid_loss= 0.656540036201477, accuracy= 63.125\n",
      "Epoch 250: train_loss = 0.6340950727462769, valid_loss= 0.6383594870567322, accuracy= 63.4375\n",
      "Epoch 251: train_loss = 0.6386001706123352, valid_loss= 0.6622739434242249, accuracy= 62.5\n",
      "Epoch 252: train_loss = 0.637689471244812, valid_loss= 0.6405616998672485, accuracy= 62.81250000000001\n",
      "Epoch 253: train_loss = 0.6422504186630249, valid_loss= 0.6598821878433228, accuracy= 62.81250000000001\n",
      "Epoch 254: train_loss = 0.6365963816642761, valid_loss= 0.6376474499702454, accuracy= 63.4375\n",
      "Epoch 255: train_loss = 0.6362939476966858, valid_loss= 0.6535066366195679, accuracy= 63.74999999999999\n",
      "Epoch 256: train_loss = 0.6327555775642395, valid_loss= 0.6358653903007507, accuracy= 63.4375\n",
      "Epoch 257: train_loss = 0.6316108703613281, valid_loss= 0.6517173051834106, accuracy= 63.74999999999999\n",
      "Epoch 258: train_loss = 0.6313458681106567, valid_loss= 0.6357213258743286, accuracy= 63.74999999999999\n",
      "Epoch 259: train_loss = 0.6323135495185852, valid_loss= 0.6542203426361084, accuracy= 63.74999999999999\n",
      "Epoch 260: train_loss = 0.6325232982635498, valid_loss= 0.6368869543075562, accuracy= 63.4375\n",
      "Epoch 261: train_loss = 0.6357676982879639, valid_loss= 0.6608747243881226, accuracy= 62.81250000000001\n",
      "Epoch 262: train_loss = 0.636384904384613, valid_loss= 0.6404920816421509, accuracy= 63.125\n",
      "Epoch 263: train_loss = 0.6425203084945679, valid_loss= 0.6616783142089844, accuracy= 62.81250000000001\n",
      "Epoch 264: train_loss = 0.6373159289360046, valid_loss= 0.6386548280715942, accuracy= 62.5\n",
      "Epoch 265: train_loss = 0.6386102437973022, valid_loss= 0.6553081274032593, accuracy= 63.74999999999999\n",
      "Epoch 266: train_loss = 0.6335324048995972, valid_loss= 0.6359288096427917, accuracy= 63.74999999999999\n",
      "Epoch 267: train_loss = 0.6322487592697144, valid_loss= 0.6508687138557434, accuracy= 63.74999999999999\n",
      "Epoch 268: train_loss = 0.6307576894760132, valid_loss= 0.635273277759552, accuracy= 63.74999999999999\n",
      "Epoch 269: train_loss = 0.6306623220443726, valid_loss= 0.6501924991607666, accuracy= 63.4375\n",
      "Epoch 270: train_loss = 0.6301305890083313, valid_loss= 0.635133683681488, accuracy= 63.74999999999999\n",
      "Epoch 271: train_loss = 0.6310309767723083, valid_loss= 0.65177983045578, accuracy= 63.74999999999999\n",
      "Epoch 272: train_loss = 0.6308169364929199, valid_loss= 0.635694146156311, accuracy= 63.125\n",
      "Epoch 273: train_loss = 0.6331742405891418, valid_loss= 0.6579999327659607, accuracy= 62.81250000000001\n",
      "Epoch 274: train_loss = 0.6341888904571533, valid_loss= 0.6388083696365356, accuracy= 62.5\n",
      "Epoch 275: train_loss = 0.6399630308151245, valid_loss= 0.6621297001838684, accuracy= 62.81250000000001\n",
      "Epoch 276: train_loss = 0.6370011568069458, valid_loss= 0.6394215822219849, accuracy= 62.5\n",
      "Epoch 277: train_loss = 0.6403878331184387, valid_loss= 0.6581682562828064, accuracy= 63.125\n",
      "Epoch 278: train_loss = 0.6348152756690979, valid_loss= 0.6364623308181763, accuracy= 63.125\n",
      "Epoch 279: train_loss = 0.6343832015991211, valid_loss= 0.6516919732093811, accuracy= 63.4375\n",
      "Epoch 280: train_loss = 0.6310126781463623, valid_loss= 0.6348903179168701, accuracy= 63.4375\n",
      "Epoch 281: train_loss = 0.6297599077224731, valid_loss= 0.6496143341064453, accuracy= 63.4375\n",
      "Epoch 282: train_loss = 0.629482090473175, valid_loss= 0.6346246004104614, accuracy= 63.74999999999999\n",
      "Epoch 283: train_loss = 0.6302339434623718, valid_loss= 0.6509914994239807, accuracy= 63.74999999999999\n",
      "Epoch 284: train_loss = 0.6299739480018616, valid_loss= 0.6350041031837463, accuracy= 63.125\n",
      "Epoch 285: train_loss = 0.6321718692779541, valid_loss= 0.6569985747337341, accuracy= 63.125\n",
      "Epoch 286: train_loss = 0.6331730484962463, valid_loss= 0.6383925080299377, accuracy= 62.5\n",
      "Epoch 287: train_loss = 0.6396068930625916, valid_loss= 0.6620250940322876, accuracy= 62.5\n",
      "Epoch 288: train_loss = 0.6366000771522522, valid_loss= 0.6392244100570679, accuracy= 62.5\n",
      "Epoch 289: train_loss = 0.6403095722198486, valid_loss= 0.6588780283927917, accuracy= 63.125\n",
      "Epoch 290: train_loss = 0.6348662376403809, valid_loss= 0.6365306377410889, accuracy= 63.4375\n",
      "Epoch 291: train_loss = 0.6349655985832214, valid_loss= 0.6529802083969116, accuracy= 63.74999999999999\n",
      "Epoch 292: train_loss = 0.6312905550003052, valid_loss= 0.634704053401947, accuracy= 63.74999999999999\n",
      "Epoch 293: train_loss = 0.6304237246513367, valid_loss= 0.6518175005912781, accuracy= 63.74999999999999\n",
      "Epoch 294: train_loss = 0.6302347183227539, valid_loss= 0.6347934007644653, accuracy= 62.81250000000001\n",
      "Epoch 295: train_loss = 0.6317034363746643, valid_loss= 0.6551483869552612, accuracy= 63.125\n",
      "Epoch 296: train_loss = 0.6319040656089783, valid_loss= 0.6362348794937134, accuracy= 63.125\n",
      "Epoch 297: train_loss = 0.6357002258300781, valid_loss= 0.6602504253387451, accuracy= 62.5\n",
      "Epoch 298: train_loss = 0.6349853277206421, valid_loss= 0.6393254399299622, accuracy= 63.125\n",
      "Epoch 299: train_loss = 0.641071617603302, valid_loss= 0.6607488393783569, accuracy= 62.81250000000001\n",
      "Epoch 300: train_loss = 0.6356549263000488, valid_loss= 0.6375402212142944, accuracy= 62.81250000000001\n",
      "Epoch 301: train_loss = 0.6371715664863586, valid_loss= 0.6544727683067322, accuracy= 63.4375\n",
      "Epoch 302: train_loss = 0.6319729089736938, valid_loss= 0.6348282098770142, accuracy= 62.81250000000001\n",
      "Epoch 303: train_loss = 0.6310591697692871, valid_loss= 0.6511510610580444, accuracy= 63.74999999999999\n",
      "Epoch 304: train_loss = 0.6297674179077148, valid_loss= 0.6343421936035156, accuracy= 62.81250000000001\n",
      "Epoch 305: train_loss = 0.6302748322486877, valid_loss= 0.651709794998169, accuracy= 63.74999999999999\n",
      "Epoch 306: train_loss = 0.6298216581344604, valid_loss= 0.634560227394104, accuracy= 63.125\n",
      "Epoch 307: train_loss = 0.631634533405304, valid_loss= 0.655228316783905, accuracy= 63.125\n",
      "Epoch 308: train_loss = 0.6316443681716919, valid_loss= 0.6357718706130981, accuracy= 63.125\n",
      "Epoch 309: train_loss = 0.6348580121994019, valid_loss= 0.6604253053665161, accuracy= 62.5\n",
      "Epoch 310: train_loss = 0.6347262263298035, valid_loss= 0.6386963725090027, accuracy= 63.4375\n",
      "Epoch 311: train_loss = 0.6401811838150024, valid_loss= 0.6593149304389954, accuracy= 63.125\n",
      "Epoch 312: train_loss = 0.6344591379165649, valid_loss= 0.6366106271743774, accuracy= 63.125\n",
      "Epoch 313: train_loss = 0.635640561580658, valid_loss= 0.6526909470558167, accuracy= 63.4375\n",
      "Epoch 314: train_loss = 0.6305177211761475, valid_loss= 0.6342884302139282, accuracy= 63.125\n",
      "Epoch 315: train_loss = 0.629860520362854, valid_loss= 0.6505502462387085, accuracy= 63.74999999999999\n",
      "Epoch 316: train_loss = 0.6289551854133606, valid_loss= 0.6339864730834961, accuracy= 62.81250000000001\n",
      "Epoch 317: train_loss = 0.6298328042030334, valid_loss= 0.6517680883407593, accuracy= 63.4375\n",
      "Epoch 318: train_loss = 0.6294142603874207, valid_loss= 0.6343652009963989, accuracy= 63.74999999999999\n",
      "Epoch 319: train_loss = 0.6316097378730774, valid_loss= 0.6559404134750366, accuracy= 63.125\n",
      "Epoch 320: train_loss = 0.6316633820533752, valid_loss= 0.6362887620925903, accuracy= 63.125\n",
      "Epoch 321: train_loss = 0.6360582113265991, valid_loss= 0.6575599908828735, accuracy= 63.125\n",
      "Epoch 322: train_loss = 0.6328479051589966, valid_loss= 0.6362271904945374, accuracy= 63.4375\n",
      "Epoch 323: train_loss = 0.6355454921722412, valid_loss= 0.6556164026260376, accuracy= 63.125\n",
      "Epoch 324: train_loss = 0.6317440271377563, valid_loss= 0.6350791454315186, accuracy= 63.4375\n",
      "Epoch 325: train_loss = 0.6329864263534546, valid_loss= 0.6529813408851624, accuracy= 63.125\n",
      "Epoch 326: train_loss = 0.6300936341285706, valid_loss= 0.6341733336448669, accuracy= 63.4375\n",
      "Epoch 327: train_loss = 0.630775511264801, valid_loss= 0.65337073802948, accuracy= 63.125\n",
      "Epoch 328: train_loss = 0.6300727128982544, valid_loss= 0.6346481442451477, accuracy= 63.4375\n",
      "Epoch 329: train_loss = 0.6325074434280396, valid_loss= 0.656636655330658, accuracy= 63.125\n",
      "Epoch 330: train_loss = 0.631881058216095, valid_loss= 0.6361945867538452, accuracy= 63.125\n",
      "Epoch 331: train_loss = 0.635886013507843, valid_loss= 0.6570655107498169, accuracy= 63.125\n",
      "Epoch 332: train_loss = 0.6323202848434448, valid_loss= 0.6356700658798218, accuracy= 63.125\n",
      "Epoch 333: train_loss = 0.6345346570014954, valid_loss= 0.6548959612846375, accuracy= 63.125\n",
      "Epoch 334: train_loss = 0.6310433149337769, valid_loss= 0.6344395875930786, accuracy= 63.4375\n",
      "Epoch 335: train_loss = 0.6318214535713196, valid_loss= 0.6539296507835388, accuracy= 63.125\n",
      "Epoch 336: train_loss = 0.6302576661109924, valid_loss= 0.6344996690750122, accuracy= 63.4375\n",
      "Epoch 337: train_loss = 0.632302463054657, valid_loss= 0.6555086374282837, accuracy= 63.125\n",
      "Epoch 338: train_loss = 0.6310765147209167, valid_loss= 0.6350274085998535, accuracy= 62.81250000000001\n",
      "Epoch 339: train_loss = 0.6336844563484192, valid_loss= 0.6554102301597595, accuracy= 63.125\n",
      "Epoch 340: train_loss = 0.6310627460479736, valid_loss= 0.6348780393600464, accuracy= 62.81250000000001\n",
      "Epoch 341: train_loss = 0.6332417726516724, valid_loss= 0.6543685793876648, accuracy= 63.125\n",
      "Epoch 342: train_loss = 0.6304349899291992, valid_loss= 0.6342793703079224, accuracy= 63.125\n",
      "Epoch 343: train_loss = 0.631902813911438, valid_loss= 0.6543139219284058, accuracy= 63.125\n",
      "Epoch 344: train_loss = 0.630259096622467, valid_loss= 0.6344241499900818, accuracy= 63.125\n",
      "Epoch 345: train_loss = 0.6324875354766846, valid_loss= 0.6559423208236694, accuracy= 63.125\n",
      "Epoch 346: train_loss = 0.6311213374137878, valid_loss= 0.6350372433662415, accuracy= 63.125\n",
      "Epoch 347: train_loss = 0.6339391469955444, valid_loss= 0.6558132171630859, accuracy= 63.125\n",
      "Epoch 348: train_loss = 0.6311144232749939, valid_loss= 0.6346738934516907, accuracy= 62.81250000000001\n",
      "Epoch 349: train_loss = 0.63306725025177, valid_loss= 0.653814435005188, accuracy= 63.125\n",
      "Epoch 350: train_loss = 0.6299452185630798, valid_loss= 0.6337922811508179, accuracy= 63.74999999999999\n",
      "Epoch 351: train_loss = 0.6310737729072571, valid_loss= 0.6535531282424927, accuracy= 63.125\n",
      "Epoch 352: train_loss = 0.6296050548553467, valid_loss= 0.6338819861412048, accuracy= 63.4375\n",
      "Epoch 353: train_loss = 0.63160640001297, valid_loss= 0.6549389958381653, accuracy= 63.125\n",
      "Epoch 354: train_loss = 0.6303200125694275, valid_loss= 0.6345669627189636, accuracy= 63.125\n",
      "Epoch 355: train_loss = 0.6332889199256897, valid_loss= 0.6565707921981812, accuracy= 63.125\n",
      "Epoch 356: train_loss = 0.6312742829322815, valid_loss= 0.6351524591445923, accuracy= 63.125\n",
      "Epoch 357: train_loss = 0.6344050168991089, valid_loss= 0.6534220576286316, accuracy= 63.125\n",
      "Epoch 358: train_loss = 0.6295891404151917, valid_loss= 0.6333503127098083, accuracy= 63.74999999999999\n",
      "Epoch 359: train_loss = 0.6301820278167725, valid_loss= 0.6521444320678711, accuracy= 63.125\n",
      "Epoch 360: train_loss = 0.6286112666130066, valid_loss= 0.6331205368041992, accuracy= 63.74999999999999\n",
      "Epoch 361: train_loss = 0.6301208734512329, valid_loss= 0.652781069278717, accuracy= 63.125\n",
      "Epoch 362: train_loss = 0.6288027763366699, valid_loss= 0.63341224193573, accuracy= 63.125\n",
      "Epoch 363: train_loss = 0.6311005353927612, valid_loss= 0.6551581621170044, accuracy= 63.125\n",
      "Epoch 364: train_loss = 0.6301006078720093, valid_loss= 0.634671688079834, accuracy= 63.125\n",
      "Epoch 365: train_loss = 0.6340163350105286, valid_loss= 0.6572951078414917, accuracy= 62.81250000000001\n",
      "Epoch 366: train_loss = 0.6314414739608765, valid_loss= 0.6354079246520996, accuracy= 62.18749999999999\n",
      "Epoch 367: train_loss = 0.6352218389511108, valid_loss= 0.6536420583724976, accuracy= 63.125\n",
      "Epoch 368: train_loss = 0.629460871219635, valid_loss= 0.6329725980758667, accuracy= 63.4375\n",
      "Epoch 369: train_loss = 0.6297103762626648, valid_loss= 0.6508795022964478, accuracy= 63.74999999999999\n",
      "Epoch 370: train_loss = 0.6276423931121826, valid_loss= 0.6325278282165527, accuracy= 63.74999999999999\n",
      "Epoch 371: train_loss = 0.629051148891449, valid_loss= 0.6522955894470215, accuracy= 63.125\n",
      "Epoch 372: train_loss = 0.6282333135604858, valid_loss= 0.6333131790161133, accuracy= 62.81250000000001\n",
      "Epoch 373: train_loss = 0.631344199180603, valid_loss= 0.6557299494743347, accuracy= 63.125\n",
      "Epoch 374: train_loss = 0.6302375197410583, valid_loss= 0.6346225738525391, accuracy= 62.5\n",
      "Epoch 375: train_loss = 0.6342008709907532, valid_loss= 0.6582723259925842, accuracy= 62.5\n",
      "Epoch 376: train_loss = 0.6318356394767761, valid_loss= 0.6354169845581055, accuracy= 62.18749999999999\n",
      "Epoch 377: train_loss = 0.6354183554649353, valid_loss= 0.6527122855186462, accuracy= 63.125\n",
      "Epoch 378: train_loss = 0.6287627816200256, valid_loss= 0.632563591003418, accuracy= 63.4375\n",
      "Epoch 379: train_loss = 0.6289360523223877, valid_loss= 0.6493470072746277, accuracy= 64.0625\n",
      "Epoch 380: train_loss = 0.6265387535095215, valid_loss= 0.631820559501648, accuracy= 63.74999999999999\n",
      "Epoch 381: train_loss = 0.6275549530982971, valid_loss= 0.6488709449768066, accuracy= 64.0625\n",
      "Epoch 382: train_loss = 0.6260414719581604, valid_loss= 0.6318439841270447, accuracy= 63.74999999999999\n",
      "Epoch 383: train_loss = 0.6280535459518433, valid_loss= 0.650476336479187, accuracy= 63.125\n",
      "Epoch 384: train_loss = 0.6267991065979004, valid_loss= 0.6324104070663452, accuracy= 63.125\n",
      "Epoch 385: train_loss = 0.6297364830970764, valid_loss= 0.655231237411499, accuracy= 63.125\n",
      "Epoch 386: train_loss = 0.6294745802879333, valid_loss= 0.6346843838691711, accuracy= 62.5\n",
      "Epoch 387: train_loss = 0.6345655918121338, valid_loss= 0.6566993594169617, accuracy= 62.81250000000001\n",
      "Epoch 388: train_loss = 0.6305575966835022, valid_loss= 0.6345560550689697, accuracy= 61.875\n",
      "Epoch 389: train_loss = 0.633958637714386, valid_loss= 0.6527080535888672, accuracy= 63.125\n",
      "Epoch 390: train_loss = 0.6281979084014893, valid_loss= 0.6325713396072388, accuracy= 63.125\n",
      "Epoch 391: train_loss = 0.6295658946037292, valid_loss= 0.6520959138870239, accuracy= 63.125\n",
      "Epoch 392: train_loss = 0.6275574564933777, valid_loss= 0.6328070759773254, accuracy= 62.81250000000001\n",
      "Epoch 393: train_loss = 0.6304520964622498, valid_loss= 0.6548399925231934, accuracy= 63.125\n",
      "Epoch 394: train_loss = 0.6290420293807983, valid_loss= 0.6339442133903503, accuracy= 62.18749999999999\n",
      "Epoch 395: train_loss = 0.6329453587532043, valid_loss= 0.6541656255722046, accuracy= 63.4375\n",
      "Epoch 396: train_loss = 0.6286941170692444, valid_loss= 0.6331865787506104, accuracy= 63.125\n",
      "Epoch 397: train_loss = 0.6311977505683899, valid_loss= 0.6535718441009521, accuracy= 63.125\n",
      "Epoch 398: train_loss = 0.6282399892807007, valid_loss= 0.6330110430717468, accuracy= 63.125\n",
      "Epoch 399: train_loss = 0.6309049129486084, valid_loss= 0.6536959409713745, accuracy= 63.125\n",
      "Epoch 400: train_loss = 0.6282191872596741, valid_loss= 0.6330130100250244, accuracy= 63.125\n",
      "Epoch 401: train_loss = 0.6310005784034729, valid_loss= 0.6538945436477661, accuracy= 63.125\n",
      "Epoch 402: train_loss = 0.6282495260238647, valid_loss= 0.6332719922065735, accuracy= 62.18749999999999\n",
      "Epoch 403: train_loss = 0.6315354108810425, valid_loss= 0.6538557410240173, accuracy= 63.125\n",
      "Epoch 404: train_loss = 0.6281715631484985, valid_loss= 0.6330072283744812, accuracy= 63.125\n",
      "Epoch 405: train_loss = 0.6309452056884766, valid_loss= 0.653255820274353, accuracy= 63.125\n",
      "Epoch 406: train_loss = 0.6277235150337219, valid_loss= 0.6327714323997498, accuracy= 62.81250000000001\n",
      "Epoch 407: train_loss = 0.6305141448974609, valid_loss= 0.6534339189529419, accuracy= 63.125\n",
      "Epoch 408: train_loss = 0.6277267932891846, valid_loss= 0.6330525279045105, accuracy= 62.5\n",
      "Epoch 409: train_loss = 0.6311678290367126, valid_loss= 0.6540757417678833, accuracy= 63.125\n",
      "Epoch 410: train_loss = 0.6280502080917358, valid_loss= 0.6332694292068481, accuracy= 62.18749999999999\n",
      "Epoch 411: train_loss = 0.6315847635269165, valid_loss= 0.6522960066795349, accuracy= 63.125\n",
      "Epoch 412: train_loss = 0.6270182132720947, valid_loss= 0.6321307420730591, accuracy= 63.125\n",
      "Epoch 413: train_loss = 0.6289576292037964, valid_loss= 0.6513859629631042, accuracy= 63.125\n",
      "Epoch 414: train_loss = 0.6263115406036377, valid_loss= 0.6318631172180176, accuracy= 63.125\n",
      "Epoch 415: train_loss = 0.6286430954933167, valid_loss= 0.65195631980896, accuracy= 63.125\n",
      "Epoch 416: train_loss = 0.6264997720718384, valid_loss= 0.6323531866073608, accuracy= 62.81250000000001\n",
      "Epoch 417: train_loss = 0.6298872232437134, valid_loss= 0.6538833379745483, accuracy= 63.125\n",
      "Epoch 418: train_loss = 0.6275834441184998, valid_loss= 0.6334778070449829, accuracy= 61.875\n",
      "Epoch 419: train_loss = 0.6319787502288818, valid_loss= 0.6532663106918335, accuracy= 63.4375\n",
      "Epoch 420: train_loss = 0.6272933483123779, valid_loss= 0.6323754787445068, accuracy= 62.18749999999999\n",
      "Epoch 421: train_loss = 0.6296263933181763, valid_loss= 0.6516433954238892, accuracy= 63.125\n",
      "Epoch 422: train_loss = 0.6261906623840332, valid_loss= 0.6317304372787476, accuracy= 63.4375\n",
      "Epoch 423: train_loss = 0.6283331513404846, valid_loss= 0.6512705683708191, accuracy= 63.125\n",
      "Epoch 424: train_loss = 0.6257966160774231, valid_loss= 0.6317185759544373, accuracy= 62.81250000000001\n",
      "Epoch 425: train_loss = 0.6285769939422607, valid_loss= 0.6521309614181519, accuracy= 63.125\n",
      "Epoch 426: train_loss = 0.6261956095695496, valid_loss= 0.6324194669723511, accuracy= 62.18749999999999\n",
      "Epoch 427: train_loss = 0.630130410194397, valid_loss= 0.6541618704795837, accuracy= 63.125\n",
      "Epoch 428: train_loss = 0.6273813247680664, valid_loss= 0.6338227987289429, accuracy= 62.5\n",
      "Epoch 429: train_loss = 0.6324552893638611, valid_loss= 0.6545063257217407, accuracy= 63.125\n",
      "Epoch 430: train_loss = 0.6276493668556213, valid_loss= 0.63321852684021, accuracy= 61.5625\n",
      "Epoch 431: train_loss = 0.6310229301452637, valid_loss= 0.6520278453826904, accuracy= 63.125\n",
      "Epoch 432: train_loss = 0.6261167526245117, valid_loss= 0.631851077079773, accuracy= 62.5\n",
      "Epoch 433: train_loss = 0.6282936334609985, valid_loss= 0.6506057977676392, accuracy= 62.81250000000001\n",
      "Epoch 434: train_loss = 0.6251185536384583, valid_loss= 0.6313431859016418, accuracy= 63.4375\n",
      "Epoch 435: train_loss = 0.6274463534355164, valid_loss= 0.651111364364624, accuracy= 63.125\n",
      "Epoch 436: train_loss = 0.625220000743866, valid_loss= 0.6316702961921692, accuracy= 62.5\n",
      "Epoch 437: train_loss = 0.628451943397522, valid_loss= 0.6537070870399475, accuracy= 62.81250000000001\n",
      "Epoch 438: train_loss = 0.6266931295394897, valid_loss= 0.6335694789886475, accuracy= 62.18749999999999\n",
      "Epoch 439: train_loss = 0.6319953203201294, valid_loss= 0.6546082496643066, accuracy= 63.125\n",
      "Epoch 440: train_loss = 0.6273298263549805, valid_loss= 0.6335148811340332, accuracy= 62.18749999999999\n",
      "Epoch 441: train_loss = 0.6314607262611389, valid_loss= 0.6528733968734741, accuracy= 63.125\n",
      "Epoch 442: train_loss = 0.6262988448143005, valid_loss= 0.6320999264717102, accuracy= 61.5625\n",
      "Epoch 443: train_loss = 0.6287021636962891, valid_loss= 0.6504246592521667, accuracy= 62.81250000000001\n",
      "Epoch 444: train_loss = 0.6247087717056274, valid_loss= 0.6312869191169739, accuracy= 62.5\n",
      "Epoch 445: train_loss = 0.6273019909858704, valid_loss= 0.6503435969352722, accuracy= 62.81250000000001\n",
      "Epoch 446: train_loss = 0.6244915723800659, valid_loss= 0.631112277507782, accuracy= 62.5\n",
      "Epoch 447: train_loss = 0.627322256565094, valid_loss= 0.6524733901023865, accuracy= 63.125\n",
      "Epoch 448: train_loss = 0.6256005167961121, valid_loss= 0.6330481767654419, accuracy= 62.18749999999999\n",
      "Epoch 449: train_loss = 0.6310762166976929, valid_loss= 0.6549314260482788, accuracy= 62.81250000000001\n",
      "Epoch 450: train_loss = 0.627175509929657, valid_loss= 0.6339518427848816, accuracy= 62.5\n",
      "Epoch 451: train_loss = 0.6324399709701538, valid_loss= 0.6536852717399597, accuracy= 63.125\n",
      "Epoch 452: train_loss = 0.6265072226524353, valid_loss= 0.632338285446167, accuracy= 62.18749999999999\n",
      "Epoch 453: train_loss = 0.6291784644126892, valid_loss= 0.6512893438339233, accuracy= 62.81250000000001\n",
      "Epoch 454: train_loss = 0.6249510049819946, valid_loss= 0.6316114664077759, accuracy= 62.18749999999999\n",
      "Epoch 455: train_loss = 0.6279973387718201, valid_loss= 0.6508709192276001, accuracy= 62.81250000000001\n",
      "Epoch 456: train_loss = 0.6245283484458923, valid_loss= 0.631470799446106, accuracy= 62.18749999999999\n",
      "Epoch 457: train_loss = 0.6279513239860535, valid_loss= 0.6511980891227722, accuracy= 62.81250000000001\n",
      "Epoch 458: train_loss = 0.6246110200881958, valid_loss= 0.6316547393798828, accuracy= 62.18749999999999\n",
      "Epoch 459: train_loss = 0.6284531950950623, valid_loss= 0.6527632474899292, accuracy= 63.125\n",
      "Epoch 460: train_loss = 0.625427782535553, valid_loss= 0.6324642896652222, accuracy= 62.18749999999999\n",
      "Epoch 461: train_loss = 0.6300428509712219, valid_loss= 0.6544396281242371, accuracy= 62.81250000000001\n",
      "Epoch 462: train_loss = 0.6263841390609741, valid_loss= 0.6333582997322083, accuracy= 62.18749999999999\n",
      "Epoch 463: train_loss = 0.6315692067146301, valid_loss= 0.6529695391654968, accuracy= 63.125\n",
      "Epoch 464: train_loss = 0.6255257725715637, valid_loss= 0.6318339109420776, accuracy= 61.875\n",
      "Epoch 465: train_loss = 0.6284374594688416, valid_loss= 0.650753378868103, accuracy= 62.81250000000001\n",
      "Epoch 466: train_loss = 0.6241026520729065, valid_loss= 0.6306972503662109, accuracy= 63.125\n",
      "Epoch 467: train_loss = 0.6264515519142151, valid_loss= 0.649834930896759, accuracy= 62.81250000000001\n",
      "Epoch 468: train_loss = 0.6233741044998169, valid_loss= 0.6303802728652954, accuracy= 63.125\n",
      "Epoch 469: train_loss = 0.6262681484222412, valid_loss= 0.6499040722846985, accuracy= 62.81250000000001\n",
      "Epoch 470: train_loss = 0.6232973337173462, valid_loss= 0.6304544806480408, accuracy= 62.81250000000001\n",
      "Epoch 471: train_loss = 0.626600444316864, valid_loss= 0.651613712310791, accuracy= 62.81250000000001\n",
      "Epoch 472: train_loss = 0.624188244342804, valid_loss= 0.6320981979370117, accuracy= 62.5\n",
      "Epoch 473: train_loss = 0.6297616958618164, valid_loss= 0.6559237241744995, accuracy= 62.5\n",
      "Epoch 474: train_loss = 0.6268431544303894, valid_loss= 0.6346111297607422, accuracy= 63.125\n",
      "Epoch 475: train_loss = 0.6339535713195801, valid_loss= 0.6557955145835876, accuracy= 62.81250000000001\n",
      "Epoch 476: train_loss = 0.6269593834877014, valid_loss= 0.6331061124801636, accuracy= 62.18749999999999\n",
      "Epoch 477: train_loss = 0.630813717842102, valid_loss= 0.6499542593955994, accuracy= 62.81250000000001\n",
      "Epoch 478: train_loss = 0.6234890818595886, valid_loss= 0.6298105120658875, accuracy= 63.4375\n",
      "Epoch 479: train_loss = 0.6245294809341431, valid_loss= 0.6471864581108093, accuracy= 63.74999999999999\n",
      "Epoch 480: train_loss = 0.6215850114822388, valid_loss= 0.6289730072021484, accuracy= 64.0625\n",
      "Epoch 481: train_loss = 0.6235302686691284, valid_loss= 0.64881432056427, accuracy= 62.81250000000001\n",
      "Epoch 482: train_loss = 0.622225284576416, valid_loss= 0.6302926540374756, accuracy= 62.18749999999999\n",
      "Epoch 483: train_loss = 0.6266440749168396, valid_loss= 0.653799831867218, accuracy= 62.81250000000001\n",
      "Epoch 484: train_loss = 0.6251226663589478, valid_loss= 0.6335719227790833, accuracy= 63.125\n",
      "Epoch 485: train_loss = 0.6325870752334595, valid_loss= 0.6574364900588989, accuracy= 62.5\n",
      "Epoch 486: train_loss = 0.6275810599327087, valid_loss= 0.6348190903663635, accuracy= 63.4375\n",
      "Epoch 487: train_loss = 0.633954644203186, valid_loss= 0.6549683809280396, accuracy= 63.125\n",
      "Epoch 488: train_loss = 0.6261917948722839, valid_loss= 0.6319561004638672, accuracy= 62.18749999999999\n",
      "Epoch 489: train_loss = 0.6288112998008728, valid_loss= 0.6511102914810181, accuracy= 62.81250000000001\n",
      "Epoch 490: train_loss = 0.6236751079559326, valid_loss= 0.6305043697357178, accuracy= 62.18749999999999\n",
      "Epoch 491: train_loss = 0.6262601017951965, valid_loss= 0.6502171754837036, accuracy= 62.81250000000001\n",
      "Epoch 492: train_loss = 0.6228960752487183, valid_loss= 0.6304563879966736, accuracy= 61.875\n",
      "Epoch 493: train_loss = 0.6265689134597778, valid_loss= 0.6522660851478577, accuracy= 62.81250000000001\n",
      "Epoch 494: train_loss = 0.6239359378814697, valid_loss= 0.6316772103309631, accuracy= 62.5\n",
      "Epoch 495: train_loss = 0.6291795969009399, valid_loss= 0.6550232172012329, accuracy= 62.5\n",
      "Epoch 496: train_loss = 0.6255767345428467, valid_loss= 0.6332822442054749, accuracy= 63.125\n",
      "Epoch 497: train_loss = 0.6318255066871643, valid_loss= 0.6542288064956665, accuracy= 63.125\n",
      "Epoch 498: train_loss = 0.6252345442771912, valid_loss= 0.6313489079475403, accuracy= 62.5\n",
      "Epoch 499: train_loss = 0.6280307769775391, valid_loss= 0.6510441899299622, accuracy= 62.5\n",
      "Epoch 500: train_loss = 0.6231963634490967, valid_loss= 0.6301394701004028, accuracy= 61.875\n",
      "Epoch 501: train_loss = 0.625819742679596, valid_loss= 0.6497045755386353, accuracy= 62.81250000000001\n",
      "Epoch 502: train_loss = 0.6222573518753052, valid_loss= 0.6294819712638855, accuracy= 62.5\n",
      "Epoch 503: train_loss = 0.625041127204895, valid_loss= 0.649608314037323, accuracy= 62.81250000000001\n",
      "Epoch 504: train_loss = 0.6220719218254089, valid_loss= 0.6300570964813232, accuracy= 61.5625\n",
      "Epoch 505: train_loss = 0.6263456344604492, valid_loss= 0.6519005298614502, accuracy= 62.5\n",
      "Epoch 506: train_loss = 0.6233110427856445, valid_loss= 0.6313774585723877, accuracy= 62.81250000000001\n",
      "Epoch 507: train_loss = 0.6288653016090393, valid_loss= 0.6559128761291504, accuracy= 62.5\n",
      "Epoch 508: train_loss = 0.6257680058479309, valid_loss= 0.633949875831604, accuracy= 64.0625\n",
      "Epoch 509: train_loss = 0.6331840753555298, valid_loss= 0.6556617617607117, accuracy= 62.81250000000001\n",
      "Epoch 510: train_loss = 0.6258438229560852, valid_loss= 0.6323556900024414, accuracy= 62.5\n",
      "Epoch 511: train_loss = 0.629892110824585, valid_loss= 0.651213526725769, accuracy= 62.5\n",
      "Epoch 512: train_loss = 0.6230949759483337, valid_loss= 0.6297727227210999, accuracy= 62.18749999999999\n",
      "Epoch 513: train_loss = 0.6249290108680725, valid_loss= 0.6484048962593079, accuracy= 62.81250000000001\n",
      "Epoch 514: train_loss = 0.6211872100830078, valid_loss= 0.6287779808044434, accuracy= 63.4375\n",
      "Epoch 515: train_loss = 0.6236208081245422, valid_loss= 0.6497006416320801, accuracy= 62.5\n",
      "Epoch 516: train_loss = 0.6216886639595032, valid_loss= 0.6299606561660767, accuracy= 61.875\n",
      "Epoch 517: train_loss = 0.6263481378555298, valid_loss= 0.6534047722816467, accuracy= 62.81250000000001\n",
      "Epoch 518: train_loss = 0.6238461136817932, valid_loss= 0.6321401596069336, accuracy= 63.4375\n",
      "Epoch 519: train_loss = 0.6304244995117188, valid_loss= 0.656082272529602, accuracy= 62.5\n",
      "Epoch 520: train_loss = 0.6256088614463806, valid_loss= 0.6330070495605469, accuracy= 63.4375\n",
      "Epoch 521: train_loss = 0.6316113471984863, valid_loss= 0.654068112373352, accuracy= 62.81250000000001\n",
      "Epoch 522: train_loss = 0.6244564652442932, valid_loss= 0.6315827965736389, accuracy= 62.5\n",
      "Epoch 523: train_loss = 0.6286801695823669, valid_loss= 0.6513255834579468, accuracy= 62.5\n",
      "Epoch 524: train_loss = 0.6226585507392883, valid_loss= 0.6300198435783386, accuracy= 61.875\n",
      "Epoch 525: train_loss = 0.6258558034896851, valid_loss= 0.6502905488014221, accuracy= 62.5\n",
      "Epoch 526: train_loss = 0.6218574047088623, valid_loss= 0.6298543214797974, accuracy= 62.5\n",
      "Epoch 527: train_loss = 0.6258289217948914, valid_loss= 0.6512287259101868, accuracy= 62.5\n",
      "Epoch 528: train_loss = 0.6222939491271973, valid_loss= 0.6305992603302002, accuracy= 62.81250000000001\n",
      "Epoch 529: train_loss = 0.6274781227111816, valid_loss= 0.6537991762161255, accuracy= 63.125\n",
      "Epoch 530: train_loss = 0.6238526701927185, valid_loss= 0.6319018006324768, accuracy= 63.4375\n",
      "Epoch 531: train_loss = 0.6298439502716064, valid_loss= 0.654265284538269, accuracy= 62.81250000000001\n",
      "Epoch 532: train_loss = 0.6242315769195557, valid_loss= 0.6319060325622559, accuracy= 63.4375\n",
      "Epoch 533: train_loss = 0.629623293876648, valid_loss= 0.6523970365524292, accuracy= 62.81250000000001\n",
      "Epoch 534: train_loss = 0.6230872273445129, valid_loss= 0.6304399371147156, accuracy= 62.81250000000001\n",
      "Epoch 535: train_loss = 0.6267593502998352, valid_loss= 0.6505743265151978, accuracy= 62.5\n",
      "Epoch 536: train_loss = 0.6218482851982117, valid_loss= 0.6296778917312622, accuracy= 62.5\n",
      "Epoch 537: train_loss = 0.625444769859314, valid_loss= 0.6503448486328125, accuracy= 62.5\n",
      "Epoch 538: train_loss = 0.6215333342552185, valid_loss= 0.6297986507415771, accuracy= 62.81250000000001\n",
      "Epoch 539: train_loss = 0.6259773969650269, valid_loss= 0.6518162488937378, accuracy= 62.81250000000001\n",
      "Epoch 540: train_loss = 0.6223814487457275, valid_loss= 0.6306952834129333, accuracy= 62.81250000000001\n",
      "Epoch 541: train_loss = 0.627746045589447, valid_loss= 0.6535949110984802, accuracy= 63.125\n",
      "Epoch 542: train_loss = 0.6235020756721497, valid_loss= 0.6315965056419373, accuracy= 63.4375\n",
      "Epoch 543: train_loss = 0.6293510794639587, valid_loss= 0.6546962857246399, accuracy= 62.81250000000001\n",
      "Epoch 544: train_loss = 0.6241911053657532, valid_loss= 0.6315028071403503, accuracy= 63.4375\n",
      "Epoch 545: train_loss = 0.629067599773407, valid_loss= 0.6535779237747192, accuracy= 62.81250000000001\n",
      "Epoch 546: train_loss = 0.623458206653595, valid_loss= 0.6308997273445129, accuracy= 62.81250000000001\n",
      "Epoch 547: train_loss = 0.6279417276382446, valid_loss= 0.6518236994743347, accuracy= 62.81250000000001\n",
      "Epoch 548: train_loss = 0.6223161816596985, valid_loss= 0.6299976110458374, accuracy= 63.125\n",
      "Epoch 549: train_loss = 0.6261204481124878, valid_loss= 0.6497761011123657, accuracy= 62.5\n",
      "Epoch 550: train_loss = 0.6210591793060303, valid_loss= 0.6289224624633789, accuracy= 61.875\n",
      "Epoch 551: train_loss = 0.6241903901100159, valid_loss= 0.6499717235565186, accuracy= 62.81250000000001\n",
      "Epoch 552: train_loss = 0.6209502816200256, valid_loss= 0.6294915676116943, accuracy= 62.81250000000001\n",
      "Epoch 553: train_loss = 0.6254796385765076, valid_loss= 0.6521127223968506, accuracy= 62.81250000000001\n",
      "Epoch 554: train_loss = 0.6221561431884766, valid_loss= 0.6307182312011719, accuracy= 62.81250000000001\n",
      "Epoch 555: train_loss = 0.6279884576797485, valid_loss= 0.6546472907066345, accuracy= 62.81250000000001\n",
      "Epoch 556: train_loss = 0.6237806081771851, valid_loss= 0.6320648193359375, accuracy= 63.4375\n",
      "Epoch 557: train_loss = 0.6302304863929749, valid_loss= 0.6532350778579712, accuracy= 62.81250000000001\n",
      "Epoch 558: train_loss = 0.6230531334877014, valid_loss= 0.6303412318229675, accuracy= 63.125\n",
      "Epoch 559: train_loss = 0.6267663240432739, valid_loss= 0.6507803201675415, accuracy= 62.81250000000001\n",
      "Epoch 560: train_loss = 0.6214624643325806, valid_loss= 0.6292903423309326, accuracy= 62.5\n",
      "Epoch 561: train_loss = 0.6247590184211731, valid_loss= 0.6501443982124329, accuracy= 62.5\n",
      "Epoch 562: train_loss = 0.6208663582801819, valid_loss= 0.6291126012802124, accuracy= 62.81250000000001\n",
      "Epoch 563: train_loss = 0.6247899532318115, valid_loss= 0.6514289379119873, accuracy= 62.81250000000001\n",
      "Epoch 564: train_loss = 0.6215560436248779, valid_loss= 0.630186915397644, accuracy= 62.81250000000001\n",
      "Epoch 565: train_loss = 0.6270816922187805, valid_loss= 0.6526676416397095, accuracy= 62.5\n",
      "Epoch 566: train_loss = 0.6223790645599365, valid_loss= 0.6307274103164673, accuracy= 62.81250000000001\n",
      "Epoch 567: train_loss = 0.6279781460762024, valid_loss= 0.6540127992630005, accuracy= 63.125\n",
      "Epoch 568: train_loss = 0.6231473088264465, valid_loss= 0.631759762763977, accuracy= 63.74999999999999\n",
      "Epoch 569: train_loss = 0.6297141909599304, valid_loss= 0.6530165076255798, accuracy= 62.5\n",
      "Epoch 570: train_loss = 0.6226527690887451, valid_loss= 0.6302255988121033, accuracy= 62.81250000000001\n",
      "Epoch 571: train_loss = 0.6266143918037415, valid_loss= 0.6508980989456177, accuracy= 62.81250000000001\n",
      "Epoch 572: train_loss = 0.6212307214736938, valid_loss= 0.6291056871414185, accuracy= 62.5\n",
      "Epoch 573: train_loss = 0.6244944334030151, valid_loss= 0.6492084860801697, accuracy= 62.5\n",
      "Epoch 574: train_loss = 0.6200557351112366, valid_loss= 0.6284712553024292, accuracy= 62.5\n",
      "Epoch 575: train_loss = 0.6236656904220581, valid_loss= 0.6499975919723511, accuracy= 62.5\n",
      "Epoch 576: train_loss = 0.6203609704971313, valid_loss= 0.6295238137245178, accuracy= 62.81250000000001\n",
      "Epoch 577: train_loss = 0.6259223222732544, valid_loss= 0.6532127261161804, accuracy= 63.125\n",
      "Epoch 578: train_loss = 0.6223246455192566, valid_loss= 0.6314440965652466, accuracy= 63.4375\n",
      "Epoch 579: train_loss = 0.6294052004814148, valid_loss= 0.6539471745491028, accuracy= 62.81250000000001\n",
      "Epoch 580: train_loss = 0.6229663491249084, valid_loss= 0.6310803294181824, accuracy= 63.4375\n",
      "Epoch 581: train_loss = 0.6283872127532959, valid_loss= 0.652127742767334, accuracy= 62.81250000000001\n",
      "Epoch 582: train_loss = 0.6218119859695435, valid_loss= 0.6297367215156555, accuracy= 63.125\n",
      "Epoch 583: train_loss = 0.6256757974624634, valid_loss= 0.6496158838272095, accuracy= 62.5\n",
      "Epoch 584: train_loss = 0.6201120615005493, valid_loss= 0.6287239789962769, accuracy= 62.81250000000001\n",
      "Epoch 585: train_loss = 0.6239232420921326, valid_loss= 0.6498141288757324, accuracy= 62.5\n",
      "Epoch 586: train_loss = 0.6200864911079407, valid_loss= 0.6291956901550293, accuracy= 63.125\n",
      "Epoch 587: train_loss = 0.6252263188362122, valid_loss= 0.6521466970443726, accuracy= 62.5\n",
      "Epoch 588: train_loss = 0.6214516758918762, valid_loss= 0.6305860280990601, accuracy= 63.4375\n",
      "Epoch 589: train_loss = 0.6279154419898987, valid_loss= 0.6533632278442383, accuracy= 62.81250000000001\n",
      "Epoch 590: train_loss = 0.6223419904708862, valid_loss= 0.6307018399238586, accuracy= 62.81250000000001\n",
      "Epoch 591: train_loss = 0.6278406977653503, valid_loss= 0.6518253087997437, accuracy= 62.81250000000001\n",
      "Epoch 592: train_loss = 0.6213558316230774, valid_loss= 0.629480242729187, accuracy= 63.125\n",
      "Epoch 593: train_loss = 0.6253407001495361, valid_loss= 0.6505919694900513, accuracy= 62.5\n",
      "Epoch 594: train_loss = 0.6204400658607483, valid_loss= 0.6291427612304688, accuracy= 63.125\n",
      "Epoch 595: train_loss = 0.6248314380645752, valid_loss= 0.650415301322937, accuracy= 62.81250000000001\n",
      "Epoch 596: train_loss = 0.6203451752662659, valid_loss= 0.6286686658859253, accuracy= 62.5\n",
      "Epoch 597: train_loss = 0.6241033673286438, valid_loss= 0.6507028341293335, accuracy= 63.125\n",
      "Epoch 598: train_loss = 0.6202476620674133, valid_loss= 0.6296311616897583, accuracy= 62.81250000000001\n",
      "Epoch 599: train_loss = 0.6260896325111389, valid_loss= 0.6542308330535889, accuracy= 63.125\n",
      "Epoch 600: train_loss = 0.6224359273910522, valid_loss= 0.6316278576850891, accuracy= 63.125\n",
      "Epoch 601: train_loss = 0.6296548843383789, valid_loss= 0.6547970771789551, accuracy= 62.81250000000001\n",
      "Epoch 602: train_loss = 0.6229770183563232, valid_loss= 0.6313973665237427, accuracy= 63.125\n",
      "Epoch 603: train_loss = 0.6288317441940308, valid_loss= 0.6524790525436401, accuracy= 62.81250000000001\n",
      "Epoch 604: train_loss = 0.6214761137962341, valid_loss= 0.6296233534812927, accuracy= 62.81250000000001\n",
      "Epoch 605: train_loss = 0.6253610849380493, valid_loss= 0.6483404040336609, accuracy= 62.5\n",
      "Epoch 606: train_loss = 0.6188243627548218, valid_loss= 0.6276362538337708, accuracy= 63.125\n",
      "Epoch 607: train_loss = 0.6215811967849731, valid_loss= 0.6466739773750305, accuracy= 62.81250000000001\n",
      "Epoch 608: train_loss = 0.6176195740699768, valid_loss= 0.6271671056747437, accuracy= 63.4375\n",
      "Epoch 609: train_loss = 0.6214808225631714, valid_loss= 0.6483519673347473, accuracy= 62.5\n",
      "Epoch 610: train_loss = 0.6184631586074829, valid_loss= 0.6283959150314331, accuracy= 62.81250000000001\n",
      "Epoch 611: train_loss = 0.6242144703865051, valid_loss= 0.6544475555419922, accuracy= 63.125\n",
      "Epoch 612: train_loss = 0.622223436832428, valid_loss= 0.6330337524414062, accuracy= 62.5\n",
      "Epoch 613: train_loss = 0.6323822736740112, valid_loss= 0.6587426066398621, accuracy= 62.81250000000001\n",
      "Epoch 614: train_loss = 0.6252918839454651, valid_loss= 0.6339513063430786, accuracy= 62.81250000000001\n",
      "Epoch 615: train_loss = 0.6331914663314819, valid_loss= 0.6548336744308472, accuracy= 62.81250000000001\n",
      "Epoch 616: train_loss = 0.6228285431861877, valid_loss= 0.6302015781402588, accuracy= 62.81250000000001\n",
      "Epoch 617: train_loss = 0.6265490651130676, valid_loss= 0.6480506658554077, accuracy= 62.5\n",
      "Epoch 618: train_loss = 0.6184878945350647, valid_loss= 0.6270893812179565, accuracy= 63.4375\n",
      "Epoch 619: train_loss = 0.6203752756118774, valid_loss= 0.6450524926185608, accuracy= 62.81250000000001\n",
      "Epoch 620: train_loss = 0.6164184212684631, valid_loss= 0.6261626482009888, accuracy= 64.0625\n",
      "Epoch 621: train_loss = 0.619708240032196, valid_loss= 0.6479455232620239, accuracy= 62.5\n",
      "Epoch 622: train_loss = 0.6178498864173889, valid_loss= 0.6282736659049988, accuracy= 62.81250000000001\n",
      "Epoch 623: train_loss = 0.6243295073509216, valid_loss= 0.6545695066452026, accuracy= 62.81250000000001\n",
      "Epoch 624: train_loss = 0.6219685673713684, valid_loss= 0.6326467394828796, accuracy= 62.81250000000001\n",
      "Epoch 625: train_loss = 0.6319094300270081, valid_loss= 0.6584078073501587, accuracy= 62.81250000000001\n",
      "Epoch 626: train_loss = 0.6247774958610535, valid_loss= 0.6338428258895874, accuracy= 63.4375\n",
      "Epoch 627: train_loss = 0.633200466632843, valid_loss= 0.654831051826477, accuracy= 62.81250000000001\n",
      "Epoch 628: train_loss = 0.6225716471672058, valid_loss= 0.6300115585327148, accuracy= 62.81250000000001\n",
      "Epoch 629: train_loss = 0.6264293193817139, valid_loss= 0.6469505429267883, accuracy= 62.81250000000001\n",
      "Epoch 630: train_loss = 0.6176117658615112, valid_loss= 0.6263382434844971, accuracy= 64.6875\n",
      "Epoch 631: train_loss = 0.619050920009613, valid_loss= 0.6437022686004639, accuracy= 63.125\n",
      "Epoch 632: train_loss = 0.6153632402420044, valid_loss= 0.625292181968689, accuracy= 65.0\n",
      "Epoch 633: train_loss = 0.6183082461357117, valid_loss= 0.6454628705978394, accuracy= 62.81250000000001\n",
      "Epoch 634: train_loss = 0.616133987903595, valid_loss= 0.6265856623649597, accuracy= 63.4375\n",
      "Epoch 635: train_loss = 0.6216320991516113, valid_loss= 0.6541839838027954, accuracy= 62.81250000000001\n",
      "Epoch 636: train_loss = 0.6213011145591736, valid_loss= 0.6333311200141907, accuracy= 64.0625\n",
      "Epoch 637: train_loss = 0.6334839463233948, valid_loss= 0.6611745953559875, accuracy= 62.5\n",
      "Epoch 638: train_loss = 0.6263816952705383, valid_loss= 0.6352985501289368, accuracy= 63.74999999999999\n",
      "Epoch 639: train_loss = 0.6356501579284668, valid_loss= 0.6521601676940918, accuracy= 62.81250000000001\n",
      "Epoch 640: train_loss = 0.6208972334861755, valid_loss= 0.6279601454734802, accuracy= 63.125\n",
      "Epoch 641: train_loss = 0.6220067739486694, valid_loss= 0.6448527574539185, accuracy= 62.81250000000001\n",
      "Epoch 642: train_loss = 0.6159648299217224, valid_loss= 0.6253105998039246, accuracy= 65.3125\n",
      "Epoch 643: train_loss = 0.6175800561904907, valid_loss= 0.643438994884491, accuracy= 62.81250000000001\n",
      "Epoch 644: train_loss = 0.6147586703300476, valid_loss= 0.6252318620681763, accuracy= 63.74999999999999\n",
      "Epoch 645: train_loss = 0.6186612844467163, valid_loss= 0.6482588648796082, accuracy= 62.5\n",
      "Epoch 646: train_loss = 0.6173457503318787, valid_loss= 0.6285641193389893, accuracy= 62.81250000000001\n",
      "Epoch 647: train_loss = 0.6256664991378784, valid_loss= 0.6572341918945312, accuracy= 62.81250000000001\n",
      "Epoch 648: train_loss = 0.6231516599655151, valid_loss= 0.6353198885917664, accuracy= 64.375\n",
      "Epoch 649: train_loss = 0.6364336609840393, valid_loss= 0.6611242890357971, accuracy= 62.5\n",
      "Epoch 650: train_loss = 0.6261352896690369, valid_loss= 0.634107768535614, accuracy= 64.0625\n",
      "Epoch 651: train_loss = 0.6335375905036926, valid_loss= 0.6492664217948914, accuracy= 62.5\n",
      "Epoch 652: train_loss = 0.6188385486602783, valid_loss= 0.6265566349029541, accuracy= 63.125\n",
      "Epoch 653: train_loss = 0.6192517876625061, valid_loss= 0.6429240703582764, accuracy= 63.125\n",
      "Epoch 654: train_loss = 0.6144847869873047, valid_loss= 0.6242914795875549, accuracy= 65.625\n",
      "Epoch 655: train_loss = 0.615902304649353, valid_loss= 0.6429283022880554, accuracy= 62.81250000000001\n",
      "Epoch 656: train_loss = 0.6140938997268677, valid_loss= 0.6250621676445007, accuracy= 63.74999999999999\n",
      "Epoch 657: train_loss = 0.6190407276153564, valid_loss= 0.6504059433937073, accuracy= 62.5\n",
      "Epoch 658: train_loss = 0.618299663066864, valid_loss= 0.6304422616958618, accuracy= 63.74999999999999\n",
      "Epoch 659: train_loss = 0.6292620301246643, valid_loss= 0.6581684350967407, accuracy= 62.81250000000001\n",
      "Epoch 660: train_loss = 0.6237003803253174, valid_loss= 0.6340240240097046, accuracy= 64.375\n",
      "Epoch 661: train_loss = 0.6340969800949097, valid_loss= 0.6580597162246704, accuracy= 63.125\n",
      "Epoch 662: train_loss = 0.6239413619041443, valid_loss= 0.6319138407707214, accuracy= 63.74999999999999\n",
      "Epoch 663: train_loss = 0.630028486251831, valid_loss= 0.64937424659729, accuracy= 62.81250000000001\n",
      "Epoch 664: train_loss = 0.6184490323066711, valid_loss= 0.6265371441841125, accuracy= 63.125\n",
      "Epoch 665: train_loss = 0.6201469898223877, valid_loss= 0.6434547305107117, accuracy= 62.81250000000001\n",
      "Epoch 666: train_loss = 0.6144945621490479, valid_loss= 0.6243904829025269, accuracy= 65.3125\n",
      "Epoch 667: train_loss = 0.6167523860931396, valid_loss= 0.644025444984436, accuracy= 62.81250000000001\n",
      "Epoch 668: train_loss = 0.6144073009490967, valid_loss= 0.6253668069839478, accuracy= 63.4375\n",
      "Epoch 669: train_loss = 0.619827389717102, valid_loss= 0.6522688865661621, accuracy= 62.81250000000001\n",
      "Epoch 670: train_loss = 0.6192145347595215, valid_loss= 0.631263017654419, accuracy= 64.0625\n",
      "Epoch 671: train_loss = 0.6307185292243958, valid_loss= 0.658510148525238, accuracy= 63.125\n",
      "Epoch 672: train_loss = 0.6238308548927307, valid_loss= 0.6335605382919312, accuracy= 64.375\n",
      "Epoch 673: train_loss = 0.6335035562515259, valid_loss= 0.6556895971298218, accuracy= 62.81250000000001\n",
      "Epoch 674: train_loss = 0.6221702694892883, valid_loss= 0.6294207572937012, accuracy= 62.81250000000001\n",
      "Epoch 675: train_loss = 0.6259188055992126, valid_loss= 0.6459841728210449, accuracy= 62.81250000000001\n",
      "Epoch 676: train_loss = 0.6160904169082642, valid_loss= 0.6251361966133118, accuracy= 64.0625\n",
      "Epoch 677: train_loss = 0.6172120571136475, valid_loss= 0.6420524716377258, accuracy= 63.125\n",
      "Epoch 678: train_loss = 0.613315224647522, valid_loss= 0.6237081289291382, accuracy= 65.3125\n",
      "Epoch 679: train_loss = 0.6159121990203857, valid_loss= 0.6444208025932312, accuracy= 62.81250000000001\n",
      "Epoch 680: train_loss = 0.6142578721046448, valid_loss= 0.6254292726516724, accuracy= 63.4375\n",
      "Epoch 681: train_loss = 0.6203531622886658, valid_loss= 0.6555372476577759, accuracy= 62.81250000000001\n",
      "Epoch 682: train_loss = 0.6209446787834167, valid_loss= 0.6337478160858154, accuracy= 64.375\n",
      "Epoch 683: train_loss = 0.6348152756690979, valid_loss= 0.6623369455337524, accuracy= 62.5\n",
      "Epoch 684: train_loss = 0.6262180209159851, valid_loss= 0.6345169544219971, accuracy= 64.0625\n",
      "Epoch 685: train_loss = 0.6349172592163086, valid_loss= 0.6513673067092896, accuracy= 62.81250000000001\n",
      "Epoch 686: train_loss = 0.6193722486495972, valid_loss= 0.6267240047454834, accuracy= 63.125\n",
      "Epoch 687: train_loss = 0.6204390525817871, valid_loss= 0.6424418687820435, accuracy= 63.125\n",
      "Epoch 688: train_loss = 0.6135631799697876, valid_loss= 0.6235840916633606, accuracy= 65.625\n",
      "Epoch 689: train_loss = 0.6144667267799377, valid_loss= 0.6421188116073608, accuracy= 62.81250000000001\n",
      "Epoch 690: train_loss = 0.6128209829330444, valid_loss= 0.624030351638794, accuracy= 64.0625\n",
      "Epoch 691: train_loss = 0.6176785826683044, valid_loss= 0.6495752334594727, accuracy= 62.5\n",
      "Epoch 692: train_loss = 0.6169813871383667, valid_loss= 0.629193902015686, accuracy= 64.375\n",
      "Epoch 693: train_loss = 0.6276227235794067, valid_loss= 0.6572089791297913, accuracy= 63.4375\n",
      "Epoch 694: train_loss = 0.622337281703949, valid_loss= 0.6330462694168091, accuracy= 64.0625\n",
      "Epoch 695: train_loss = 0.6331748366355896, valid_loss= 0.6573663949966431, accuracy= 62.81250000000001\n",
      "Epoch 696: train_loss = 0.6226844787597656, valid_loss= 0.6308498978614807, accuracy= 64.375\n",
      "Epoch 697: train_loss = 0.628882884979248, valid_loss= 0.6491273641586304, accuracy= 62.5\n",
      "Epoch 698: train_loss = 0.6174407005310059, valid_loss= 0.6259837746620178, accuracy= 63.4375\n",
      "Epoch 699: train_loss = 0.6200059652328491, valid_loss= 0.6430402994155884, accuracy= 62.81250000000001\n",
      "Epoch 700: train_loss = 0.6134722828865051, valid_loss= 0.6234015226364136, accuracy= 64.375\n",
      "Epoch 701: train_loss = 0.6155697703361511, valid_loss= 0.6422102451324463, accuracy= 62.81250000000001\n",
      "Epoch 702: train_loss = 0.6126490235328674, valid_loss= 0.6233980655670166, accuracy= 64.375\n",
      "Epoch 703: train_loss = 0.6168467998504639, valid_loss= 0.6478173136711121, accuracy= 62.81250000000001\n",
      "Epoch 704: train_loss = 0.6156727075576782, valid_loss= 0.6276075839996338, accuracy= 63.74999999999999\n",
      "Epoch 705: train_loss = 0.6251092553138733, valid_loss= 0.6588881015777588, accuracy= 62.81250000000001\n",
      "Epoch 706: train_loss = 0.6229783296585083, valid_loss= 0.6347735524177551, accuracy= 64.0625\n",
      "Epoch 707: train_loss = 0.6363946199417114, valid_loss= 0.6581826210021973, accuracy= 62.81250000000001\n",
      "Epoch 708: train_loss = 0.6232308745384216, valid_loss= 0.6306877732276917, accuracy= 64.375\n",
      "Epoch 709: train_loss = 0.6287301778793335, valid_loss= 0.6484296917915344, accuracy= 62.81250000000001\n",
      "Epoch 710: train_loss = 0.6168767809867859, valid_loss= 0.6251343488693237, accuracy= 63.125\n",
      "Epoch 711: train_loss = 0.6185928583145142, valid_loss= 0.6433603167533875, accuracy= 62.81250000000001\n",
      "Epoch 712: train_loss = 0.6133349537849426, valid_loss= 0.6231963634490967, accuracy= 64.375\n",
      "Epoch 713: train_loss = 0.6158173084259033, valid_loss= 0.6430122256278992, accuracy= 62.81250000000001\n",
      "Epoch 714: train_loss = 0.6128220558166504, valid_loss= 0.6236622929573059, accuracy= 63.74999999999999\n",
      "Epoch 715: train_loss = 0.6180306077003479, valid_loss= 0.6489088535308838, accuracy= 62.5\n",
      "Epoch 716: train_loss = 0.6161518692970276, valid_loss= 0.6283935308456421, accuracy= 64.6875\n",
      "Epoch 717: train_loss = 0.6268828511238098, valid_loss= 0.6585095524787903, accuracy= 62.81250000000001\n",
      "Epoch 718: train_loss = 0.6226977705955505, valid_loss= 0.6333787441253662, accuracy= 64.0625\n",
      "Epoch 719: train_loss = 0.6342929005622864, valid_loss= 0.6557010412216187, accuracy= 62.81250000000001\n",
      "Epoch 720: train_loss = 0.6211562752723694, valid_loss= 0.6287388205528259, accuracy= 63.74999999999999\n",
      "Epoch 721: train_loss = 0.6258078813552856, valid_loss= 0.6468251943588257, accuracy= 62.81250000000001\n",
      "Epoch 722: train_loss = 0.6155059337615967, valid_loss= 0.6242528557777405, accuracy= 63.74999999999999\n",
      "Epoch 723: train_loss = 0.617219090461731, valid_loss= 0.6422585248947144, accuracy= 62.81250000000001\n",
      "Epoch 724: train_loss = 0.612356960773468, valid_loss= 0.6225966215133667, accuracy= 64.375\n",
      "Epoch 725: train_loss = 0.6149513721466064, valid_loss= 0.6456437706947327, accuracy= 63.125\n",
      "Epoch 726: train_loss = 0.6138432025909424, valid_loss= 0.625377357006073, accuracy= 62.81250000000001\n",
      "Epoch 727: train_loss = 0.6216745972633362, valid_loss= 0.6518983840942383, accuracy= 62.81250000000001\n",
      "Epoch 728: train_loss = 0.6178925037384033, valid_loss= 0.6294352412223816, accuracy= 64.0625\n",
      "Epoch 729: train_loss = 0.6283169388771057, valid_loss= 0.6569328904151917, accuracy= 62.81250000000001\n",
      "Epoch 730: train_loss = 0.621649980545044, valid_loss= 0.6310251951217651, accuracy= 64.375\n",
      "Epoch 731: train_loss = 0.6303504109382629, valid_loss= 0.6547632813453674, accuracy= 62.81250000000001\n",
      "Epoch 732: train_loss = 0.6200485229492188, valid_loss= 0.6288853883743286, accuracy= 64.0625\n",
      "Epoch 733: train_loss = 0.6263390183448792, valid_loss= 0.647591233253479, accuracy= 62.81250000000001\n",
      "Epoch 734: train_loss = 0.6155315041542053, valid_loss= 0.6245989799499512, accuracy= 63.4375\n",
      "Epoch 735: train_loss = 0.6183379292488098, valid_loss= 0.643701434135437, accuracy= 62.81250000000001\n",
      "Epoch 736: train_loss = 0.6128082275390625, valid_loss= 0.6230508089065552, accuracy= 64.0625\n",
      "Epoch 737: train_loss = 0.6163643598556519, valid_loss= 0.6444450616836548, accuracy= 62.81250000000001\n",
      "Epoch 738: train_loss = 0.612962543964386, valid_loss= 0.6239904165267944, accuracy= 63.4375\n",
      "Epoch 739: train_loss = 0.6193132400512695, valid_loss= 0.6515344381332397, accuracy= 62.81250000000001\n",
      "Epoch 740: train_loss = 0.6172995567321777, valid_loss= 0.6296732425689697, accuracy= 64.0625\n",
      "Epoch 741: train_loss = 0.6293861269950867, valid_loss= 0.657719075679779, accuracy= 63.125\n",
      "Epoch 742: train_loss = 0.6218907833099365, valid_loss= 0.6316320300102234, accuracy= 64.375\n",
      "Epoch 743: train_loss = 0.6316664814949036, valid_loss= 0.6533581614494324, accuracy= 62.81250000000001\n",
      "Epoch 744: train_loss = 0.6190744042396545, valid_loss= 0.6275054216384888, accuracy= 63.74999999999999\n",
      "Epoch 745: train_loss = 0.6242448687553406, valid_loss= 0.644459068775177, accuracy= 62.81250000000001\n",
      "Epoch 746: train_loss = 0.6135526299476624, valid_loss= 0.622821033000946, accuracy= 64.6875\n",
      "Epoch 747: train_loss = 0.615115225315094, valid_loss= 0.6405214071273804, accuracy= 62.81250000000001\n",
      "Epoch 748: train_loss = 0.6107808947563171, valid_loss= 0.6214267015457153, accuracy= 65.0\n",
      "Epoch 749: train_loss = 0.6134217381477356, valid_loss= 0.6439638137817383, accuracy= 63.125\n",
      "Epoch 750: train_loss = 0.6123119592666626, valid_loss= 0.6240652799606323, accuracy= 63.74999999999999\n",
      "Epoch 751: train_loss = 0.6203785538673401, valid_loss= 0.6531453132629395, accuracy= 63.125\n",
      "Epoch 752: train_loss = 0.6181815266609192, valid_loss= 0.6312957406044006, accuracy= 64.375\n",
      "Epoch 753: train_loss = 0.6325665712356567, valid_loss= 0.6629799008369446, accuracy= 62.18749999999999\n",
      "Epoch 754: train_loss = 0.625464916229248, valid_loss= 0.6356240510940552, accuracy= 65.0\n",
      "Epoch 755: train_loss = 0.6381217837333679, valid_loss= 0.6501161456108093, accuracy= 62.81250000000001\n",
      "Epoch 756: train_loss = 0.6174338459968567, valid_loss= 0.6243170499801636, accuracy= 63.4375\n",
      "Epoch 757: train_loss = 0.6180656552314758, valid_loss= 0.6398473978042603, accuracy= 63.4375\n",
      "Epoch 758: train_loss = 0.6105878949165344, valid_loss= 0.62111896276474, accuracy= 65.625\n",
      "Epoch 759: train_loss = 0.6111497282981873, valid_loss= 0.6384586095809937, accuracy= 62.81250000000001\n",
      "Epoch 760: train_loss = 0.609275758266449, valid_loss= 0.6206455230712891, accuracy= 65.625\n",
      "Epoch 761: train_loss = 0.6129318475723267, valid_loss= 0.6448750495910645, accuracy= 62.81250000000001\n",
      "Epoch 762: train_loss = 0.6125688552856445, valid_loss= 0.6254491806030273, accuracy= 63.74999999999999\n",
      "Epoch 763: train_loss = 0.623435914516449, valid_loss= 0.656272828578949, accuracy= 62.81250000000001\n",
      "Epoch 764: train_loss = 0.6202812790870667, valid_loss= 0.6329900622367859, accuracy= 64.375\n",
      "Epoch 765: train_loss = 0.6351127624511719, valid_loss= 0.6608074903488159, accuracy= 62.18749999999999\n",
      "Epoch 766: train_loss = 0.6238651275634766, valid_loss= 0.6322226524353027, accuracy= 64.6875\n",
      "Epoch 767: train_loss = 0.6329837441444397, valid_loss= 0.649046003818512, accuracy= 62.81250000000001\n",
      "Epoch 768: train_loss = 0.616159975528717, valid_loss= 0.6239484548568726, accuracy= 63.74999999999999\n",
      "Epoch 769: train_loss = 0.6175844073295593, valid_loss= 0.6399920582771301, accuracy= 63.125\n",
      "Epoch 770: train_loss = 0.6103450655937195, valid_loss= 0.6208714246749878, accuracy= 66.25\n",
      "Epoch 771: train_loss = 0.6117587089538574, valid_loss= 0.639213502407074, accuracy= 62.81250000000001\n",
      "Epoch 772: train_loss = 0.6094376444816589, valid_loss= 0.6204929351806641, accuracy= 65.3125\n",
      "Epoch 773: train_loss = 0.6136132478713989, valid_loss= 0.6461727619171143, accuracy= 62.5\n",
      "Epoch 774: train_loss = 0.6131159663200378, valid_loss= 0.6261858344078064, accuracy= 64.6875\n",
      "Epoch 775: train_loss = 0.625304102897644, valid_loss= 0.6599107980728149, accuracy= 62.18749999999999\n",
      "Epoch 776: train_loss = 0.6226335763931274, valid_loss= 0.6359097957611084, accuracy= 64.375\n",
      "Epoch 777: train_loss = 0.6397270560264587, valid_loss= 0.6585804224014282, accuracy= 62.5\n",
      "Epoch 778: train_loss = 0.6226609945297241, valid_loss= 0.629141628742218, accuracy= 64.0625\n",
      "Epoch 779: train_loss = 0.6278766989707947, valid_loss= 0.6464080214500427, accuracy= 63.125\n",
      "Epoch 780: train_loss = 0.6143806576728821, valid_loss= 0.6226943135261536, accuracy= 64.375\n",
      "Epoch 781: train_loss = 0.6157768368721008, valid_loss= 0.6406430006027222, accuracy= 63.125\n",
      "Epoch 782: train_loss = 0.6103721857070923, valid_loss= 0.6206549406051636, accuracy= 65.0\n",
      "Epoch 783: train_loss = 0.6129010915756226, valid_loss= 0.642342209815979, accuracy= 62.81250000000001\n",
      "Epoch 784: train_loss = 0.6108189225196838, valid_loss= 0.6217764019966125, accuracy= 64.0625\n",
      "Epoch 785: train_loss = 0.6173776984214783, valid_loss= 0.6485959887504578, accuracy= 63.125\n",
      "Epoch 786: train_loss = 0.6146172285079956, valid_loss= 0.6268566250801086, accuracy= 64.375\n",
      "Epoch 787: train_loss = 0.6263964772224426, valid_loss= 0.6566061973571777, accuracy= 63.125\n",
      "Epoch 788: train_loss = 0.620299220085144, valid_loss= 0.6305881142616272, accuracy= 64.6875\n",
      "Epoch 789: train_loss = 0.6315453052520752, valid_loss= 0.6551166772842407, accuracy= 63.125\n",
      "Epoch 790: train_loss = 0.6195055246353149, valid_loss= 0.6278750896453857, accuracy= 65.0\n",
      "Epoch 791: train_loss = 0.6265469789505005, valid_loss= 0.6467028260231018, accuracy= 63.125\n",
      "Epoch 792: train_loss = 0.6141133904457092, valid_loss= 0.6225017309188843, accuracy= 64.0625\n",
      "Epoch 793: train_loss = 0.6166808009147644, valid_loss= 0.6407300233840942, accuracy= 62.81250000000001\n",
      "Epoch 794: train_loss = 0.6102767586708069, valid_loss= 0.6201987266540527, accuracy= 65.625\n",
      "Epoch 795: train_loss = 0.6132323145866394, valid_loss= 0.6433542370796204, accuracy= 63.125\n",
      "Epoch 796: train_loss = 0.611189603805542, valid_loss= 0.6224686503410339, accuracy= 63.4375\n",
      "Epoch 797: train_loss = 0.618829071521759, valid_loss= 0.6490746736526489, accuracy= 63.125\n",
      "Epoch 798: train_loss = 0.6149107813835144, valid_loss= 0.6266671419143677, accuracy= 65.0\n",
      "Epoch 799: train_loss = 0.6262955665588379, valid_loss= 0.6573494672775269, accuracy= 62.5\n",
      "Epoch 800: train_loss = 0.6206690073013306, valid_loss= 0.6307458281517029, accuracy= 64.375\n",
      "Epoch 801: train_loss = 0.6317554116249084, valid_loss= 0.6532770395278931, accuracy= 63.125\n",
      "Epoch 802: train_loss = 0.6181501150131226, valid_loss= 0.6260298490524292, accuracy= 64.375\n",
      "Epoch 803: train_loss = 0.6236199140548706, valid_loss= 0.6444474458694458, accuracy= 62.81250000000001\n",
      "Epoch 804: train_loss = 0.6125149726867676, valid_loss= 0.6211276650428772, accuracy= 65.3125\n",
      "Epoch 805: train_loss = 0.6141033172607422, valid_loss= 0.6387028694152832, accuracy= 62.81250000000001\n",
      "Epoch 806: train_loss = 0.6088870763778687, valid_loss= 0.6191695928573608, accuracy= 65.625\n",
      "Epoch 807: train_loss = 0.6108813881874084, valid_loss= 0.6400018930435181, accuracy= 63.125\n",
      "Epoch 808: train_loss = 0.6090877056121826, valid_loss= 0.6202244162559509, accuracy= 64.6875\n",
      "Epoch 809: train_loss = 0.6150603294372559, valid_loss= 0.6492682695388794, accuracy= 63.125\n",
      "Epoch 810: train_loss = 0.6145123243331909, valid_loss= 0.6286550760269165, accuracy= 65.0\n",
      "Epoch 811: train_loss = 0.6303152441978455, valid_loss= 0.6651292443275452, accuracy= 61.5625\n",
      "Epoch 812: train_loss = 0.6261345148086548, valid_loss= 0.6364670991897583, accuracy= 65.625\n",
      "Epoch 813: train_loss = 0.6408990621566772, valid_loss= 0.6509521007537842, accuracy= 63.125\n",
      "Epoch 814: train_loss = 0.6173741817474365, valid_loss= 0.6236158013343811, accuracy= 63.74999999999999\n",
      "Epoch 815: train_loss = 0.618320107460022, valid_loss= 0.6394399404525757, accuracy= 62.81250000000001\n",
      "Epoch 816: train_loss = 0.609371542930603, valid_loss= 0.6195677518844604, accuracy= 65.9375\n",
      "Epoch 817: train_loss = 0.6098921895027161, valid_loss= 0.6370503902435303, accuracy= 62.81250000000001\n",
      "Epoch 818: train_loss = 0.6074617505073547, valid_loss= 0.6187055706977844, accuracy= 65.9375\n",
      "Epoch 819: train_loss = 0.6103439927101135, valid_loss= 0.6416180729866028, accuracy= 63.125\n",
      "Epoch 820: train_loss = 0.6095404624938965, valid_loss= 0.6222759485244751, accuracy= 63.4375\n",
      "Epoch 821: train_loss = 0.6197022795677185, valid_loss= 0.6541798710823059, accuracy= 62.81250000000001\n",
      "Epoch 822: train_loss = 0.6177062392234802, valid_loss= 0.6313549280166626, accuracy= 65.9375\n",
      "Epoch 823: train_loss = 0.6343445181846619, valid_loss= 0.6637445092201233, accuracy= 61.875\n",
      "Epoch 824: train_loss = 0.6251248121261597, valid_loss= 0.6339671015739441, accuracy= 65.0\n",
      "Epoch 825: train_loss = 0.6364553570747375, valid_loss= 0.6465272903442383, accuracy= 63.125\n",
      "Epoch 826: train_loss = 0.6141982674598694, valid_loss= 0.6216386556625366, accuracy= 64.375\n",
      "Epoch 827: train_loss = 0.6132692098617554, valid_loss= 0.635158360004425, accuracy= 63.4375\n",
      "Epoch 828: train_loss = 0.6067318320274353, valid_loss= 0.6184680461883545, accuracy= 66.875\n",
      "Epoch 829: train_loss = 0.6066074967384338, valid_loss= 0.6335865259170532, accuracy= 63.74999999999999\n",
      "Epoch 830: train_loss = 0.6051604747772217, valid_loss= 0.6173378825187683, accuracy= 65.9375\n",
      "Epoch 831: train_loss = 0.6078478097915649, valid_loss= 0.6403409838676453, accuracy= 63.4375\n",
      "Epoch 832: train_loss = 0.6084359884262085, valid_loss= 0.6223361492156982, accuracy= 64.375\n",
      "Epoch 833: train_loss = 0.6207385063171387, valid_loss= 0.6620720624923706, accuracy= 62.18749999999999\n",
      "Epoch 834: train_loss = 0.6231043338775635, valid_loss= 0.6395512819290161, accuracy= 64.0625\n",
      "Epoch 835: train_loss = 0.6466559767723083, valid_loss= 0.6577150225639343, accuracy= 61.5625\n",
      "Epoch 836: train_loss = 0.6219624876976013, valid_loss= 0.626457929611206, accuracy= 64.375\n",
      "Epoch 837: train_loss = 0.6236574053764343, valid_loss= 0.641271710395813, accuracy= 63.125\n",
      "Epoch 838: train_loss = 0.6100882291793823, valid_loss= 0.619611382484436, accuracy= 65.9375\n",
      "Epoch 839: train_loss = 0.6100115776062012, valid_loss= 0.6368128061294556, accuracy= 62.81250000000001\n",
      "Epoch 840: train_loss = 0.6068379282951355, valid_loss= 0.6180155277252197, accuracy= 65.625\n",
      "Epoch 841: train_loss = 0.6094205379486084, valid_loss= 0.6404476761817932, accuracy= 63.125\n",
      "Epoch 842: train_loss = 0.6084375977516174, valid_loss= 0.6213761568069458, accuracy= 64.375\n",
      "Epoch 843: train_loss = 0.6190476417541504, valid_loss= 0.6527382135391235, accuracy= 63.4375\n",
      "Epoch 844: train_loss = 0.616427481174469, valid_loss= 0.6299485564231873, accuracy= 66.25\n",
      "Epoch 845: train_loss = 0.6326852440834045, valid_loss= 0.6577678918838501, accuracy= 62.18749999999999\n",
      "Epoch 846: train_loss = 0.6207242012023926, valid_loss= 0.6297065615653992, accuracy= 65.0\n",
      "Epoch 847: train_loss = 0.6305983066558838, valid_loss= 0.6483719944953918, accuracy= 63.125\n",
      "Epoch 848: train_loss = 0.6142268180847168, valid_loss= 0.6216995120048523, accuracy= 64.375\n",
      "Epoch 849: train_loss = 0.6163742542266846, valid_loss= 0.6394222974777222, accuracy= 63.125\n",
      "Epoch 850: train_loss = 0.6084191203117371, valid_loss= 0.6183680295944214, accuracy= 65.3125\n",
      "Epoch 851: train_loss = 0.6100330352783203, valid_loss= 0.6388770341873169, accuracy= 63.125\n",
      "Epoch 852: train_loss = 0.6074659824371338, valid_loss= 0.6187102794647217, accuracy= 65.0\n",
      "Epoch 853: train_loss = 0.6137309074401855, valid_loss= 0.647075891494751, accuracy= 63.125\n",
      "Epoch 854: train_loss = 0.6121519207954407, valid_loss= 0.625377893447876, accuracy= 65.0\n",
      "Epoch 855: train_loss = 0.6262046098709106, valid_loss= 0.6604512333869934, accuracy= 61.5625\n",
      "Epoch 856: train_loss = 0.6218832731246948, valid_loss= 0.6330937147140503, accuracy= 65.0\n",
      "Epoch 857: train_loss = 0.636533260345459, valid_loss= 0.6507419347763062, accuracy= 63.125\n",
      "Epoch 858: train_loss = 0.6165007948875427, valid_loss= 0.622909665107727, accuracy= 64.0625\n",
      "Epoch 859: train_loss = 0.6185702681541443, valid_loss= 0.6403118371963501, accuracy= 62.81250000000001\n",
      "Epoch 860: train_loss = 0.6089447736740112, valid_loss= 0.6186827421188354, accuracy= 65.0\n",
      "Epoch 861: train_loss = 0.6103475093841553, valid_loss= 0.6358733177185059, accuracy= 63.125\n",
      "Epoch 862: train_loss = 0.6058624982833862, valid_loss= 0.616788387298584, accuracy= 65.3125\n",
      "Epoch 863: train_loss = 0.6086238622665405, valid_loss= 0.6398739218711853, accuracy= 63.4375\n",
      "Epoch 864: train_loss = 0.6075268983840942, valid_loss= 0.6208568215370178, accuracy= 64.375\n",
      "Epoch 865: train_loss = 0.6192015409469604, valid_loss= 0.655584454536438, accuracy= 61.875\n",
      "Epoch 866: train_loss = 0.6178810000419617, valid_loss= 0.6322654485702515, accuracy= 65.9375\n",
      "Epoch 867: train_loss = 0.6364861726760864, valid_loss= 0.6602767705917358, accuracy= 62.5\n",
      "Epoch 868: train_loss = 0.6233132481575012, valid_loss= 0.6294220089912415, accuracy= 64.6875\n",
      "Epoch 869: train_loss = 0.6300057172775269, valid_loss= 0.6433244943618774, accuracy= 63.4375\n",
      "Epoch 870: train_loss = 0.6111847162246704, valid_loss= 0.619706928730011, accuracy= 64.6875\n",
      "Epoch 871: train_loss = 0.6116092205047607, valid_loss= 0.6362829208374023, accuracy= 63.125\n",
      "Epoch 872: train_loss = 0.6060250401496887, valid_loss= 0.6171559691429138, accuracy= 65.625\n",
      "Epoch 873: train_loss = 0.6084705591201782, valid_loss= 0.6386848092079163, accuracy= 62.81250000000001\n",
      "Epoch 874: train_loss = 0.6067319512367249, valid_loss= 0.6185547113418579, accuracy= 64.6875\n",
      "Epoch 875: train_loss = 0.6143965125083923, valid_loss= 0.6492798924446106, accuracy= 63.125\n",
      "Epoch 876: train_loss = 0.6133559942245483, valid_loss= 0.6273086071014404, accuracy= 65.9375\n",
      "Epoch 877: train_loss = 0.629433274269104, valid_loss= 0.6620470881462097, accuracy= 61.5625\n",
      "Epoch 878: train_loss = 0.6231455206871033, valid_loss= 0.6325384378433228, accuracy= 65.0\n",
      "Epoch 879: train_loss = 0.6356329321861267, valid_loss= 0.6467777490615845, accuracy= 63.4375\n",
      "Epoch 880: train_loss = 0.613429844379425, valid_loss= 0.6205884218215942, accuracy= 64.6875\n",
      "Epoch 881: train_loss = 0.6131719946861267, valid_loss= 0.6364816427230835, accuracy= 63.125\n",
      "Epoch 882: train_loss = 0.6060406565666199, valid_loss= 0.6173375844955444, accuracy= 65.625\n",
      "Epoch 883: train_loss = 0.6077954769134521, valid_loss= 0.6375517845153809, accuracy= 62.5\n",
      "Epoch 884: train_loss = 0.6060221195220947, valid_loss= 0.6172119379043579, accuracy= 66.5625\n",
      "Epoch 885: train_loss = 0.6113930344581604, valid_loss= 0.6437144875526428, accuracy= 63.4375\n",
      "Epoch 886: train_loss = 0.6094350814819336, valid_loss= 0.6228678226470947, accuracy= 66.25\n",
      "Epoch 887: train_loss = 0.6228835582733154, valid_loss= 0.6573265194892883, accuracy= 60.9375\n",
      "Epoch 888: train_loss = 0.6193075776100159, valid_loss= 0.632538378238678, accuracy= 65.0\n",
      "Epoch 889: train_loss = 0.6368722915649414, valid_loss= 0.6557337641716003, accuracy= 61.875\n",
      "Epoch 890: train_loss = 0.6191940307617188, valid_loss= 0.6252154111862183, accuracy= 64.6875\n",
      "Epoch 891: train_loss = 0.6232485175132751, valid_loss= 0.6415106058120728, accuracy= 63.125\n",
      "Epoch 892: train_loss = 0.6091098785400391, valid_loss= 0.618686318397522, accuracy= 65.625\n",
      "Epoch 893: train_loss = 0.6105078458786011, valid_loss= 0.6373112797737122, accuracy= 62.81250000000001\n",
      "Epoch 894: train_loss = 0.6058817505836487, valid_loss= 0.6170526742935181, accuracy= 65.9375\n",
      "Epoch 895: train_loss = 0.6093063950538635, valid_loss= 0.639815628528595, accuracy= 63.4375\n",
      "Epoch 896: train_loss = 0.6068549752235413, valid_loss= 0.6185036897659302, accuracy= 64.375\n",
      "Epoch 897: train_loss = 0.6152499318122864, valid_loss= 0.6472760438919067, accuracy= 63.125\n",
      "Epoch 898: train_loss = 0.6116728782653809, valid_loss= 0.6253138184547424, accuracy= 66.25\n",
      "Epoch 899: train_loss = 0.6271145343780518, valid_loss= 0.6601763963699341, accuracy= 61.5625\n",
      "Epoch 900: train_loss = 0.6212836503982544, valid_loss= 0.6324799060821533, accuracy= 65.3125\n",
      "Epoch 901: train_loss = 0.6366273164749146, valid_loss= 0.643079936504364, accuracy= 63.74999999999999\n",
      "Epoch 902: train_loss = 0.6109588742256165, valid_loss= 0.6182149052619934, accuracy= 65.9375\n",
      "Epoch 903: train_loss = 0.6090535521507263, valid_loss= 0.6336917281150818, accuracy= 64.0625\n",
      "Epoch 904: train_loss = 0.6036677360534668, valid_loss= 0.61601322889328, accuracy= 67.1875\n",
      "Epoch 905: train_loss = 0.6041696667671204, valid_loss= 0.6339977979660034, accuracy= 63.74999999999999\n",
      "Epoch 906: train_loss = 0.603145182132721, valid_loss= 0.6151073575019836, accuracy= 66.875\n",
      "Epoch 907: train_loss = 0.6074995398521423, valid_loss= 0.645045280456543, accuracy= 63.74999999999999\n",
      "Epoch 908: train_loss = 0.6094164848327637, valid_loss= 0.6258716583251953, accuracy= 66.25\n",
      "Epoch 909: train_loss = 0.6290168166160583, valid_loss= 0.6706816554069519, accuracy= 61.25000000000001\n",
      "Epoch 910: train_loss = 0.6288668513298035, valid_loss= 0.6423224210739136, accuracy= 62.18749999999999\n",
      "Epoch 911: train_loss = 0.6517171859741211, valid_loss= 0.6435905694961548, accuracy= 64.0625\n",
      "Epoch 912: train_loss = 0.6123613119125366, valid_loss= 0.6200335621833801, accuracy= 66.875\n",
      "Epoch 913: train_loss = 0.6069859266281128, valid_loss= 0.6320064663887024, accuracy= 63.74999999999999\n",
      "Epoch 914: train_loss = 0.6028980612754822, valid_loss= 0.6168218851089478, accuracy= 67.1875\n",
      "Epoch 915: train_loss = 0.6031954884529114, valid_loss= 0.6337074637413025, accuracy= 63.4375\n",
      "Epoch 916: train_loss = 0.6028280854225159, valid_loss= 0.6155990362167358, accuracy= 66.5625\n",
      "Epoch 917: train_loss = 0.6083654761314392, valid_loss= 0.646395206451416, accuracy= 63.74999999999999\n",
      "Epoch 918: train_loss = 0.6101061105728149, valid_loss= 0.6262609362602234, accuracy= 65.625\n",
      "Epoch 919: train_loss = 0.6305895447731018, valid_loss= 0.6701785922050476, accuracy= 61.25000000000001\n",
      "Epoch 920: train_loss = 0.6284235715866089, valid_loss= 0.6417803168296814, accuracy= 61.875\n",
      "Epoch 921: train_loss = 0.6512888073921204, valid_loss= 0.6454411745071411, accuracy= 62.81250000000001\n",
      "Epoch 922: train_loss = 0.6145840287208557, valid_loss= 0.6196178793907166, accuracy= 66.25\n",
      "Epoch 923: train_loss = 0.6082764863967896, valid_loss= 0.6327121257781982, accuracy= 63.74999999999999\n",
      "Epoch 924: train_loss = 0.6031426787376404, valid_loss= 0.6163949370384216, accuracy= 67.1875\n",
      "Epoch 925: train_loss = 0.6047804355621338, valid_loss= 0.6359432935714722, accuracy= 62.81250000000001\n",
      "Epoch 926: train_loss = 0.6038479804992676, valid_loss= 0.6171947717666626, accuracy= 65.625\n",
      "Epoch 927: train_loss = 0.6127297282218933, valid_loss= 0.6463268995285034, accuracy= 62.81250000000001\n",
      "Epoch 928: train_loss = 0.6102889776229858, valid_loss= 0.6257859468460083, accuracy= 65.9375\n",
      "Epoch 929: train_loss = 0.628829300403595, valid_loss= 0.6628968119621277, accuracy= 61.5625\n",
      "Epoch 930: train_loss = 0.6230151653289795, valid_loss= 0.6353172063827515, accuracy= 63.125\n",
      "Epoch 931: train_loss = 0.6422658562660217, valid_loss= 0.6437761187553406, accuracy= 62.81250000000001\n",
      "Epoch 932: train_loss = 0.6112483143806458, valid_loss= 0.618449330329895, accuracy= 66.25\n",
      "Epoch 933: train_loss = 0.6093176007270813, valid_loss= 0.6332123875617981, accuracy= 63.74999999999999\n",
      "Epoch 934: train_loss = 0.6029455661773682, valid_loss= 0.6159793138504028, accuracy= 67.5\n",
      "Epoch 935: train_loss = 0.6041526198387146, valid_loss= 0.6344698071479797, accuracy= 63.4375\n",
      "Epoch 936: train_loss = 0.6026861667633057, valid_loss= 0.6156091690063477, accuracy= 66.25\n",
      "Epoch 937: train_loss = 0.6093019843101501, valid_loss= 0.6454140543937683, accuracy= 63.74999999999999\n",
      "Epoch 938: train_loss = 0.6092245578765869, valid_loss= 0.6250100135803223, accuracy= 65.9375\n",
      "Epoch 939: train_loss = 0.6289173364639282, valid_loss= 0.6616568565368652, accuracy= 61.875\n",
      "Epoch 940: train_loss = 0.6220389604568481, valid_loss= 0.6358987092971802, accuracy= 62.81250000000001\n",
      "Epoch 941: train_loss = 0.6438623070716858, valid_loss= 0.6461242437362671, accuracy= 62.5\n",
      "Epoch 942: train_loss = 0.6126853823661804, valid_loss= 0.6190889477729797, accuracy= 65.9375\n",
      "Epoch 943: train_loss = 0.6126910448074341, valid_loss= 0.6351335644721985, accuracy= 63.74999999999999\n",
      "Epoch 944: train_loss = 0.6038276553153992, valid_loss= 0.6157006025314331, accuracy= 66.5625\n",
      "Epoch 945: train_loss = 0.603967547416687, valid_loss= 0.6347370147705078, accuracy= 63.74999999999999\n",
      "Epoch 946: train_loss = 0.6026139259338379, valid_loss= 0.6152526140213013, accuracy= 65.9375\n",
      "Epoch 947: train_loss = 0.608844518661499, valid_loss= 0.6440964937210083, accuracy= 63.74999999999999\n",
      "Epoch 948: train_loss = 0.6081432104110718, valid_loss= 0.6231961250305176, accuracy= 66.5625\n",
      "Epoch 949: train_loss = 0.6260467767715454, valid_loss= 0.6602433323860168, accuracy= 62.18749999999999\n",
      "Epoch 950: train_loss = 0.6204099059104919, valid_loss= 0.6342228651046753, accuracy= 63.125\n",
      "Epoch 951: train_loss = 0.641551673412323, valid_loss= 0.6437263488769531, accuracy= 63.4375\n",
      "Epoch 952: train_loss = 0.6108261346817017, valid_loss= 0.6179338097572327, accuracy= 65.625\n",
      "Epoch 953: train_loss = 0.6110314130783081, valid_loss= 0.6353137493133545, accuracy= 62.81250000000001\n",
      "Epoch 954: train_loss = 0.6036351323127747, valid_loss= 0.6155287623405457, accuracy= 67.1875\n",
      "Epoch 955: train_loss = 0.6066145896911621, valid_loss= 0.6378868818283081, accuracy= 63.125\n",
      "Epoch 956: train_loss = 0.6044660210609436, valid_loss= 0.6167098879814148, accuracy= 65.625\n",
      "Epoch 957: train_loss = 0.6133371591567993, valid_loss= 0.6439601182937622, accuracy= 63.4375\n",
      "Epoch 958: train_loss = 0.608406662940979, valid_loss= 0.6219780445098877, accuracy= 66.5625\n",
      "Epoch 959: train_loss = 0.6247234344482422, valid_loss= 0.6563124656677246, accuracy= 61.5625\n",
      "Epoch 960: train_loss = 0.6175292730331421, valid_loss= 0.6301390528678894, accuracy= 65.0\n",
      "Epoch 961: train_loss = 0.6357874870300293, valid_loss= 0.6447260975837708, accuracy= 63.125\n",
      "Epoch 962: train_loss = 0.6115371584892273, valid_loss= 0.618028998374939, accuracy= 65.625\n",
      "Epoch 963: train_loss = 0.6128426194190979, valid_loss= 0.6378291249275208, accuracy= 64.0625\n",
      "Epoch 964: train_loss = 0.6048315763473511, valid_loss= 0.6157470941543579, accuracy= 66.875\n",
      "Epoch 965: train_loss = 0.6080684661865234, valid_loss= 0.6399779319763184, accuracy= 64.0625\n",
      "Epoch 966: train_loss = 0.6055664420127869, valid_loss= 0.6176174879074097, accuracy= 65.625\n",
      "Epoch 967: train_loss = 0.6160814762115479, valid_loss= 0.647905707359314, accuracy= 63.4375\n",
      "Epoch 968: train_loss = 0.6108747124671936, valid_loss= 0.6250060796737671, accuracy= 65.9375\n",
      "Epoch 969: train_loss = 0.6290605664253235, valid_loss= 0.6539087295532227, accuracy= 61.5625\n",
      "Epoch 970: train_loss = 0.6162153482437134, valid_loss= 0.6262888312339783, accuracy= 66.5625\n",
      "Epoch 971: train_loss = 0.6289367079734802, valid_loss= 0.646210789680481, accuracy= 62.5\n",
      "Epoch 972: train_loss = 0.6110939383506775, valid_loss= 0.618918776512146, accuracy= 65.0\n",
      "Epoch 973: train_loss = 0.6146805882453918, valid_loss= 0.6387280225753784, accuracy= 63.74999999999999\n",
      "Epoch 974: train_loss = 0.6053112745285034, valid_loss= 0.6155811548233032, accuracy= 66.875\n",
      "Epoch 975: train_loss = 0.6084840297698975, valid_loss= 0.6364337801933289, accuracy= 63.125\n",
      "Epoch 976: train_loss = 0.6034069061279297, valid_loss= 0.614458441734314, accuracy= 66.25\n",
      "Epoch 977: train_loss = 0.6086671352386475, valid_loss= 0.6411206126213074, accuracy= 63.74999999999999\n",
      "Epoch 978: train_loss = 0.6059355139732361, valid_loss= 0.6189041137695312, accuracy= 66.25\n",
      "Epoch 979: train_loss = 0.6197503805160522, valid_loss= 0.6554888486862183, accuracy= 62.18749999999999\n",
      "Epoch 980: train_loss = 0.6161378026008606, valid_loss= 0.6307546496391296, accuracy= 62.81250000000001\n",
      "Epoch 981: train_loss = 0.6369643211364746, valid_loss= 0.6442354917526245, accuracy= 63.125\n",
      "Epoch 982: train_loss = 0.6112009286880493, valid_loss= 0.617473840713501, accuracy= 65.9375\n",
      "Epoch 983: train_loss = 0.612408459186554, valid_loss= 0.6361621618270874, accuracy= 64.0625\n",
      "Epoch 984: train_loss = 0.603711724281311, valid_loss= 0.6149784326553345, accuracy= 67.5\n",
      "Epoch 985: train_loss = 0.6065129637718201, valid_loss= 0.6388331055641174, accuracy= 63.4375\n",
      "Epoch 986: train_loss = 0.6041808724403381, valid_loss= 0.6160222887992859, accuracy= 66.25\n",
      "Epoch 987: train_loss = 0.611453652381897, valid_loss= 0.6453253030776978, accuracy= 63.4375\n",
      "Epoch 988: train_loss = 0.6082791090011597, valid_loss= 0.6231340169906616, accuracy= 66.25\n",
      "Epoch 989: train_loss = 0.6245766282081604, valid_loss= 0.6483412384986877, accuracy= 63.125\n",
      "Epoch 990: train_loss = 0.6111900806427002, valid_loss= 0.6229006052017212, accuracy= 66.5625\n",
      "Epoch 991: train_loss = 0.6242742538452148, valid_loss= 0.645231306552887, accuracy= 63.125\n",
      "Epoch 992: train_loss = 0.6092297434806824, valid_loss= 0.6190762519836426, accuracy= 65.9375\n",
      "Epoch 993: train_loss = 0.6186965107917786, valid_loss= 0.6422296762466431, accuracy= 63.4375\n",
      "Epoch 994: train_loss = 0.6070378422737122, valid_loss= 0.6164178848266602, accuracy= 65.3125\n",
      "Epoch 995: train_loss = 0.6136935949325562, valid_loss= 0.6423693895339966, accuracy= 63.4375\n",
      "Epoch 996: train_loss = 0.6067716479301453, valid_loss= 0.6170865893363953, accuracy= 65.625\n",
      "Epoch 997: train_loss = 0.6150190234184265, valid_loss= 0.6445671319961548, accuracy= 63.125\n",
      "Epoch 998: train_loss = 0.608155369758606, valid_loss= 0.6184995174407959, accuracy= 65.9375\n",
      "Epoch 999: train_loss = 0.6171822547912598, valid_loss= 0.6465917825698853, accuracy= 62.81250000000001\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 1000\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(mymodel.parameters(), lr=0.1)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    train_loss = 0.0\n",
    "    mymodel.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = mymodel(inputs)\n",
    "\n",
    "        loss = loss_fn(pred,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss_list.append(train_loss/len(train_loader))\n",
    "\n",
    "    mymodel.eval()\n",
    "    valid_loss, correct = 0, 0\n",
    "    size = len(valid_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            pred = mymodel(inputs)\n",
    "            loss = loss_fn(pred,labels)\n",
    "            valid_loss += loss.item()\n",
    "            binary_pred = (pred >= 0.5).float()\n",
    "            correct += (binary_pred==labels).sum().item()\n",
    "        correct /= size\n",
    "        valid_loss/=len(valid_loader)\n",
    "        accuracy_list.append(correct)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss = {train_loss_list[epoch]}, valid_loss= {valid_loss_list[epoch]}, accuracy= {correct*100}\")\n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(train_loss_list)\n",
    "sns.lineplot(valid_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to improve model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel2, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(11, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "model2 = MyModel2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss = 0.7185860276222229, valid_loss= 0.7067301869392395, accuracy= 50.31250000000001\n",
      "Epoch 1: train_loss = 0.7150040864944458, valid_loss= 0.6934952735900879, accuracy= 50.31250000000001\n",
      "Epoch 2: train_loss = 0.7100645899772644, valid_loss= 0.6799095869064331, accuracy= 59.375\n",
      "Epoch 3: train_loss = 0.6971568465232849, valid_loss= 0.6748687028884888, accuracy= 63.4375\n",
      "Epoch 4: train_loss = 0.6983942985534668, valid_loss= 0.6755560636520386, accuracy= 62.18749999999999\n",
      "Epoch 5: train_loss = 0.6912628412246704, valid_loss= 0.6750776767730713, accuracy= 61.875\n",
      "Epoch 6: train_loss = 0.6855766773223877, valid_loss= 0.6744602918624878, accuracy= 62.5\n",
      "Epoch 7: train_loss = 0.688639223575592, valid_loss= 0.6740574836730957, accuracy= 61.875\n",
      "Epoch 8: train_loss = 0.6857348680496216, valid_loss= 0.673320472240448, accuracy= 61.875\n",
      "Epoch 9: train_loss = 0.6934221982955933, valid_loss= 0.6730610728263855, accuracy= 63.125\n",
      "Epoch 10: train_loss = 0.6906613111495972, valid_loss= 0.6739422082901001, accuracy= 61.875\n",
      "Epoch 11: train_loss = 0.6810703873634338, valid_loss= 0.6749836206436157, accuracy= 60.62499999999999\n",
      "Epoch 12: train_loss = 0.6790419220924377, valid_loss= 0.6756354570388794, accuracy= 59.06249999999999\n",
      "Epoch 13: train_loss = 0.6899461150169373, valid_loss= 0.672240138053894, accuracy= 62.5\n",
      "Epoch 14: train_loss = 0.6805892586708069, valid_loss= 0.6696435213088989, accuracy= 62.18749999999999\n",
      "Epoch 15: train_loss = 0.680058479309082, valid_loss= 0.6682540774345398, accuracy= 62.81250000000001\n",
      "Epoch 16: train_loss = 0.6748782396316528, valid_loss= 0.6679467558860779, accuracy= 62.81250000000001\n",
      "Epoch 17: train_loss = 0.6802548170089722, valid_loss= 0.6670680642127991, accuracy= 62.81250000000001\n",
      "Epoch 18: train_loss = 0.6735275387763977, valid_loss= 0.6643713116645813, accuracy= 62.81250000000001\n",
      "Epoch 19: train_loss = 0.6793732047080994, valid_loss= 0.6629248857498169, accuracy= 62.81250000000001\n",
      "Epoch 20: train_loss = 0.6764873266220093, valid_loss= 0.6626197099685669, accuracy= 62.5\n",
      "Epoch 21: train_loss = 0.675498366355896, valid_loss= 0.6625672578811646, accuracy= 62.5\n",
      "Epoch 22: train_loss = 0.6750937700271606, valid_loss= 0.6611172556877136, accuracy= 62.5\n",
      "Epoch 23: train_loss = 0.6740105152130127, valid_loss= 0.6598072052001953, accuracy= 62.5\n",
      "Epoch 24: train_loss = 0.6647540926933289, valid_loss= 0.6598706245422363, accuracy= 62.5\n",
      "Epoch 25: train_loss = 0.6686359643936157, valid_loss= 0.6578664779663086, accuracy= 62.5\n",
      "Epoch 26: train_loss = 0.6736884117126465, valid_loss= 0.6563432812690735, accuracy= 62.81250000000001\n",
      "Epoch 27: train_loss = 0.6644993424415588, valid_loss= 0.6552347540855408, accuracy= 63.4375\n",
      "Epoch 28: train_loss = 0.6658586859703064, valid_loss= 0.6536135673522949, accuracy= 63.125\n",
      "Epoch 29: train_loss = 0.6748272180557251, valid_loss= 0.6533654928207397, accuracy= 63.74999999999999\n",
      "Epoch 30: train_loss = 0.6673117280006409, valid_loss= 0.6553476452827454, accuracy= 62.5\n",
      "Epoch 31: train_loss = 0.6685925722122192, valid_loss= 0.6541050672531128, accuracy= 62.5\n",
      "Epoch 32: train_loss = 0.6696026921272278, valid_loss= 0.653142511844635, accuracy= 62.18749999999999\n",
      "Epoch 33: train_loss = 0.6728482842445374, valid_loss= 0.6508828401565552, accuracy= 63.125\n",
      "Epoch 34: train_loss = 0.6642037034034729, valid_loss= 0.6494220495223999, accuracy= 63.125\n",
      "Epoch 35: train_loss = 0.6709498167037964, valid_loss= 0.6509865522384644, accuracy= 63.74999999999999\n",
      "Epoch 36: train_loss = 0.6780580878257751, valid_loss= 0.6522105932235718, accuracy= 62.81250000000001\n",
      "Epoch 37: train_loss = 0.667258083820343, valid_loss= 0.653840184211731, accuracy= 62.18749999999999\n",
      "Epoch 38: train_loss = 0.6736090183258057, valid_loss= 0.6524376273155212, accuracy= 62.5\n",
      "Epoch 39: train_loss = 0.6651688814163208, valid_loss= 0.6504896879196167, accuracy= 63.4375\n",
      "Epoch 40: train_loss = 0.6725215315818787, valid_loss= 0.6495612859725952, accuracy= 63.125\n",
      "Epoch 41: train_loss = 0.6683824062347412, valid_loss= 0.6508309841156006, accuracy= 62.18749999999999\n",
      "Epoch 42: train_loss = 0.6656968593597412, valid_loss= 0.6530710458755493, accuracy= 62.81250000000001\n",
      "Epoch 43: train_loss = 0.6647741794586182, valid_loss= 0.6521486043930054, accuracy= 62.5\n",
      "Epoch 44: train_loss = 0.6694607138633728, valid_loss= 0.6498207449913025, accuracy= 62.5\n",
      "Epoch 45: train_loss = 0.6627141833305359, valid_loss= 0.6493811011314392, accuracy= 63.4375\n",
      "Epoch 46: train_loss = 0.66529780626297, valid_loss= 0.6492201089859009, accuracy= 63.4375\n",
      "Epoch 47: train_loss = 0.6695631742477417, valid_loss= 0.6492820978164673, accuracy= 63.4375\n",
      "Epoch 48: train_loss = 0.6613746285438538, valid_loss= 0.6496306657791138, accuracy= 63.4375\n",
      "Epoch 49: train_loss = 0.6620786190032959, valid_loss= 0.6505278944969177, accuracy= 62.5\n",
      "Epoch 50: train_loss = 0.664986252784729, valid_loss= 0.6502922773361206, accuracy= 62.5\n",
      "Epoch 51: train_loss = 0.6716810464859009, valid_loss= 0.6486228704452515, accuracy= 63.4375\n",
      "Epoch 52: train_loss = 0.6582420468330383, valid_loss= 0.6468645334243774, accuracy= 63.125\n",
      "Epoch 53: train_loss = 0.6534526944160461, valid_loss= 0.6467357873916626, accuracy= 63.4375\n",
      "Epoch 54: train_loss = 0.6713228225708008, valid_loss= 0.6474951505661011, accuracy= 63.125\n",
      "Epoch 55: train_loss = 0.6718494892120361, valid_loss= 0.6481720209121704, accuracy= 62.5\n",
      "Epoch 56: train_loss = 0.659603476524353, valid_loss= 0.6487722396850586, accuracy= 62.18749999999999\n",
      "Epoch 57: train_loss = 0.6571194529533386, valid_loss= 0.6474236845970154, accuracy= 62.81250000000001\n",
      "Epoch 58: train_loss = 0.6663268804550171, valid_loss= 0.6469031572341919, accuracy= 63.125\n",
      "Epoch 59: train_loss = 0.6642047166824341, valid_loss= 0.6482540369033813, accuracy= 62.5\n",
      "Epoch 60: train_loss = 0.6591525077819824, valid_loss= 0.6484566330909729, accuracy= 62.18749999999999\n",
      "Epoch 61: train_loss = 0.6607664227485657, valid_loss= 0.6474802494049072, accuracy= 62.5\n",
      "Epoch 62: train_loss = 0.6625040769577026, valid_loss= 0.6466392874717712, accuracy= 63.125\n",
      "Epoch 63: train_loss = 0.6581939458847046, valid_loss= 0.6465162038803101, accuracy= 63.125\n",
      "Epoch 64: train_loss = 0.661592960357666, valid_loss= 0.6477105617523193, accuracy= 62.5\n",
      "Epoch 65: train_loss = 0.6621288657188416, valid_loss= 0.6495128870010376, accuracy= 62.5\n",
      "Epoch 66: train_loss = 0.6635028719902039, valid_loss= 0.6498600840568542, accuracy= 62.18749999999999\n",
      "Epoch 67: train_loss = 0.6681910157203674, valid_loss= 0.6501712203025818, accuracy= 62.5\n",
      "Epoch 68: train_loss = 0.6643484234809875, valid_loss= 0.6480808854103088, accuracy= 62.5\n",
      "Epoch 69: train_loss = 0.6572529673576355, valid_loss= 0.6466591358184814, accuracy= 63.125\n",
      "Epoch 70: train_loss = 0.6655511856079102, valid_loss= 0.6471675038337708, accuracy= 62.81250000000001\n",
      "Epoch 71: train_loss = 0.6627879738807678, valid_loss= 0.6483609676361084, accuracy= 62.5\n",
      "Epoch 72: train_loss = 0.6597424745559692, valid_loss= 0.6478243470191956, accuracy= 62.5\n",
      "Epoch 73: train_loss = 0.6570523381233215, valid_loss= 0.6470076441764832, accuracy= 62.18749999999999\n",
      "Epoch 74: train_loss = 0.657392144203186, valid_loss= 0.6466078758239746, accuracy= 62.81250000000001\n",
      "Epoch 75: train_loss = 0.6551494598388672, valid_loss= 0.6475626826286316, accuracy= 62.18749999999999\n",
      "Epoch 76: train_loss = 0.6619721055030823, valid_loss= 0.6486375331878662, accuracy= 62.5\n",
      "Epoch 77: train_loss = 0.6626505255699158, valid_loss= 0.6490781307220459, accuracy= 62.5\n",
      "Epoch 78: train_loss = 0.6599105596542358, valid_loss= 0.6479176878929138, accuracy= 62.81250000000001\n",
      "Epoch 79: train_loss = 0.6584799885749817, valid_loss= 0.6467586755752563, accuracy= 62.5\n",
      "Epoch 80: train_loss = 0.6598213315010071, valid_loss= 0.6458607316017151, accuracy= 62.81250000000001\n",
      "Epoch 81: train_loss = 0.6625344157218933, valid_loss= 0.646687388420105, accuracy= 63.125\n",
      "Epoch 82: train_loss = 0.6599788665771484, valid_loss= 0.6470814943313599, accuracy= 63.125\n",
      "Epoch 83: train_loss = 0.656561017036438, valid_loss= 0.6480224132537842, accuracy= 62.18749999999999\n",
      "Epoch 84: train_loss = 0.6563669443130493, valid_loss= 0.6498870253562927, accuracy= 61.875\n",
      "Epoch 85: train_loss = 0.6588665843009949, valid_loss= 0.6488611102104187, accuracy= 62.18749999999999\n",
      "Epoch 86: train_loss = 0.6591538190841675, valid_loss= 0.647358775138855, accuracy= 62.81250000000001\n",
      "Epoch 87: train_loss = 0.6549562811851501, valid_loss= 0.6471371054649353, accuracy= 62.5\n",
      "Epoch 88: train_loss = 0.6584212183952332, valid_loss= 0.6473613977432251, accuracy= 62.81250000000001\n",
      "Epoch 89: train_loss = 0.6495742201805115, valid_loss= 0.6478563547134399, accuracy= 63.4375\n",
      "Epoch 90: train_loss = 0.6591351628303528, valid_loss= 0.6487374305725098, accuracy= 63.4375\n",
      "Epoch 91: train_loss = 0.6604182124137878, valid_loss= 0.6489875912666321, accuracy= 63.4375\n",
      "Epoch 92: train_loss = 0.6593791246414185, valid_loss= 0.6494455933570862, accuracy= 63.4375\n",
      "Epoch 93: train_loss = 0.6571594476699829, valid_loss= 0.649270236492157, accuracy= 63.4375\n",
      "Epoch 94: train_loss = 0.6599738001823425, valid_loss= 0.6489111185073853, accuracy= 62.81250000000001\n",
      "Epoch 95: train_loss = 0.6537060141563416, valid_loss= 0.6481412053108215, accuracy= 62.81250000000001\n",
      "Epoch 96: train_loss = 0.6559882760047913, valid_loss= 0.6482502222061157, accuracy= 62.5\n",
      "Epoch 97: train_loss = 0.6623835563659668, valid_loss= 0.6482983827590942, accuracy= 62.5\n",
      "Epoch 98: train_loss = 0.6519507765769958, valid_loss= 0.6476634740829468, accuracy= 62.5\n",
      "Epoch 99: train_loss = 0.6553329229354858, valid_loss= 0.6486297845840454, accuracy= 62.81250000000001\n",
      "Epoch 100: train_loss = 0.6590580344200134, valid_loss= 0.6495075225830078, accuracy= 62.81250000000001\n",
      "Epoch 101: train_loss = 0.6560901999473572, valid_loss= 0.6497190594673157, accuracy= 62.81250000000001\n",
      "Epoch 102: train_loss = 0.653404176235199, valid_loss= 0.6490980386734009, accuracy= 62.81250000000001\n",
      "Epoch 103: train_loss = 0.6578815579414368, valid_loss= 0.648448646068573, accuracy= 62.81250000000001\n",
      "Epoch 104: train_loss = 0.6617016792297363, valid_loss= 0.6473008990287781, accuracy= 63.4375\n",
      "Epoch 105: train_loss = 0.6542530059814453, valid_loss= 0.6476306915283203, accuracy= 63.4375\n",
      "Epoch 106: train_loss = 0.6582939624786377, valid_loss= 0.6479803323745728, accuracy= 63.125\n",
      "Epoch 107: train_loss = 0.6619725823402405, valid_loss= 0.6477523446083069, accuracy= 62.81250000000001\n",
      "Epoch 108: train_loss = 0.6577722430229187, valid_loss= 0.6476278305053711, accuracy= 62.81250000000001\n",
      "Epoch 109: train_loss = 0.657500684261322, valid_loss= 0.6489883661270142, accuracy= 63.125\n",
      "Epoch 110: train_loss = 0.6608913540840149, valid_loss= 0.650481104850769, accuracy= 62.18749999999999\n",
      "Epoch 111: train_loss = 0.6564532518386841, valid_loss= 0.6482888460159302, accuracy= 62.81250000000001\n",
      "Epoch 112: train_loss = 0.6592397689819336, valid_loss= 0.6458791494369507, accuracy= 63.4375\n",
      "Epoch 113: train_loss = 0.6531808972358704, valid_loss= 0.6458436250686646, accuracy= 63.4375\n",
      "Epoch 114: train_loss = 0.6587170362472534, valid_loss= 0.6467903852462769, accuracy= 63.125\n",
      "Epoch 115: train_loss = 0.6516216993331909, valid_loss= 0.6483578085899353, accuracy= 63.4375\n",
      "Epoch 116: train_loss = 0.6584170460700989, valid_loss= 0.6497336626052856, accuracy= 62.5\n",
      "Epoch 117: train_loss = 0.6612255573272705, valid_loss= 0.6489394307136536, accuracy= 62.5\n",
      "Epoch 118: train_loss = 0.6612648367881775, valid_loss= 0.6469971537590027, accuracy= 63.4375\n",
      "Epoch 119: train_loss = 0.6521915197372437, valid_loss= 0.6461334228515625, accuracy= 63.125\n",
      "Epoch 120: train_loss = 0.6557336449623108, valid_loss= 0.6463664770126343, accuracy= 63.4375\n",
      "Epoch 121: train_loss = 0.6571470499038696, valid_loss= 0.6475294232368469, accuracy= 63.125\n",
      "Epoch 122: train_loss = 0.6619430184364319, valid_loss= 0.648894190788269, accuracy= 63.4375\n",
      "Epoch 123: train_loss = 0.6561681032180786, valid_loss= 0.6495489478111267, accuracy= 62.18749999999999\n",
      "Epoch 124: train_loss = 0.6511178016662598, valid_loss= 0.6499931812286377, accuracy= 62.18749999999999\n",
      "Epoch 125: train_loss = 0.6604459285736084, valid_loss= 0.649674117565155, accuracy= 62.81250000000001\n",
      "Epoch 126: train_loss = 0.6551127433776855, valid_loss= 0.6492353677749634, accuracy= 63.125\n",
      "Epoch 127: train_loss = 0.6585901975631714, valid_loss= 0.6486413478851318, accuracy= 63.4375\n",
      "Epoch 128: train_loss = 0.6516552567481995, valid_loss= 0.6484711766242981, accuracy= 63.4375\n",
      "Epoch 129: train_loss = 0.6528852581977844, valid_loss= 0.6482024788856506, accuracy= 63.4375\n",
      "Epoch 130: train_loss = 0.6576746702194214, valid_loss= 0.6480249166488647, accuracy= 63.4375\n",
      "Epoch 131: train_loss = 0.6540971994400024, valid_loss= 0.6480810046195984, accuracy= 63.125\n",
      "Epoch 132: train_loss = 0.6528816223144531, valid_loss= 0.6482099294662476, accuracy= 63.74999999999999\n",
      "Epoch 133: train_loss = 0.6596319079399109, valid_loss= 0.6478670239448547, accuracy= 63.125\n",
      "Epoch 134: train_loss = 0.6577019691467285, valid_loss= 0.647663414478302, accuracy= 63.4375\n",
      "Epoch 135: train_loss = 0.659993588924408, valid_loss= 0.6474789381027222, accuracy= 63.4375\n",
      "Epoch 136: train_loss = 0.6558087468147278, valid_loss= 0.6479099988937378, accuracy= 63.125\n",
      "Epoch 137: train_loss = 0.6625125408172607, valid_loss= 0.6480721831321716, accuracy= 63.4375\n",
      "Epoch 138: train_loss = 0.6542146801948547, valid_loss= 0.6483224630355835, accuracy= 63.125\n",
      "Epoch 139: train_loss = 0.656572699546814, valid_loss= 0.6476168632507324, accuracy= 63.125\n",
      "Epoch 140: train_loss = 0.6593040823936462, valid_loss= 0.6467551589012146, accuracy= 63.125\n",
      "Epoch 141: train_loss = 0.6607611775398254, valid_loss= 0.6459123492240906, accuracy= 63.74999999999999\n",
      "Epoch 142: train_loss = 0.6559608578681946, valid_loss= 0.6465157866477966, accuracy= 63.4375\n",
      "Epoch 143: train_loss = 0.6548733115196228, valid_loss= 0.6474403142929077, accuracy= 62.81250000000001\n",
      "Epoch 144: train_loss = 0.6479513049125671, valid_loss= 0.6483789682388306, accuracy= 62.18749999999999\n",
      "Epoch 145: train_loss = 0.6515871286392212, valid_loss= 0.6490867733955383, accuracy= 62.5\n",
      "Epoch 146: train_loss = 0.6562862396240234, valid_loss= 0.6481119990348816, accuracy= 62.5\n",
      "Epoch 147: train_loss = 0.6539530754089355, valid_loss= 0.6470280885696411, accuracy= 63.4375\n",
      "Epoch 148: train_loss = 0.6533775925636292, valid_loss= 0.6464005708694458, accuracy= 63.4375\n",
      "Epoch 149: train_loss = 0.662043035030365, valid_loss= 0.6458004117012024, accuracy= 63.4375\n",
      "Epoch 150: train_loss = 0.6566437482833862, valid_loss= 0.6463928818702698, accuracy= 63.4375\n",
      "Epoch 151: train_loss = 0.6570373773574829, valid_loss= 0.6473226547241211, accuracy= 62.81250000000001\n",
      "Epoch 152: train_loss = 0.6499305367469788, valid_loss= 0.6489245295524597, accuracy= 62.81250000000001\n",
      "Epoch 153: train_loss = 0.6583669781684875, valid_loss= 0.6482957601547241, accuracy= 62.81250000000001\n",
      "Epoch 154: train_loss = 0.6519484519958496, valid_loss= 0.6473191380500793, accuracy= 63.74999999999999\n",
      "Epoch 155: train_loss = 0.657206118106842, valid_loss= 0.6470955610275269, accuracy= 63.125\n",
      "Epoch 156: train_loss = 0.6584165096282959, valid_loss= 0.6470147371292114, accuracy= 63.125\n",
      "Epoch 157: train_loss = 0.6534382700920105, valid_loss= 0.6473191380500793, accuracy= 63.125\n",
      "Epoch 158: train_loss = 0.6561324000358582, valid_loss= 0.6473561525344849, accuracy= 63.4375\n",
      "Epoch 159: train_loss = 0.6521574854850769, valid_loss= 0.6472058296203613, accuracy= 63.4375\n",
      "Epoch 160: train_loss = 0.653315007686615, valid_loss= 0.6468561291694641, accuracy= 63.4375\n",
      "Epoch 161: train_loss = 0.6524960994720459, valid_loss= 0.6466604471206665, accuracy= 63.125\n",
      "Epoch 162: train_loss = 0.6600508093833923, valid_loss= 0.6468889713287354, accuracy= 63.125\n",
      "Epoch 163: train_loss = 0.6517997980117798, valid_loss= 0.6467652320861816, accuracy= 62.81250000000001\n",
      "Epoch 164: train_loss = 0.6526803970336914, valid_loss= 0.6473807692527771, accuracy= 62.5\n",
      "Epoch 165: train_loss = 0.6555764675140381, valid_loss= 0.6471858024597168, accuracy= 62.5\n",
      "Epoch 166: train_loss = 0.6544667482376099, valid_loss= 0.6456981301307678, accuracy= 62.81250000000001\n",
      "Epoch 167: train_loss = 0.6586062908172607, valid_loss= 0.6451455354690552, accuracy= 63.4375\n",
      "Epoch 168: train_loss = 0.6593334674835205, valid_loss= 0.6453855037689209, accuracy= 63.4375\n",
      "Epoch 169: train_loss = 0.6582789421081543, valid_loss= 0.6461766362190247, accuracy= 62.5\n",
      "Epoch 170: train_loss = 0.6536098122596741, valid_loss= 0.6464942693710327, accuracy= 62.5\n",
      "Epoch 171: train_loss = 0.6549654603004456, valid_loss= 0.6474169492721558, accuracy= 62.5\n",
      "Epoch 172: train_loss = 0.655364990234375, valid_loss= 0.6466971635818481, accuracy= 62.18749999999999\n",
      "Epoch 173: train_loss = 0.655396580696106, valid_loss= 0.6459795236587524, accuracy= 63.125\n",
      "Epoch 174: train_loss = 0.6555268168449402, valid_loss= 0.6457735300064087, accuracy= 63.125\n",
      "Epoch 175: train_loss = 0.6524476408958435, valid_loss= 0.645905613899231, accuracy= 63.125\n",
      "Epoch 176: train_loss = 0.6550264954566956, valid_loss= 0.646708071231842, accuracy= 63.4375\n",
      "Epoch 177: train_loss = 0.6578193306922913, valid_loss= 0.6468620300292969, accuracy= 63.4375\n",
      "Epoch 178: train_loss = 0.6614392995834351, valid_loss= 0.6469271779060364, accuracy= 62.81250000000001\n",
      "Epoch 179: train_loss = 0.6542447209358215, valid_loss= 0.6469195485115051, accuracy= 62.81250000000001\n",
      "Epoch 180: train_loss = 0.6530185341835022, valid_loss= 0.6471817493438721, accuracy= 62.5\n",
      "Epoch 181: train_loss = 0.6574380397796631, valid_loss= 0.6471672058105469, accuracy= 62.5\n",
      "Epoch 182: train_loss = 0.6613251566886902, valid_loss= 0.6460418701171875, accuracy= 63.125\n",
      "Epoch 183: train_loss = 0.6539974212646484, valid_loss= 0.6457046270370483, accuracy= 63.125\n",
      "Epoch 184: train_loss = 0.649241030216217, valid_loss= 0.6455280184745789, accuracy= 63.125\n",
      "Epoch 185: train_loss = 0.6558456420898438, valid_loss= 0.645537793636322, accuracy= 63.125\n",
      "Epoch 186: train_loss = 0.6559557914733887, valid_loss= 0.6458492279052734, accuracy= 63.125\n",
      "Epoch 187: train_loss = 0.6527342200279236, valid_loss= 0.6465235352516174, accuracy= 63.125\n",
      "Epoch 188: train_loss = 0.6530543565750122, valid_loss= 0.6461615562438965, accuracy= 63.4375\n",
      "Epoch 189: train_loss = 0.6497696042060852, valid_loss= 0.6456912755966187, accuracy= 63.74999999999999\n",
      "Epoch 190: train_loss = 0.6579732894897461, valid_loss= 0.6455193758010864, accuracy= 63.4375\n",
      "Epoch 191: train_loss = 0.6542525887489319, valid_loss= 0.6462311148643494, accuracy= 63.74999999999999\n",
      "Epoch 192: train_loss = 0.651968777179718, valid_loss= 0.647101879119873, accuracy= 62.5\n",
      "Epoch 193: train_loss = 0.6532240509986877, valid_loss= 0.6464844942092896, accuracy= 62.81250000000001\n",
      "Epoch 194: train_loss = 0.6489006280899048, valid_loss= 0.646511435508728, accuracy= 62.5\n",
      "Epoch 195: train_loss = 0.6497606039047241, valid_loss= 0.6454541683197021, accuracy= 63.74999999999999\n",
      "Epoch 196: train_loss = 0.6571199297904968, valid_loss= 0.644663393497467, accuracy= 63.74999999999999\n",
      "Epoch 197: train_loss = 0.6484857797622681, valid_loss= 0.6448462009429932, accuracy= 63.74999999999999\n",
      "Epoch 198: train_loss = 0.6537795662879944, valid_loss= 0.6459177136421204, accuracy= 63.125\n",
      "Epoch 199: train_loss = 0.6559160351753235, valid_loss= 0.6461936831474304, accuracy= 63.125\n",
      "Epoch 200: train_loss = 0.6546297669410706, valid_loss= 0.6468427181243896, accuracy= 63.125\n",
      "Epoch 201: train_loss = 0.6542086601257324, valid_loss= 0.6467703580856323, accuracy= 63.125\n",
      "Epoch 202: train_loss = 0.6543559432029724, valid_loss= 0.6464898586273193, accuracy= 63.125\n",
      "Epoch 203: train_loss = 0.6574870944023132, valid_loss= 0.6458374857902527, accuracy= 63.74999999999999\n",
      "Epoch 204: train_loss = 0.6558498740196228, valid_loss= 0.6456631422042847, accuracy= 63.74999999999999\n",
      "Epoch 205: train_loss = 0.653443455696106, valid_loss= 0.6463969349861145, accuracy= 62.81250000000001\n",
      "Epoch 206: train_loss = 0.6517401933670044, valid_loss= 0.6461111903190613, accuracy= 63.4375\n",
      "Epoch 207: train_loss = 0.6520993113517761, valid_loss= 0.646392822265625, accuracy= 62.81250000000001\n",
      "Epoch 208: train_loss = 0.6541327834129333, valid_loss= 0.6465886235237122, accuracy= 62.5\n",
      "Epoch 209: train_loss = 0.6503541469573975, valid_loss= 0.6461516618728638, accuracy= 63.4375\n",
      "Epoch 210: train_loss = 0.6542676091194153, valid_loss= 0.6460564732551575, accuracy= 63.4375\n",
      "Epoch 211: train_loss = 0.6506903171539307, valid_loss= 0.6458756923675537, accuracy= 63.4375\n",
      "Epoch 212: train_loss = 0.6526788473129272, valid_loss= 0.6453688144683838, accuracy= 63.74999999999999\n",
      "Epoch 213: train_loss = 0.6579825282096863, valid_loss= 0.6464175581932068, accuracy= 63.125\n",
      "Epoch 214: train_loss = 0.6584969758987427, valid_loss= 0.6476287841796875, accuracy= 62.18749999999999\n",
      "Epoch 215: train_loss = 0.6502736806869507, valid_loss= 0.6467709541320801, accuracy= 63.125\n",
      "Epoch 216: train_loss = 0.6546171307563782, valid_loss= 0.6463085412979126, accuracy= 63.125\n",
      "Epoch 217: train_loss = 0.6557826399803162, valid_loss= 0.646598219871521, accuracy= 63.74999999999999\n",
      "Epoch 218: train_loss = 0.6590878963470459, valid_loss= 0.6466917395591736, accuracy= 63.74999999999999\n",
      "Epoch 219: train_loss = 0.6513175368309021, valid_loss= 0.6468299031257629, accuracy= 63.125\n",
      "Epoch 220: train_loss = 0.6539765000343323, valid_loss= 0.6463249921798706, accuracy= 63.74999999999999\n",
      "Epoch 221: train_loss = 0.650913417339325, valid_loss= 0.6459530591964722, accuracy= 63.74999999999999\n",
      "Epoch 222: train_loss = 0.6564322710037231, valid_loss= 0.6465819478034973, accuracy= 63.4375\n",
      "Epoch 223: train_loss = 0.655620276927948, valid_loss= 0.6473767161369324, accuracy= 62.5\n",
      "Epoch 224: train_loss = 0.6476659774780273, valid_loss= 0.647781252861023, accuracy= 62.5\n",
      "Epoch 225: train_loss = 0.6544532775878906, valid_loss= 0.6470061540603638, accuracy= 62.81250000000001\n",
      "Epoch 226: train_loss = 0.651377260684967, valid_loss= 0.646178126335144, accuracy= 62.81250000000001\n",
      "Epoch 227: train_loss = 0.6509556174278259, valid_loss= 0.6454357504844666, accuracy= 63.74999999999999\n",
      "Epoch 228: train_loss = 0.6514883637428284, valid_loss= 0.6453104615211487, accuracy= 63.4375\n",
      "Epoch 229: train_loss = 0.649911105632782, valid_loss= 0.6456688642501831, accuracy= 63.4375\n",
      "Epoch 230: train_loss = 0.6530844569206238, valid_loss= 0.6458749771118164, accuracy= 63.4375\n",
      "Epoch 231: train_loss = 0.649813711643219, valid_loss= 0.6456738710403442, accuracy= 63.4375\n",
      "Epoch 232: train_loss = 0.6531693935394287, valid_loss= 0.6464223861694336, accuracy= 63.74999999999999\n",
      "Epoch 233: train_loss = 0.6504616141319275, valid_loss= 0.6471136212348938, accuracy= 63.74999999999999\n",
      "Epoch 234: train_loss = 0.6558240056037903, valid_loss= 0.6466602087020874, accuracy= 63.74999999999999\n",
      "Epoch 235: train_loss = 0.6572543382644653, valid_loss= 0.6464698314666748, accuracy= 62.81250000000001\n",
      "Epoch 236: train_loss = 0.6561457514762878, valid_loss= 0.6454905271530151, accuracy= 63.4375\n",
      "Epoch 237: train_loss = 0.6595141887664795, valid_loss= 0.644874632358551, accuracy= 63.4375\n",
      "Epoch 238: train_loss = 0.6513360142707825, valid_loss= 0.6450861692428589, accuracy= 62.81250000000001\n",
      "Epoch 239: train_loss = 0.6540586352348328, valid_loss= 0.6463356018066406, accuracy= 62.81250000000001\n",
      "Epoch 240: train_loss = 0.6480651497840881, valid_loss= 0.6472133994102478, accuracy= 62.5\n",
      "Epoch 241: train_loss = 0.6468853950500488, valid_loss= 0.6469408869743347, accuracy= 62.5\n",
      "Epoch 242: train_loss = 0.6592832207679749, valid_loss= 0.6456683874130249, accuracy= 63.4375\n",
      "Epoch 243: train_loss = 0.6558223962783813, valid_loss= 0.6452631950378418, accuracy= 63.74999999999999\n",
      "Epoch 244: train_loss = 0.6580421924591064, valid_loss= 0.6444185972213745, accuracy= 63.74999999999999\n",
      "Epoch 245: train_loss = 0.6509585976600647, valid_loss= 0.6448056101799011, accuracy= 63.74999999999999\n",
      "Epoch 246: train_loss = 0.6524108052253723, valid_loss= 0.6458032727241516, accuracy= 62.81250000000001\n",
      "Epoch 247: train_loss = 0.6589203476905823, valid_loss= 0.6470238566398621, accuracy= 62.81250000000001\n",
      "Epoch 248: train_loss = 0.6557894945144653, valid_loss= 0.6471632122993469, accuracy= 62.5\n",
      "Epoch 249: train_loss = 0.6594163775444031, valid_loss= 0.6458047032356262, accuracy= 62.81250000000001\n",
      "Epoch 250: train_loss = 0.6520013213157654, valid_loss= 0.6455079317092896, accuracy= 63.125\n",
      "Epoch 251: train_loss = 0.6588543653488159, valid_loss= 0.6459312438964844, accuracy= 63.125\n",
      "Epoch 252: train_loss = 0.6519840955734253, valid_loss= 0.6462123990058899, accuracy= 63.125\n",
      "Epoch 253: train_loss = 0.6477087140083313, valid_loss= 0.6464227437973022, accuracy= 63.125\n",
      "Epoch 254: train_loss = 0.654693067073822, valid_loss= 0.646622359752655, accuracy= 63.125\n",
      "Epoch 255: train_loss = 0.6497539281845093, valid_loss= 0.6468149423599243, accuracy= 62.81250000000001\n",
      "Epoch 256: train_loss = 0.6537299752235413, valid_loss= 0.6477102041244507, accuracy= 62.81250000000001\n",
      "Epoch 257: train_loss = 0.6521860957145691, valid_loss= 0.6481348276138306, accuracy= 62.5\n",
      "Epoch 258: train_loss = 0.649988055229187, valid_loss= 0.6472037434577942, accuracy= 62.81250000000001\n",
      "Epoch 259: train_loss = 0.6533356308937073, valid_loss= 0.6460226774215698, accuracy= 62.81250000000001\n",
      "Epoch 260: train_loss = 0.6531308889389038, valid_loss= 0.6446579694747925, accuracy= 63.74999999999999\n",
      "Epoch 261: train_loss = 0.6552333831787109, valid_loss= 0.6450072526931763, accuracy= 63.125\n",
      "Epoch 262: train_loss = 0.6517745852470398, valid_loss= 0.6463655233383179, accuracy= 62.81250000000001\n",
      "Epoch 263: train_loss = 0.650836169719696, valid_loss= 0.647820234298706, accuracy= 62.5\n",
      "Epoch 264: train_loss = 0.6561873555183411, valid_loss= 0.6474381685256958, accuracy= 62.5\n",
      "Epoch 265: train_loss = 0.6539890170097351, valid_loss= 0.6459223628044128, accuracy= 63.125\n",
      "Epoch 266: train_loss = 0.6513846516609192, valid_loss= 0.645287811756134, accuracy= 63.125\n",
      "Epoch 267: train_loss = 0.6518008708953857, valid_loss= 0.6457815170288086, accuracy= 62.81250000000001\n",
      "Epoch 268: train_loss = 0.6472316980361938, valid_loss= 0.6457525491714478, accuracy= 63.125\n",
      "Epoch 269: train_loss = 0.6537526845932007, valid_loss= 0.6458342671394348, accuracy= 63.74999999999999\n",
      "Epoch 270: train_loss = 0.6500627994537354, valid_loss= 0.6462588310241699, accuracy= 63.125\n",
      "Epoch 271: train_loss = 0.6489151120185852, valid_loss= 0.6468341946601868, accuracy= 62.81250000000001\n",
      "Epoch 272: train_loss = 0.6462484002113342, valid_loss= 0.6478342413902283, accuracy= 63.125\n",
      "Epoch 273: train_loss = 0.6552115678787231, valid_loss= 0.6477594971656799, accuracy= 63.125\n",
      "Epoch 274: train_loss = 0.6479305624961853, valid_loss= 0.6461197137832642, accuracy= 63.74999999999999\n",
      "Epoch 275: train_loss = 0.6600863337516785, valid_loss= 0.6448296904563904, accuracy= 63.74999999999999\n",
      "Epoch 276: train_loss = 0.6416531205177307, valid_loss= 0.6446253061294556, accuracy= 63.74999999999999\n",
      "Epoch 277: train_loss = 0.6585306525230408, valid_loss= 0.6449254751205444, accuracy= 63.74999999999999\n",
      "Epoch 278: train_loss = 0.6513639688491821, valid_loss= 0.6453343033790588, accuracy= 62.81250000000001\n",
      "Epoch 279: train_loss = 0.6595718860626221, valid_loss= 0.6462236642837524, accuracy= 62.5\n",
      "Epoch 280: train_loss = 0.645076334476471, valid_loss= 0.6471501588821411, accuracy= 61.875\n",
      "Epoch 281: train_loss = 0.6490046381950378, valid_loss= 0.6468462347984314, accuracy= 61.875\n",
      "Epoch 282: train_loss = 0.6528618335723877, valid_loss= 0.64594566822052, accuracy= 62.5\n",
      "Epoch 283: train_loss = 0.6559159755706787, valid_loss= 0.6454921960830688, accuracy= 62.81250000000001\n",
      "Epoch 284: train_loss = 0.6464118957519531, valid_loss= 0.6446458697319031, accuracy= 63.125\n",
      "Epoch 285: train_loss = 0.6557878851890564, valid_loss= 0.6450459361076355, accuracy= 62.81250000000001\n",
      "Epoch 286: train_loss = 0.6535415649414062, valid_loss= 0.6448759436607361, accuracy= 63.125\n",
      "Epoch 287: train_loss = 0.6477372646331787, valid_loss= 0.6457754373550415, accuracy= 62.81250000000001\n",
      "Epoch 288: train_loss = 0.6521154642105103, valid_loss= 0.6458632349967957, accuracy= 62.81250000000001\n",
      "Epoch 289: train_loss = 0.6456460356712341, valid_loss= 0.6444377303123474, accuracy= 62.81250000000001\n",
      "Epoch 290: train_loss = 0.653991162776947, valid_loss= 0.6438361406326294, accuracy= 62.81250000000001\n",
      "Epoch 291: train_loss = 0.6580842733383179, valid_loss= 0.6442053318023682, accuracy= 63.125\n",
      "Epoch 292: train_loss = 0.6528252363204956, valid_loss= 0.6456772089004517, accuracy= 62.81250000000001\n",
      "Epoch 293: train_loss = 0.6541051864624023, valid_loss= 0.6467779874801636, accuracy= 62.81250000000001\n",
      "Epoch 294: train_loss = 0.6531900763511658, valid_loss= 0.6458964943885803, accuracy= 62.5\n",
      "Epoch 295: train_loss = 0.6568383574485779, valid_loss= 0.6450749635696411, accuracy= 62.81250000000001\n",
      "Epoch 296: train_loss = 0.6526421904563904, valid_loss= 0.6439279913902283, accuracy= 62.81250000000001\n",
      "Epoch 297: train_loss = 0.6521526575088501, valid_loss= 0.6435799598693848, accuracy= 62.81250000000001\n",
      "Epoch 298: train_loss = 0.6519532799720764, valid_loss= 0.6439293026924133, accuracy= 62.81250000000001\n",
      "Epoch 299: train_loss = 0.6545006632804871, valid_loss= 0.6448752880096436, accuracy= 62.5\n",
      "Epoch 300: train_loss = 0.657238781452179, valid_loss= 0.6454969644546509, accuracy= 62.81250000000001\n",
      "Epoch 301: train_loss = 0.6525110006332397, valid_loss= 0.6451998353004456, accuracy= 62.5\n",
      "Epoch 302: train_loss = 0.6518795490264893, valid_loss= 0.6448141932487488, accuracy= 62.18749999999999\n",
      "Epoch 303: train_loss = 0.6503967046737671, valid_loss= 0.6457200050354004, accuracy= 62.5\n",
      "Epoch 304: train_loss = 0.6487798690795898, valid_loss= 0.6466566324234009, accuracy= 62.5\n",
      "Epoch 305: train_loss = 0.6528784036636353, valid_loss= 0.6464492082595825, accuracy= 63.4375\n",
      "Epoch 306: train_loss = 0.6518586874008179, valid_loss= 0.646450936794281, accuracy= 63.4375\n",
      "Epoch 307: train_loss = 0.6493587493896484, valid_loss= 0.6463901996612549, accuracy= 63.74999999999999\n",
      "Epoch 308: train_loss = 0.6505776643753052, valid_loss= 0.6469374895095825, accuracy= 63.74999999999999\n",
      "Epoch 309: train_loss = 0.6477718949317932, valid_loss= 0.6474083662033081, accuracy= 63.74999999999999\n",
      "Epoch 310: train_loss = 0.655552864074707, valid_loss= 0.6462987661361694, accuracy= 63.74999999999999\n",
      "Epoch 311: train_loss = 0.6592956781387329, valid_loss= 0.6457306146621704, accuracy= 63.125\n",
      "Epoch 312: train_loss = 0.6455257534980774, valid_loss= 0.6467584371566772, accuracy= 63.74999999999999\n",
      "Epoch 313: train_loss = 0.6551213264465332, valid_loss= 0.6472799181938171, accuracy= 63.125\n",
      "Epoch 314: train_loss = 0.6527913212776184, valid_loss= 0.6465460658073425, accuracy= 63.125\n",
      "Epoch 315: train_loss = 0.6532943844795227, valid_loss= 0.6466640830039978, accuracy= 62.5\n",
      "Epoch 316: train_loss = 0.6517066359519958, valid_loss= 0.6454358100891113, accuracy= 62.81250000000001\n",
      "Epoch 317: train_loss = 0.6464053392410278, valid_loss= 0.6448478698730469, accuracy= 63.74999999999999\n",
      "Epoch 318: train_loss = 0.6488367319107056, valid_loss= 0.6449341773986816, accuracy= 63.74999999999999\n",
      "Epoch 319: train_loss = 0.6503152847290039, valid_loss= 0.645351231098175, accuracy= 63.74999999999999\n",
      "Epoch 320: train_loss = 0.6482751369476318, valid_loss= 0.6465940475463867, accuracy= 62.18749999999999\n",
      "Epoch 321: train_loss = 0.6502773761749268, valid_loss= 0.646780252456665, accuracy= 62.18749999999999\n",
      "Epoch 322: train_loss = 0.6540515422821045, valid_loss= 0.6464686989784241, accuracy= 62.18749999999999\n",
      "Epoch 323: train_loss = 0.6532520651817322, valid_loss= 0.6452397108078003, accuracy= 63.4375\n",
      "Epoch 324: train_loss = 0.6515408754348755, valid_loss= 0.6443051099777222, accuracy= 63.4375\n",
      "Epoch 325: train_loss = 0.6444788575172424, valid_loss= 0.6443537473678589, accuracy= 63.125\n",
      "Epoch 326: train_loss = 0.6504257917404175, valid_loss= 0.6452869176864624, accuracy= 63.74999999999999\n",
      "Epoch 327: train_loss = 0.6549385786056519, valid_loss= 0.6463795900344849, accuracy= 63.74999999999999\n",
      "Epoch 328: train_loss = 0.6539464592933655, valid_loss= 0.6466706395149231, accuracy= 62.81250000000001\n",
      "Epoch 329: train_loss = 0.652242124080658, valid_loss= 0.6459041833877563, accuracy= 63.74999999999999\n",
      "Epoch 330: train_loss = 0.6481203436851501, valid_loss= 0.6449647545814514, accuracy= 63.4375\n",
      "Epoch 331: train_loss = 0.6571083664894104, valid_loss= 0.6457340717315674, accuracy= 63.74999999999999\n",
      "Epoch 332: train_loss = 0.654864490032196, valid_loss= 0.6457506418228149, accuracy= 63.74999999999999\n",
      "Epoch 333: train_loss = 0.6478021144866943, valid_loss= 0.6449953317642212, accuracy= 63.74999999999999\n",
      "Epoch 334: train_loss = 0.6504759788513184, valid_loss= 0.6454569101333618, accuracy= 63.74999999999999\n",
      "Epoch 335: train_loss = 0.6558898687362671, valid_loss= 0.6450053453445435, accuracy= 63.74999999999999\n",
      "Epoch 336: train_loss = 0.6530934572219849, valid_loss= 0.6449027061462402, accuracy= 63.4375\n",
      "Epoch 337: train_loss = 0.6495514512062073, valid_loss= 0.644694447517395, accuracy= 63.4375\n",
      "Epoch 338: train_loss = 0.6461198329925537, valid_loss= 0.6445579528808594, accuracy= 62.81250000000001\n",
      "Epoch 339: train_loss = 0.6533789038658142, valid_loss= 0.6446426510810852, accuracy= 63.125\n",
      "Epoch 340: train_loss = 0.654466450214386, valid_loss= 0.6455856561660767, accuracy= 63.74999999999999\n",
      "Epoch 341: train_loss = 0.6479712128639221, valid_loss= 0.6461763381958008, accuracy= 63.4375\n",
      "Epoch 342: train_loss = 0.6531636714935303, valid_loss= 0.6460577845573425, accuracy= 63.74999999999999\n",
      "Epoch 343: train_loss = 0.6475028395652771, valid_loss= 0.6455596685409546, accuracy= 63.74999999999999\n",
      "Epoch 344: train_loss = 0.6509007811546326, valid_loss= 0.6449297666549683, accuracy= 63.4375\n",
      "Epoch 345: train_loss = 0.6516719460487366, valid_loss= 0.6447650194168091, accuracy= 63.74999999999999\n",
      "Epoch 346: train_loss = 0.6545488238334656, valid_loss= 0.6446917653083801, accuracy= 63.125\n",
      "Epoch 347: train_loss = 0.6530250906944275, valid_loss= 0.644716739654541, accuracy= 63.4375\n",
      "Epoch 348: train_loss = 0.6443556547164917, valid_loss= 0.6445883512496948, accuracy= 63.4375\n",
      "Epoch 349: train_loss = 0.6502789855003357, valid_loss= 0.6444880366325378, accuracy= 63.4375\n",
      "Epoch 350: train_loss = 0.6456548571586609, valid_loss= 0.6447431445121765, accuracy= 63.4375\n",
      "Epoch 351: train_loss = 0.6527484655380249, valid_loss= 0.6463576555252075, accuracy= 62.81250000000001\n",
      "Epoch 352: train_loss = 0.6502299904823303, valid_loss= 0.6460881233215332, accuracy= 63.74999999999999\n",
      "Epoch 353: train_loss = 0.6465756297111511, valid_loss= 0.6455018520355225, accuracy= 63.74999999999999\n",
      "Epoch 354: train_loss = 0.6456433534622192, valid_loss= 0.6450434923171997, accuracy= 63.125\n",
      "Epoch 355: train_loss = 0.6509965658187866, valid_loss= 0.6453419923782349, accuracy= 63.125\n",
      "Epoch 356: train_loss = 0.6490880250930786, valid_loss= 0.6463823318481445, accuracy= 63.74999999999999\n",
      "Epoch 357: train_loss = 0.6499359607696533, valid_loss= 0.6470659971237183, accuracy= 62.81250000000001\n",
      "Epoch 358: train_loss = 0.6520131230354309, valid_loss= 0.646291196346283, accuracy= 63.4375\n",
      "Epoch 359: train_loss = 0.6499860286712646, valid_loss= 0.6448720097541809, accuracy= 63.4375\n",
      "Epoch 360: train_loss = 0.6465747356414795, valid_loss= 0.6445713043212891, accuracy= 63.125\n",
      "Epoch 361: train_loss = 0.6472145318984985, valid_loss= 0.6445971727371216, accuracy= 63.4375\n",
      "Epoch 362: train_loss = 0.6423819661140442, valid_loss= 0.6453171968460083, accuracy= 63.4375\n",
      "Epoch 363: train_loss = 0.6561065316200256, valid_loss= 0.6452142596244812, accuracy= 63.4375\n",
      "Epoch 364: train_loss = 0.6484615802764893, valid_loss= 0.6450608968734741, accuracy= 62.81250000000001\n",
      "Epoch 365: train_loss = 0.645675778388977, valid_loss= 0.6449170112609863, accuracy= 63.125\n",
      "Epoch 366: train_loss = 0.6510444283485413, valid_loss= 0.6453722715377808, accuracy= 62.81250000000001\n",
      "Epoch 367: train_loss = 0.6466488242149353, valid_loss= 0.6449998617172241, accuracy= 62.81250000000001\n",
      "Epoch 368: train_loss = 0.6551944613456726, valid_loss= 0.6445202827453613, accuracy= 63.125\n",
      "Epoch 369: train_loss = 0.6498203873634338, valid_loss= 0.6443785429000854, accuracy= 63.125\n",
      "Epoch 370: train_loss = 0.6393471956253052, valid_loss= 0.64438396692276, accuracy= 62.81250000000001\n",
      "Epoch 371: train_loss = 0.6477549076080322, valid_loss= 0.6445274949073792, accuracy= 62.5\n",
      "Epoch 372: train_loss = 0.64653080701828, valid_loss= 0.6451083421707153, accuracy= 62.5\n",
      "Epoch 373: train_loss = 0.6514714956283569, valid_loss= 0.6459175944328308, accuracy= 62.5\n",
      "Epoch 374: train_loss = 0.6483564376831055, valid_loss= 0.6460431218147278, accuracy= 62.5\n",
      "Epoch 375: train_loss = 0.6518171429634094, valid_loss= 0.64513099193573, accuracy= 62.81250000000001\n",
      "Epoch 376: train_loss = 0.6467095017433167, valid_loss= 0.6437785029411316, accuracy= 63.4375\n",
      "Epoch 377: train_loss = 0.6509920954704285, valid_loss= 0.6434245109558105, accuracy= 63.74999999999999\n",
      "Epoch 378: train_loss = 0.6559251546859741, valid_loss= 0.6437241435050964, accuracy= 63.4375\n",
      "Epoch 379: train_loss = 0.6509596705436707, valid_loss= 0.6449825167655945, accuracy= 63.125\n",
      "Epoch 380: train_loss = 0.6542797684669495, valid_loss= 0.6462051272392273, accuracy= 62.5\n",
      "Epoch 381: train_loss = 0.6417120695114136, valid_loss= 0.6474465131759644, accuracy= 61.875\n",
      "Epoch 382: train_loss = 0.6494382619857788, valid_loss= 0.6459265947341919, accuracy= 62.5\n",
      "Epoch 383: train_loss = 0.6495370864868164, valid_loss= 0.644399106502533, accuracy= 63.4375\n",
      "Epoch 384: train_loss = 0.6517496109008789, valid_loss= 0.6439180374145508, accuracy= 63.74999999999999\n",
      "Epoch 385: train_loss = 0.6524874567985535, valid_loss= 0.643667459487915, accuracy= 63.4375\n",
      "Epoch 386: train_loss = 0.6478903293609619, valid_loss= 0.6442944407463074, accuracy= 63.74999999999999\n",
      "Epoch 387: train_loss = 0.6499542593955994, valid_loss= 0.6453877091407776, accuracy= 63.4375\n",
      "Epoch 388: train_loss = 0.64681476354599, valid_loss= 0.646225094795227, accuracy= 63.125\n",
      "Epoch 389: train_loss = 0.6503843665122986, valid_loss= 0.6460576057434082, accuracy= 63.125\n",
      "Epoch 390: train_loss = 0.6519728899002075, valid_loss= 0.6456481218338013, accuracy= 63.4375\n",
      "Epoch 391: train_loss = 0.647878885269165, valid_loss= 0.6451314091682434, accuracy= 63.74999999999999\n",
      "Epoch 392: train_loss = 0.6512638926506042, valid_loss= 0.6445020437240601, accuracy= 63.125\n",
      "Epoch 393: train_loss = 0.6486496925354004, valid_loss= 0.6450808048248291, accuracy= 63.74999999999999\n",
      "Epoch 394: train_loss = 0.6490947008132935, valid_loss= 0.6459203362464905, accuracy= 63.4375\n",
      "Epoch 395: train_loss = 0.6426814198493958, valid_loss= 0.6461015343666077, accuracy= 63.4375\n",
      "Epoch 396: train_loss = 0.6451298594474792, valid_loss= 0.6460756063461304, accuracy= 63.4375\n",
      "Epoch 397: train_loss = 0.6573499441146851, valid_loss= 0.6465386748313904, accuracy= 63.4375\n",
      "Epoch 398: train_loss = 0.6505425572395325, valid_loss= 0.6465510725975037, accuracy= 63.4375\n",
      "Epoch 399: train_loss = 0.6477302312850952, valid_loss= 0.6467595100402832, accuracy= 63.125\n",
      "Epoch 400: train_loss = 0.6469652056694031, valid_loss= 0.6470411419868469, accuracy= 63.125\n",
      "Epoch 401: train_loss = 0.6489848494529724, valid_loss= 0.6470067501068115, accuracy= 63.125\n",
      "Epoch 402: train_loss = 0.6555728316307068, valid_loss= 0.6458568572998047, accuracy= 63.125\n",
      "Epoch 403: train_loss = 0.6556306481361389, valid_loss= 0.645182728767395, accuracy= 62.81250000000001\n",
      "Epoch 404: train_loss = 0.6529677510261536, valid_loss= 0.644818902015686, accuracy= 63.4375\n",
      "Epoch 405: train_loss = 0.650177538394928, valid_loss= 0.6448397040367126, accuracy= 63.4375\n",
      "Epoch 406: train_loss = 0.6447681188583374, valid_loss= 0.6444998979568481, accuracy= 63.4375\n",
      "Epoch 407: train_loss = 0.649288535118103, valid_loss= 0.644663393497467, accuracy= 63.4375\n",
      "Epoch 408: train_loss = 0.6464218497276306, valid_loss= 0.6449123024940491, accuracy= 63.4375\n",
      "Epoch 409: train_loss = 0.6479234099388123, valid_loss= 0.6456986665725708, accuracy= 63.125\n",
      "Epoch 410: train_loss = 0.6481385231018066, valid_loss= 0.646031379699707, accuracy= 63.125\n",
      "Epoch 411: train_loss = 0.6459128260612488, valid_loss= 0.645187258720398, accuracy= 63.4375\n",
      "Epoch 412: train_loss = 0.6503226161003113, valid_loss= 0.6449781656265259, accuracy= 63.125\n",
      "Epoch 413: train_loss = 0.6474318504333496, valid_loss= 0.6450481414794922, accuracy= 63.125\n",
      "Epoch 414: train_loss = 0.6473932266235352, valid_loss= 0.6462687253952026, accuracy= 63.125\n",
      "Epoch 415: train_loss = 0.6524642109870911, valid_loss= 0.6462694406509399, accuracy= 63.125\n",
      "Epoch 416: train_loss = 0.6548725962638855, valid_loss= 0.645228385925293, accuracy= 63.4375\n",
      "Epoch 417: train_loss = 0.6530174612998962, valid_loss= 0.6449989080429077, accuracy= 62.5\n",
      "Epoch 418: train_loss = 0.649183452129364, valid_loss= 0.6451906561851501, accuracy= 62.5\n",
      "Epoch 419: train_loss = 0.6462156772613525, valid_loss= 0.6450604796409607, accuracy= 62.81250000000001\n",
      "Epoch 420: train_loss = 0.655478298664093, valid_loss= 0.6446009874343872, accuracy= 63.125\n",
      "Epoch 421: train_loss = 0.651422381401062, valid_loss= 0.6448165774345398, accuracy= 62.81250000000001\n",
      "Epoch 422: train_loss = 0.651353657245636, valid_loss= 0.6450355648994446, accuracy= 61.875\n",
      "Epoch 423: train_loss = 0.6528932452201843, valid_loss= 0.6458545327186584, accuracy= 62.81250000000001\n",
      "Epoch 424: train_loss = 0.6491998434066772, valid_loss= 0.6449236869812012, accuracy= 62.5\n",
      "Epoch 425: train_loss = 0.6468514204025269, valid_loss= 0.6442450284957886, accuracy= 63.125\n",
      "Epoch 426: train_loss = 0.6491777896881104, valid_loss= 0.6438486576080322, accuracy= 63.125\n",
      "Epoch 427: train_loss = 0.6490130424499512, valid_loss= 0.6437636613845825, accuracy= 62.81250000000001\n",
      "Epoch 428: train_loss = 0.648797333240509, valid_loss= 0.643476665019989, accuracy= 63.4375\n",
      "Epoch 429: train_loss = 0.6480472087860107, valid_loss= 0.6446033716201782, accuracy= 63.125\n",
      "Epoch 430: train_loss = 0.6539382934570312, valid_loss= 0.6468908786773682, accuracy= 61.875\n",
      "Epoch 431: train_loss = 0.6446438431739807, valid_loss= 0.6472756862640381, accuracy= 61.875\n",
      "Epoch 432: train_loss = 0.6437297463417053, valid_loss= 0.6466370820999146, accuracy= 62.81250000000001\n",
      "Epoch 433: train_loss = 0.6552278399467468, valid_loss= 0.6447461247444153, accuracy= 63.125\n",
      "Epoch 434: train_loss = 0.639879047870636, valid_loss= 0.6444406509399414, accuracy= 62.81250000000001\n",
      "Epoch 435: train_loss = 0.6491831541061401, valid_loss= 0.6448212265968323, accuracy= 63.125\n",
      "Epoch 436: train_loss = 0.6433615684509277, valid_loss= 0.6456613540649414, accuracy= 62.81250000000001\n",
      "Epoch 437: train_loss = 0.646944522857666, valid_loss= 0.6468174457550049, accuracy= 61.875\n",
      "Epoch 438: train_loss = 0.6438016891479492, valid_loss= 0.6459264755249023, accuracy= 62.81250000000001\n",
      "Epoch 439: train_loss = 0.65046226978302, valid_loss= 0.646007776260376, accuracy= 62.81250000000001\n",
      "Epoch 440: train_loss = 0.6447895169258118, valid_loss= 0.645444929599762, accuracy= 62.81250000000001\n",
      "Epoch 441: train_loss = 0.650390625, valid_loss= 0.6445190906524658, accuracy= 62.81250000000001\n",
      "Epoch 442: train_loss = 0.6506056189537048, valid_loss= 0.6445911526679993, accuracy= 62.81250000000001\n",
      "Epoch 443: train_loss = 0.6472769975662231, valid_loss= 0.6455696821212769, accuracy= 62.81250000000001\n",
      "Epoch 444: train_loss = 0.6448480486869812, valid_loss= 0.6468005180358887, accuracy= 61.875\n",
      "Epoch 445: train_loss = 0.6518440842628479, valid_loss= 0.6462081670761108, accuracy= 62.18749999999999\n",
      "Epoch 446: train_loss = 0.653214156627655, valid_loss= 0.6442873477935791, accuracy= 63.125\n",
      "Epoch 447: train_loss = 0.6506600379943848, valid_loss= 0.6437159776687622, accuracy= 63.4375\n",
      "Epoch 448: train_loss = 0.6513882279396057, valid_loss= 0.6440407633781433, accuracy= 63.4375\n",
      "Epoch 449: train_loss = 0.644723653793335, valid_loss= 0.6444662809371948, accuracy= 62.81250000000001\n",
      "Epoch 450: train_loss = 0.6489707231521606, valid_loss= 0.6447709798812866, accuracy= 63.125\n",
      "Epoch 451: train_loss = 0.6492617130279541, valid_loss= 0.6449132561683655, accuracy= 63.125\n",
      "Epoch 452: train_loss = 0.6518596410751343, valid_loss= 0.6456252336502075, accuracy= 63.125\n",
      "Epoch 453: train_loss = 0.6464294195175171, valid_loss= 0.6461581587791443, accuracy= 62.5\n",
      "Epoch 454: train_loss = 0.6413525342941284, valid_loss= 0.6460099816322327, accuracy= 63.125\n",
      "Epoch 455: train_loss = 0.6500569581985474, valid_loss= 0.6453222632408142, accuracy= 63.74999999999999\n",
      "Epoch 456: train_loss = 0.6522418260574341, valid_loss= 0.6449832320213318, accuracy= 63.74999999999999\n",
      "Epoch 457: train_loss = 0.6508795619010925, valid_loss= 0.6451174020767212, accuracy= 63.125\n",
      "Epoch 458: train_loss = 0.6496099233627319, valid_loss= 0.644818902015686, accuracy= 62.81250000000001\n",
      "Epoch 459: train_loss = 0.6397871375083923, valid_loss= 0.6453399658203125, accuracy= 63.125\n",
      "Epoch 460: train_loss = 0.6464135050773621, valid_loss= 0.6450363993644714, accuracy= 63.4375\n",
      "Epoch 461: train_loss = 0.6482731699943542, valid_loss= 0.6455460786819458, accuracy= 63.4375\n",
      "Epoch 462: train_loss = 0.6457979679107666, valid_loss= 0.6453107595443726, accuracy= 63.125\n",
      "Epoch 463: train_loss = 0.6467881202697754, valid_loss= 0.6453083157539368, accuracy= 63.125\n",
      "Epoch 464: train_loss = 0.6468803882598877, valid_loss= 0.6459273099899292, accuracy= 63.125\n",
      "Epoch 465: train_loss = 0.6423532366752625, valid_loss= 0.6470707058906555, accuracy= 62.5\n",
      "Epoch 466: train_loss = 0.6460586786270142, valid_loss= 0.6474794745445251, accuracy= 62.18749999999999\n",
      "Epoch 467: train_loss = 0.6511671543121338, valid_loss= 0.6459121108055115, accuracy= 63.125\n",
      "Epoch 468: train_loss = 0.6479964852333069, valid_loss= 0.6441628932952881, accuracy= 63.74999999999999\n",
      "Epoch 469: train_loss = 0.651583194732666, valid_loss= 0.6431838870048523, accuracy= 64.0625\n",
      "Epoch 470: train_loss = 0.6555309891700745, valid_loss= 0.6438168287277222, accuracy= 63.4375\n",
      "Epoch 471: train_loss = 0.647764265537262, valid_loss= 0.6462804079055786, accuracy= 62.5\n",
      "Epoch 472: train_loss = 0.6450592875480652, valid_loss= 0.6487308740615845, accuracy= 63.125\n",
      "Epoch 473: train_loss = 0.6492530107498169, valid_loss= 0.6474350094795227, accuracy= 61.875\n",
      "Epoch 474: train_loss = 0.6490442752838135, valid_loss= 0.6447610259056091, accuracy= 63.125\n",
      "Epoch 475: train_loss = 0.6393132209777832, valid_loss= 0.6436442136764526, accuracy= 63.4375\n",
      "Epoch 476: train_loss = 0.6501420736312866, valid_loss= 0.6437737941741943, accuracy= 63.74999999999999\n",
      "Epoch 477: train_loss = 0.6414580941200256, valid_loss= 0.6451994776725769, accuracy= 63.4375\n",
      "Epoch 478: train_loss = 0.6446307301521301, valid_loss= 0.6462655067443848, accuracy= 62.18749999999999\n",
      "Epoch 479: train_loss = 0.6434884071350098, valid_loss= 0.6458522081375122, accuracy= 62.5\n",
      "Epoch 480: train_loss = 0.6407821774482727, valid_loss= 0.6447173357009888, accuracy= 63.74999999999999\n",
      "Epoch 481: train_loss = 0.6499127745628357, valid_loss= 0.6448289752006531, accuracy= 64.0625\n",
      "Epoch 482: train_loss = 0.649246871471405, valid_loss= 0.6443317532539368, accuracy= 64.0625\n",
      "Epoch 483: train_loss = 0.6484300494194031, valid_loss= 0.6440423130989075, accuracy= 64.0625\n",
      "Epoch 484: train_loss = 0.645530104637146, valid_loss= 0.6437784433364868, accuracy= 64.0625\n",
      "Epoch 485: train_loss = 0.6541595458984375, valid_loss= 0.6435938477516174, accuracy= 64.0625\n",
      "Epoch 486: train_loss = 0.6415430307388306, valid_loss= 0.6445449590682983, accuracy= 63.125\n",
      "Epoch 487: train_loss = 0.651024341583252, valid_loss= 0.644716203212738, accuracy= 63.4375\n",
      "Epoch 488: train_loss = 0.6459958553314209, valid_loss= 0.6445191502571106, accuracy= 63.4375\n",
      "Epoch 489: train_loss = 0.648232638835907, valid_loss= 0.6440912485122681, accuracy= 63.4375\n",
      "Epoch 490: train_loss = 0.6417692303657532, valid_loss= 0.6436947584152222, accuracy= 63.125\n",
      "Epoch 491: train_loss = 0.6513773798942566, valid_loss= 0.6439169049263, accuracy= 63.125\n",
      "Epoch 492: train_loss = 0.6535744071006775, valid_loss= 0.6444609761238098, accuracy= 63.4375\n",
      "Epoch 493: train_loss = 0.653763473033905, valid_loss= 0.6435356140136719, accuracy= 63.4375\n",
      "Epoch 494: train_loss = 0.6453111171722412, valid_loss= 0.6428669691085815, accuracy= 63.4375\n",
      "Epoch 495: train_loss = 0.6414380073547363, valid_loss= 0.6427870988845825, accuracy= 64.375\n",
      "Epoch 496: train_loss = 0.6464791297912598, valid_loss= 0.6440072655677795, accuracy= 63.74999999999999\n",
      "Epoch 497: train_loss = 0.6476513743400574, valid_loss= 0.644207775592804, accuracy= 63.74999999999999\n",
      "Epoch 498: train_loss = 0.6497749090194702, valid_loss= 0.6423311233520508, accuracy= 63.4375\n",
      "Epoch 499: train_loss = 0.6455329060554504, valid_loss= 0.6422339677810669, accuracy= 63.125\n",
      "Epoch 500: train_loss = 0.6469764113426208, valid_loss= 0.6443658471107483, accuracy= 63.74999999999999\n",
      "Epoch 501: train_loss = 0.6453042030334473, valid_loss= 0.6457059383392334, accuracy= 62.81250000000001\n",
      "Epoch 502: train_loss = 0.6483251452445984, valid_loss= 0.6448075771331787, accuracy= 62.5\n",
      "Epoch 503: train_loss = 0.6461760401725769, valid_loss= 0.6434140205383301, accuracy= 63.74999999999999\n",
      "Epoch 504: train_loss = 0.6496515870094299, valid_loss= 0.6430864930152893, accuracy= 63.74999999999999\n",
      "Epoch 505: train_loss = 0.6450249552726746, valid_loss= 0.64466392993927, accuracy= 62.18749999999999\n",
      "Epoch 506: train_loss = 0.6413081884384155, valid_loss= 0.6457134485244751, accuracy= 62.81250000000001\n",
      "Epoch 507: train_loss = 0.6470955610275269, valid_loss= 0.64564049243927, accuracy= 63.125\n",
      "Epoch 508: train_loss = 0.6509649753570557, valid_loss= 0.6443473696708679, accuracy= 63.125\n",
      "Epoch 509: train_loss = 0.6508414149284363, valid_loss= 0.6439319849014282, accuracy= 63.74999999999999\n",
      "Epoch 510: train_loss = 0.6501871347427368, valid_loss= 0.6436219215393066, accuracy= 63.74999999999999\n",
      "Epoch 511: train_loss = 0.6475982069969177, valid_loss= 0.6441329121589661, accuracy= 63.125\n",
      "Epoch 512: train_loss = 0.647580087184906, valid_loss= 0.6450079679489136, accuracy= 63.125\n",
      "Epoch 513: train_loss = 0.6475515365600586, valid_loss= 0.644460916519165, accuracy= 63.125\n",
      "Epoch 514: train_loss = 0.642776370048523, valid_loss= 0.6442662477493286, accuracy= 63.74999999999999\n",
      "Epoch 515: train_loss = 0.6442731022834778, valid_loss= 0.6448317170143127, accuracy= 63.125\n",
      "Epoch 516: train_loss = 0.642399251461029, valid_loss= 0.6452695727348328, accuracy= 63.74999999999999\n",
      "Epoch 517: train_loss = 0.6472973227500916, valid_loss= 0.6451205015182495, accuracy= 63.74999999999999\n",
      "Epoch 518: train_loss = 0.6500838398933411, valid_loss= 0.6445063948631287, accuracy= 63.74999999999999\n",
      "Epoch 519: train_loss = 0.6533044576644897, valid_loss= 0.6439844369888306, accuracy= 63.4375\n",
      "Epoch 520: train_loss = 0.6578065752983093, valid_loss= 0.64359050989151, accuracy= 63.4375\n",
      "Epoch 521: train_loss = 0.6509698629379272, valid_loss= 0.6436261534690857, accuracy= 63.74999999999999\n",
      "Epoch 522: train_loss = 0.644037127494812, valid_loss= 0.6442546248435974, accuracy= 63.74999999999999\n",
      "Epoch 523: train_loss = 0.6472528576850891, valid_loss= 0.6445574164390564, accuracy= 63.74999999999999\n",
      "Epoch 524: train_loss = 0.6491122841835022, valid_loss= 0.6451014280319214, accuracy= 63.4375\n",
      "Epoch 525: train_loss = 0.6485868692398071, valid_loss= 0.6452581882476807, accuracy= 62.81250000000001\n",
      "Epoch 526: train_loss = 0.643383264541626, valid_loss= 0.6450810432434082, accuracy= 62.5\n",
      "Epoch 527: train_loss = 0.6414403319358826, valid_loss= 0.644557535648346, accuracy= 63.4375\n",
      "Epoch 528: train_loss = 0.6470130085945129, valid_loss= 0.6438218355178833, accuracy= 63.74999999999999\n",
      "Epoch 529: train_loss = 0.6523072719573975, valid_loss= 0.6445692181587219, accuracy= 63.74999999999999\n",
      "Epoch 530: train_loss = 0.6443912386894226, valid_loss= 0.6466837525367737, accuracy= 63.4375\n",
      "Epoch 531: train_loss = 0.6463404297828674, valid_loss= 0.6464958190917969, accuracy= 63.74999999999999\n",
      "Epoch 532: train_loss = 0.6520541310310364, valid_loss= 0.6449860334396362, accuracy= 63.4375\n",
      "Epoch 533: train_loss = 0.6481371521949768, valid_loss= 0.6435605883598328, accuracy= 63.74999999999999\n",
      "Epoch 534: train_loss = 0.642519474029541, valid_loss= 0.6438183784484863, accuracy= 64.0625\n",
      "Epoch 535: train_loss = 0.6479706168174744, valid_loss= 0.6445286870002747, accuracy= 64.0625\n",
      "Epoch 536: train_loss = 0.645577073097229, valid_loss= 0.6460009813308716, accuracy= 62.18749999999999\n",
      "Epoch 537: train_loss = 0.6523444652557373, valid_loss= 0.6459552645683289, accuracy= 62.5\n",
      "Epoch 538: train_loss = 0.6419063210487366, valid_loss= 0.644702672958374, accuracy= 63.74999999999999\n",
      "Epoch 539: train_loss = 0.6495757699012756, valid_loss= 0.644016444683075, accuracy= 63.74999999999999\n",
      "Epoch 540: train_loss = 0.6504623293876648, valid_loss= 0.6439481973648071, accuracy= 63.74999999999999\n",
      "Epoch 541: train_loss = 0.6429303288459778, valid_loss= 0.6437928080558777, accuracy= 63.74999999999999\n",
      "Epoch 542: train_loss = 0.6481865644454956, valid_loss= 0.6441807746887207, accuracy= 63.74999999999999\n",
      "Epoch 543: train_loss = 0.6441769003868103, valid_loss= 0.6446902751922607, accuracy= 63.125\n",
      "Epoch 544: train_loss = 0.6470696926116943, valid_loss= 0.6443602442741394, accuracy= 63.74999999999999\n",
      "Epoch 545: train_loss = 0.6470829844474792, valid_loss= 0.6444377899169922, accuracy= 64.0625\n",
      "Epoch 546: train_loss = 0.6445621848106384, valid_loss= 0.6451139450073242, accuracy= 63.74999999999999\n",
      "Epoch 547: train_loss = 0.648718535900116, valid_loss= 0.6450124979019165, accuracy= 64.0625\n",
      "Epoch 548: train_loss = 0.6490523219108582, valid_loss= 0.6444251537322998, accuracy= 63.4375\n",
      "Epoch 549: train_loss = 0.6430784463882446, valid_loss= 0.6440837979316711, accuracy= 63.74999999999999\n",
      "Epoch 550: train_loss = 0.6434974074363708, valid_loss= 0.6447480916976929, accuracy= 63.4375\n",
      "Epoch 551: train_loss = 0.6522939205169678, valid_loss= 0.6454890966415405, accuracy= 63.4375\n",
      "Epoch 552: train_loss = 0.6444167494773865, valid_loss= 0.6457107067108154, accuracy= 63.125\n",
      "Epoch 553: train_loss = 0.6530483961105347, valid_loss= 0.645318329334259, accuracy= 64.0625\n",
      "Epoch 554: train_loss = 0.6500407457351685, valid_loss= 0.6452129483222961, accuracy= 64.0625\n",
      "Epoch 555: train_loss = 0.640944242477417, valid_loss= 0.6439343690872192, accuracy= 63.74999999999999\n",
      "Epoch 556: train_loss = 0.6476173996925354, valid_loss= 0.6427199244499207, accuracy= 63.74999999999999\n",
      "Epoch 557: train_loss = 0.6403929591178894, valid_loss= 0.6432821154594421, accuracy= 63.74999999999999\n",
      "Epoch 558: train_loss = 0.6441656351089478, valid_loss= 0.6450914144515991, accuracy= 64.0625\n",
      "Epoch 559: train_loss = 0.6423351168632507, valid_loss= 0.6458238959312439, accuracy= 63.125\n",
      "Epoch 560: train_loss = 0.6462109088897705, valid_loss= 0.6452502608299255, accuracy= 63.4375\n",
      "Epoch 561: train_loss = 0.6529331803321838, valid_loss= 0.643952488899231, accuracy= 64.0625\n",
      "Epoch 562: train_loss = 0.6501955389976501, valid_loss= 0.6439515948295593, accuracy= 64.0625\n",
      "Epoch 563: train_loss = 0.6483447551727295, valid_loss= 0.6443424224853516, accuracy= 63.125\n",
      "Epoch 564: train_loss = 0.6487388610839844, valid_loss= 0.6446555256843567, accuracy= 62.18749999999999\n",
      "Epoch 565: train_loss = 0.6430472731590271, valid_loss= 0.6443562507629395, accuracy= 62.5\n",
      "Epoch 566: train_loss = 0.6446560025215149, valid_loss= 0.643547534942627, accuracy= 63.4375\n",
      "Epoch 567: train_loss = 0.6462044715881348, valid_loss= 0.6431244015693665, accuracy= 63.74999999999999\n",
      "Epoch 568: train_loss = 0.6485326290130615, valid_loss= 0.6442054510116577, accuracy= 63.125\n",
      "Epoch 569: train_loss = 0.6529964804649353, valid_loss= 0.6447986364364624, accuracy= 64.0625\n",
      "Epoch 570: train_loss = 0.648939311504364, valid_loss= 0.6440345048904419, accuracy= 63.4375\n",
      "Epoch 571: train_loss = 0.648485004901886, valid_loss= 0.6427619457244873, accuracy= 63.125\n",
      "Epoch 572: train_loss = 0.6451864242553711, valid_loss= 0.6425351500511169, accuracy= 63.125\n",
      "Epoch 573: train_loss = 0.6433373093605042, valid_loss= 0.6433776021003723, accuracy= 63.125\n",
      "Epoch 574: train_loss = 0.6450797319412231, valid_loss= 0.6443457007408142, accuracy= 63.4375\n",
      "Epoch 575: train_loss = 0.6428898572921753, valid_loss= 0.6448596715927124, accuracy= 63.4375\n",
      "Epoch 576: train_loss = 0.641844630241394, valid_loss= 0.6438588500022888, accuracy= 63.125\n",
      "Epoch 577: train_loss = 0.6429777145385742, valid_loss= 0.6428648233413696, accuracy= 64.0625\n",
      "Epoch 578: train_loss = 0.6489874124526978, valid_loss= 0.6427000164985657, accuracy= 63.4375\n",
      "Epoch 579: train_loss = 0.6464775800704956, valid_loss= 0.6436177492141724, accuracy= 63.74999999999999\n",
      "Epoch 580: train_loss = 0.6482678651809692, valid_loss= 0.6440442800521851, accuracy= 63.4375\n",
      "Epoch 581: train_loss = 0.6471304893493652, valid_loss= 0.6446714401245117, accuracy= 63.125\n",
      "Epoch 582: train_loss = 0.647412121295929, valid_loss= 0.6452902555465698, accuracy= 63.125\n",
      "Epoch 583: train_loss = 0.6480506062507629, valid_loss= 0.6457502245903015, accuracy= 63.125\n",
      "Epoch 584: train_loss = 0.6479799747467041, valid_loss= 0.6459749341011047, accuracy= 62.81250000000001\n",
      "Epoch 585: train_loss = 0.6435472369194031, valid_loss= 0.6452013254165649, accuracy= 63.125\n",
      "Epoch 586: train_loss = 0.6427611708641052, valid_loss= 0.6445953249931335, accuracy= 63.74999999999999\n",
      "Epoch 587: train_loss = 0.6479045748710632, valid_loss= 0.6440767049789429, accuracy= 64.0625\n",
      "Epoch 588: train_loss = 0.6474493741989136, valid_loss= 0.64384925365448, accuracy= 63.74999999999999\n",
      "Epoch 589: train_loss = 0.651448667049408, valid_loss= 0.643785834312439, accuracy= 63.74999999999999\n",
      "Epoch 590: train_loss = 0.6396583914756775, valid_loss= 0.6444069147109985, accuracy= 63.125\n",
      "Epoch 591: train_loss = 0.6457386612892151, valid_loss= 0.6443548202514648, accuracy= 62.81250000000001\n",
      "Epoch 592: train_loss = 0.6575761437416077, valid_loss= 0.6433204412460327, accuracy= 63.4375\n",
      "Epoch 593: train_loss = 0.6435784697532654, valid_loss= 0.6442418694496155, accuracy= 63.125\n",
      "Epoch 594: train_loss = 0.6405632495880127, valid_loss= 0.6442989706993103, accuracy= 62.81250000000001\n",
      "Epoch 595: train_loss = 0.6432217955589294, valid_loss= 0.6437264680862427, accuracy= 63.125\n",
      "Epoch 596: train_loss = 0.6458501815795898, valid_loss= 0.6426488161087036, accuracy= 62.81250000000001\n",
      "Epoch 597: train_loss = 0.6443899273872375, valid_loss= 0.6425412893295288, accuracy= 63.125\n",
      "Epoch 598: train_loss = 0.6452918648719788, valid_loss= 0.6424172520637512, accuracy= 63.125\n",
      "Epoch 599: train_loss = 0.6426950693130493, valid_loss= 0.6429480314254761, accuracy= 63.125\n",
      "Epoch 600: train_loss = 0.642771303653717, valid_loss= 0.6436890959739685, accuracy= 63.4375\n",
      "Epoch 601: train_loss = 0.6487537026405334, valid_loss= 0.6445448994636536, accuracy= 64.375\n",
      "Epoch 602: train_loss = 0.6468818187713623, valid_loss= 0.643375039100647, accuracy= 63.74999999999999\n",
      "Epoch 603: train_loss = 0.6448971033096313, valid_loss= 0.6416123509407043, accuracy= 63.74999999999999\n",
      "Epoch 604: train_loss = 0.6474500894546509, valid_loss= 0.6408360600471497, accuracy= 63.74999999999999\n",
      "Epoch 605: train_loss = 0.6507229804992676, valid_loss= 0.6406642198562622, accuracy= 64.375\n",
      "Epoch 606: train_loss = 0.6466811299324036, valid_loss= 0.6415163278579712, accuracy= 62.81250000000001\n",
      "Epoch 607: train_loss = 0.6524447202682495, valid_loss= 0.6428540945053101, accuracy= 63.4375\n",
      "Epoch 608: train_loss = 0.6442998051643372, valid_loss= 0.6445266604423523, accuracy= 63.4375\n",
      "Epoch 609: train_loss = 0.6459488272666931, valid_loss= 0.6443952322006226, accuracy= 63.125\n",
      "Epoch 610: train_loss = 0.6435490250587463, valid_loss= 0.6426900625228882, accuracy= 63.125\n",
      "Epoch 611: train_loss = 0.6467927098274231, valid_loss= 0.6421610713005066, accuracy= 63.4375\n",
      "Epoch 612: train_loss = 0.6456646919250488, valid_loss= 0.6423452496528625, accuracy= 63.74999999999999\n",
      "Epoch 613: train_loss = 0.6508723497390747, valid_loss= 0.6443374156951904, accuracy= 62.81250000000001\n",
      "Epoch 614: train_loss = 0.654134213924408, valid_loss= 0.6451500654220581, accuracy= 63.125\n",
      "Epoch 615: train_loss = 0.6459313035011292, valid_loss= 0.6441856622695923, accuracy= 64.0625\n",
      "Epoch 616: train_loss = 0.6483812928199768, valid_loss= 0.6425501108169556, accuracy= 62.81250000000001\n",
      "Epoch 617: train_loss = 0.6508240103721619, valid_loss= 0.6420877575874329, accuracy= 63.4375\n",
      "Epoch 618: train_loss = 0.6524709463119507, valid_loss= 0.6422576308250427, accuracy= 63.74999999999999\n",
      "Epoch 619: train_loss = 0.6435794830322266, valid_loss= 0.6425662040710449, accuracy= 63.74999999999999\n",
      "Epoch 620: train_loss = 0.6439862251281738, valid_loss= 0.6433960199356079, accuracy= 63.125\n",
      "Epoch 621: train_loss = 0.642531156539917, valid_loss= 0.6449224352836609, accuracy= 62.5\n",
      "Epoch 622: train_loss = 0.6429528594017029, valid_loss= 0.6446643471717834, accuracy= 63.4375\n",
      "Epoch 623: train_loss = 0.6495944261550903, valid_loss= 0.644140362739563, accuracy= 63.74999999999999\n",
      "Epoch 624: train_loss = 0.6417794823646545, valid_loss= 0.6439672708511353, accuracy= 64.0625\n",
      "Epoch 625: train_loss = 0.6443901062011719, valid_loss= 0.6435359716415405, accuracy= 63.4375\n",
      "Epoch 626: train_loss = 0.6485257148742676, valid_loss= 0.6441641449928284, accuracy= 64.0625\n",
      "Epoch 627: train_loss = 0.6492490172386169, valid_loss= 0.6447480916976929, accuracy= 62.81250000000001\n",
      "Epoch 628: train_loss = 0.6502602696418762, valid_loss= 0.6450937986373901, accuracy= 62.18749999999999\n",
      "Epoch 629: train_loss = 0.6459490060806274, valid_loss= 0.6442314386367798, accuracy= 62.18749999999999\n",
      "Epoch 630: train_loss = 0.6515355706214905, valid_loss= 0.6430566906929016, accuracy= 63.4375\n",
      "Epoch 631: train_loss = 0.641589343547821, valid_loss= 0.6429017186164856, accuracy= 63.4375\n",
      "Epoch 632: train_loss = 0.6452049016952515, valid_loss= 0.6443675756454468, accuracy= 63.125\n",
      "Epoch 633: train_loss = 0.6448400616645813, valid_loss= 0.6451929211616516, accuracy= 62.18749999999999\n",
      "Epoch 634: train_loss = 0.646101176738739, valid_loss= 0.6439156532287598, accuracy= 63.4375\n",
      "Epoch 635: train_loss = 0.6477118730545044, valid_loss= 0.6433667540550232, accuracy= 63.4375\n",
      "Epoch 636: train_loss = 0.6458450555801392, valid_loss= 0.6435266733169556, accuracy= 63.74999999999999\n",
      "Epoch 637: train_loss = 0.6448245644569397, valid_loss= 0.6435999870300293, accuracy= 63.4375\n",
      "Epoch 638: train_loss = 0.6455082893371582, valid_loss= 0.6439188718795776, accuracy= 63.4375\n",
      "Epoch 639: train_loss = 0.6466162800788879, valid_loss= 0.6443087458610535, accuracy= 63.74999999999999\n",
      "Epoch 640: train_loss = 0.650863766670227, valid_loss= 0.6441116333007812, accuracy= 63.125\n",
      "Epoch 641: train_loss = 0.645108699798584, valid_loss= 0.6432971358299255, accuracy= 63.74999999999999\n",
      "Epoch 642: train_loss = 0.643326461315155, valid_loss= 0.6429967880249023, accuracy= 63.74999999999999\n",
      "Epoch 643: train_loss = 0.646451473236084, valid_loss= 0.6436588764190674, accuracy= 62.81250000000001\n",
      "Epoch 644: train_loss = 0.6461876034736633, valid_loss= 0.6433542966842651, accuracy= 62.81250000000001\n",
      "Epoch 645: train_loss = 0.6450424194335938, valid_loss= 0.6431530714035034, accuracy= 63.74999999999999\n",
      "Epoch 646: train_loss = 0.6492780447006226, valid_loss= 0.6432769298553467, accuracy= 63.125\n",
      "Epoch 647: train_loss = 0.6407757997512817, valid_loss= 0.6431671380996704, accuracy= 63.125\n",
      "Epoch 648: train_loss = 0.6479222178459167, valid_loss= 0.6436838507652283, accuracy= 62.5\n",
      "Epoch 649: train_loss = 0.6471961140632629, valid_loss= 0.6432332992553711, accuracy= 62.5\n",
      "Epoch 650: train_loss = 0.6452714204788208, valid_loss= 0.642204225063324, accuracy= 63.74999999999999\n",
      "Epoch 651: train_loss = 0.6412055492401123, valid_loss= 0.64211106300354, accuracy= 63.74999999999999\n",
      "Epoch 652: train_loss = 0.6435224413871765, valid_loss= 0.6421414613723755, accuracy= 63.74999999999999\n",
      "Epoch 653: train_loss = 0.6467417478561401, valid_loss= 0.6421550512313843, accuracy= 63.4375\n",
      "Epoch 654: train_loss = 0.6480402946472168, valid_loss= 0.6415523290634155, accuracy= 63.4375\n",
      "Epoch 655: train_loss = 0.6432483792304993, valid_loss= 0.6414738297462463, accuracy= 63.4375\n",
      "Epoch 656: train_loss = 0.6502363681793213, valid_loss= 0.643417477607727, accuracy= 62.81250000000001\n",
      "Epoch 657: train_loss = 0.6437816619873047, valid_loss= 0.6442832946777344, accuracy= 63.125\n",
      "Epoch 658: train_loss = 0.6434410214424133, valid_loss= 0.6438875198364258, accuracy= 63.74999999999999\n",
      "Epoch 659: train_loss = 0.6459227204322815, valid_loss= 0.6425877809524536, accuracy= 62.5\n",
      "Epoch 660: train_loss = 0.6520602703094482, valid_loss= 0.6410285234451294, accuracy= 63.74999999999999\n",
      "Epoch 661: train_loss = 0.644573986530304, valid_loss= 0.6414426565170288, accuracy= 63.74999999999999\n",
      "Epoch 662: train_loss = 0.6483538746833801, valid_loss= 0.6425794959068298, accuracy= 63.4375\n",
      "Epoch 663: train_loss = 0.6354026794433594, valid_loss= 0.6448809504508972, accuracy= 61.875\n",
      "Epoch 664: train_loss = 0.6424633264541626, valid_loss= 0.646003246307373, accuracy= 61.875\n",
      "Epoch 665: train_loss = 0.6469583511352539, valid_loss= 0.6444631814956665, accuracy= 63.4375\n",
      "Epoch 666: train_loss = 0.6504528522491455, valid_loss= 0.6438038349151611, accuracy= 63.4375\n",
      "Epoch 667: train_loss = 0.6522934436798096, valid_loss= 0.6443375945091248, accuracy= 63.4375\n",
      "Epoch 668: train_loss = 0.6500719785690308, valid_loss= 0.6461613774299622, accuracy= 62.5\n",
      "Epoch 669: train_loss = 0.645585298538208, valid_loss= 0.6466386914253235, accuracy= 62.5\n",
      "Epoch 670: train_loss = 0.6472470760345459, valid_loss= 0.6452306509017944, accuracy= 63.4375\n",
      "Epoch 671: train_loss = 0.6471188068389893, valid_loss= 0.6441777348518372, accuracy= 63.4375\n",
      "Epoch 672: train_loss = 0.6452654004096985, valid_loss= 0.6450386047363281, accuracy= 63.74999999999999\n",
      "Epoch 673: train_loss = 0.6415997743606567, valid_loss= 0.6455942392349243, accuracy= 63.4375\n",
      "Epoch 674: train_loss = 0.6430681347846985, valid_loss= 0.6453338265419006, accuracy= 63.74999999999999\n",
      "Epoch 675: train_loss = 0.6385185122489929, valid_loss= 0.6444129943847656, accuracy= 63.4375\n",
      "Epoch 676: train_loss = 0.6443377137184143, valid_loss= 0.6443973779678345, accuracy= 63.4375\n",
      "Epoch 677: train_loss = 0.6471263766288757, valid_loss= 0.6442655920982361, accuracy= 63.74999999999999\n",
      "Epoch 678: train_loss = 0.6468251943588257, valid_loss= 0.6449355483055115, accuracy= 63.74999999999999\n",
      "Epoch 679: train_loss = 0.6512107849121094, valid_loss= 0.64545077085495, accuracy= 61.875\n",
      "Epoch 680: train_loss = 0.6455747485160828, valid_loss= 0.6445003151893616, accuracy= 61.875\n",
      "Epoch 681: train_loss = 0.6477459073066711, valid_loss= 0.6433110237121582, accuracy= 62.81250000000001\n",
      "Epoch 682: train_loss = 0.6508004665374756, valid_loss= 0.6424053311347961, accuracy= 63.125\n",
      "Epoch 683: train_loss = 0.6490275263786316, valid_loss= 0.6425633430480957, accuracy= 63.4375\n",
      "Epoch 684: train_loss = 0.6432923674583435, valid_loss= 0.6432762742042542, accuracy= 62.81250000000001\n",
      "Epoch 685: train_loss = 0.6497492790222168, valid_loss= 0.6446589827537537, accuracy= 61.5625\n",
      "Epoch 686: train_loss = 0.6508166193962097, valid_loss= 0.6446763277053833, accuracy= 61.875\n",
      "Epoch 687: train_loss = 0.6405293941497803, valid_loss= 0.6441492438316345, accuracy= 61.875\n",
      "Epoch 688: train_loss = 0.6424782872200012, valid_loss= 0.6430585980415344, accuracy= 63.74999999999999\n",
      "Epoch 689: train_loss = 0.649548351764679, valid_loss= 0.6425715088844299, accuracy= 63.74999999999999\n",
      "Epoch 690: train_loss = 0.6445412635803223, valid_loss= 0.6427847146987915, accuracy= 63.74999999999999\n",
      "Epoch 691: train_loss = 0.6450766921043396, valid_loss= 0.6440456509590149, accuracy= 62.81250000000001\n",
      "Epoch 692: train_loss = 0.6410225629806519, valid_loss= 0.6441446542739868, accuracy= 62.81250000000001\n",
      "Epoch 693: train_loss = 0.6409780383110046, valid_loss= 0.6435672044754028, accuracy= 63.125\n",
      "Epoch 694: train_loss = 0.6482704281806946, valid_loss= 0.6428430676460266, accuracy= 63.4375\n",
      "Epoch 695: train_loss = 0.6445749998092651, valid_loss= 0.6422608494758606, accuracy= 63.74999999999999\n",
      "Epoch 696: train_loss = 0.6470436453819275, valid_loss= 0.6424859762191772, accuracy= 63.74999999999999\n",
      "Epoch 697: train_loss = 0.646587610244751, valid_loss= 0.6430641412734985, accuracy= 63.4375\n",
      "Epoch 698: train_loss = 0.6470669507980347, valid_loss= 0.6430186629295349, accuracy= 63.74999999999999\n",
      "Epoch 699: train_loss = 0.6430408358573914, valid_loss= 0.6434265375137329, accuracy= 63.74999999999999\n",
      "Epoch 700: train_loss = 0.6441347599029541, valid_loss= 0.6440078616142273, accuracy= 63.74999999999999\n",
      "Epoch 701: train_loss = 0.6397191286087036, valid_loss= 0.64360511302948, accuracy= 63.4375\n",
      "Epoch 702: train_loss = 0.6365609169006348, valid_loss= 0.6435162425041199, accuracy= 64.0625\n",
      "Epoch 703: train_loss = 0.6426288485527039, valid_loss= 0.6446131467819214, accuracy= 63.4375\n",
      "Epoch 704: train_loss = 0.6376602649688721, valid_loss= 0.6456168293952942, accuracy= 63.74999999999999\n",
      "Epoch 705: train_loss = 0.643779456615448, valid_loss= 0.6449116468429565, accuracy= 63.4375\n",
      "Epoch 706: train_loss = 0.6423632502555847, valid_loss= 0.6442384719848633, accuracy= 63.4375\n",
      "Epoch 707: train_loss = 0.6385557651519775, valid_loss= 0.6435529589653015, accuracy= 63.4375\n",
      "Epoch 708: train_loss = 0.6418811082839966, valid_loss= 0.6438819169998169, accuracy= 63.74999999999999\n",
      "Epoch 709: train_loss = 0.6429604887962341, valid_loss= 0.6447746157646179, accuracy= 63.74999999999999\n",
      "Epoch 710: train_loss = 0.640651524066925, valid_loss= 0.6444453001022339, accuracy= 63.74999999999999\n",
      "Epoch 711: train_loss = 0.6424521207809448, valid_loss= 0.6433281302452087, accuracy= 63.4375\n",
      "Epoch 712: train_loss = 0.6475543975830078, valid_loss= 0.6430950164794922, accuracy= 63.125\n",
      "Epoch 713: train_loss = 0.6443612575531006, valid_loss= 0.6440524458885193, accuracy= 63.4375\n",
      "Epoch 714: train_loss = 0.6395944356918335, valid_loss= 0.6453171968460083, accuracy= 62.5\n",
      "Epoch 715: train_loss = 0.649243950843811, valid_loss= 0.6448212265968323, accuracy= 62.5\n",
      "Epoch 716: train_loss = 0.6406230926513672, valid_loss= 0.643388569355011, accuracy= 63.4375\n",
      "Epoch 717: train_loss = 0.6420741677284241, valid_loss= 0.6425666809082031, accuracy= 63.4375\n",
      "Epoch 718: train_loss = 0.6468523144721985, valid_loss= 0.642618715763092, accuracy= 63.74999999999999\n",
      "Epoch 719: train_loss = 0.6441022157669067, valid_loss= 0.6429123878479004, accuracy= 63.4375\n",
      "Epoch 720: train_loss = 0.6381908059120178, valid_loss= 0.6442380547523499, accuracy= 63.125\n",
      "Epoch 721: train_loss = 0.644524872303009, valid_loss= 0.6442638635635376, accuracy= 62.18749999999999\n",
      "Epoch 722: train_loss = 0.6477547287940979, valid_loss= 0.6422437429428101, accuracy= 63.74999999999999\n",
      "Epoch 723: train_loss = 0.641425371170044, valid_loss= 0.6418571472167969, accuracy= 63.4375\n",
      "Epoch 724: train_loss = 0.6422044038772583, valid_loss= 0.6414424180984497, accuracy= 63.74999999999999\n",
      "Epoch 725: train_loss = 0.642821729183197, valid_loss= 0.6418039798736572, accuracy= 63.4375\n",
      "Epoch 726: train_loss = 0.6463028192520142, valid_loss= 0.6425522565841675, accuracy= 63.125\n",
      "Epoch 727: train_loss = 0.6401558518409729, valid_loss= 0.6423617005348206, accuracy= 63.125\n",
      "Epoch 728: train_loss = 0.6426955461502075, valid_loss= 0.6417697668075562, accuracy= 63.74999999999999\n",
      "Epoch 729: train_loss = 0.6492922306060791, valid_loss= 0.6413944363594055, accuracy= 64.375\n",
      "Epoch 730: train_loss = 0.6414282321929932, valid_loss= 0.6418424844741821, accuracy= 64.6875\n",
      "Epoch 731: train_loss = 0.6423003673553467, valid_loss= 0.6424614787101746, accuracy= 63.74999999999999\n",
      "Epoch 732: train_loss = 0.6411497592926025, valid_loss= 0.6431946158409119, accuracy= 63.4375\n",
      "Epoch 733: train_loss = 0.6486502289772034, valid_loss= 0.6437208652496338, accuracy= 63.125\n",
      "Epoch 734: train_loss = 0.6461877226829529, valid_loss= 0.6436396837234497, accuracy= 63.125\n",
      "Epoch 735: train_loss = 0.6434506773948669, valid_loss= 0.6435714364051819, accuracy= 62.81250000000001\n",
      "Epoch 736: train_loss = 0.6412954330444336, valid_loss= 0.6435583233833313, accuracy= 63.125\n",
      "Epoch 737: train_loss = 0.6396712064743042, valid_loss= 0.6427537202835083, accuracy= 63.74999999999999\n",
      "Epoch 738: train_loss = 0.6398615837097168, valid_loss= 0.643107533454895, accuracy= 63.4375\n",
      "Epoch 739: train_loss = 0.6383305191993713, valid_loss= 0.6442519426345825, accuracy= 63.74999999999999\n",
      "Epoch 740: train_loss = 0.6460585594177246, valid_loss= 0.645208477973938, accuracy= 63.74999999999999\n",
      "Epoch 741: train_loss = 0.6380763053894043, valid_loss= 0.6459229588508606, accuracy= 64.0625\n",
      "Epoch 742: train_loss = 0.6496679186820984, valid_loss= 0.6447780132293701, accuracy= 63.74999999999999\n",
      "Epoch 743: train_loss = 0.6435896158218384, valid_loss= 0.6442245244979858, accuracy= 63.74999999999999\n",
      "Epoch 744: train_loss = 0.6446061134338379, valid_loss= 0.6442885398864746, accuracy= 63.74999999999999\n",
      "Epoch 745: train_loss = 0.6367338299751282, valid_loss= 0.6435441970825195, accuracy= 63.74999999999999\n",
      "Epoch 746: train_loss = 0.6461342573165894, valid_loss= 0.6431142687797546, accuracy= 63.74999999999999\n",
      "Epoch 747: train_loss = 0.6487573981285095, valid_loss= 0.6440041661262512, accuracy= 62.81250000000001\n",
      "Epoch 748: train_loss = 0.6416086554527283, valid_loss= 0.6437288522720337, accuracy= 62.5\n",
      "Epoch 749: train_loss = 0.6427727937698364, valid_loss= 0.6436710357666016, accuracy= 63.125\n",
      "Epoch 750: train_loss = 0.6463746428489685, valid_loss= 0.6433380246162415, accuracy= 63.4375\n",
      "Epoch 751: train_loss = 0.6419698596000671, valid_loss= 0.6441599130630493, accuracy= 63.125\n",
      "Epoch 752: train_loss = 0.6497549414634705, valid_loss= 0.6447710990905762, accuracy= 62.81250000000001\n",
      "Epoch 753: train_loss = 0.6462666988372803, valid_loss= 0.6452793478965759, accuracy= 62.81250000000001\n",
      "Epoch 754: train_loss = 0.6443723440170288, valid_loss= 0.6448061466217041, accuracy= 62.81250000000001\n",
      "Epoch 755: train_loss = 0.6483789682388306, valid_loss= 0.6437180638313293, accuracy= 63.4375\n",
      "Epoch 756: train_loss = 0.6555734872817993, valid_loss= 0.6429396867752075, accuracy= 63.4375\n",
      "Epoch 757: train_loss = 0.6475043296813965, valid_loss= 0.6433249711990356, accuracy= 62.5\n",
      "Epoch 758: train_loss = 0.6400870680809021, valid_loss= 0.6441824436187744, accuracy= 62.81250000000001\n",
      "Epoch 759: train_loss = 0.6420481204986572, valid_loss= 0.6436553001403809, accuracy= 62.5\n",
      "Epoch 760: train_loss = 0.6413726210594177, valid_loss= 0.6438409090042114, accuracy= 62.81250000000001\n",
      "Epoch 761: train_loss = 0.6440126895904541, valid_loss= 0.6437686681747437, accuracy= 64.0625\n",
      "Epoch 762: train_loss = 0.6418691277503967, valid_loss= 0.6450915932655334, accuracy= 62.5\n",
      "Epoch 763: train_loss = 0.6441837549209595, valid_loss= 0.6457503437995911, accuracy= 62.5\n",
      "Epoch 764: train_loss = 0.6346645355224609, valid_loss= 0.6451774835586548, accuracy= 62.81250000000001\n",
      "Epoch 765: train_loss = 0.6384407877922058, valid_loss= 0.6448416709899902, accuracy= 63.125\n",
      "Epoch 766: train_loss = 0.6399758458137512, valid_loss= 0.644741415977478, accuracy= 64.0625\n",
      "Epoch 767: train_loss = 0.6469001770019531, valid_loss= 0.6436957716941833, accuracy= 63.74999999999999\n",
      "Epoch 768: train_loss = 0.6441076993942261, valid_loss= 0.6432740092277527, accuracy= 64.0625\n",
      "Epoch 769: train_loss = 0.644292414188385, valid_loss= 0.6434696912765503, accuracy= 62.81250000000001\n",
      "Epoch 770: train_loss = 0.6395789980888367, valid_loss= 0.6447126865386963, accuracy= 63.125\n",
      "Epoch 771: train_loss = 0.6432698965072632, valid_loss= 0.6455874443054199, accuracy= 61.5625\n",
      "Epoch 772: train_loss = 0.6432346701622009, valid_loss= 0.6447648406028748, accuracy= 63.125\n",
      "Epoch 773: train_loss = 0.6418233513832092, valid_loss= 0.6429100036621094, accuracy= 63.125\n",
      "Epoch 774: train_loss = 0.6450067162513733, valid_loss= 0.6425095200538635, accuracy= 63.125\n",
      "Epoch 775: train_loss = 0.6457001566886902, valid_loss= 0.6430544853210449, accuracy= 62.81250000000001\n",
      "Epoch 776: train_loss = 0.6429036855697632, valid_loss= 0.6432541012763977, accuracy= 62.81250000000001\n",
      "Epoch 777: train_loss = 0.6494998931884766, valid_loss= 0.6439965963363647, accuracy= 62.81250000000001\n",
      "Epoch 778: train_loss = 0.6481569409370422, valid_loss= 0.6437508463859558, accuracy= 63.125\n",
      "Epoch 779: train_loss = 0.6387620568275452, valid_loss= 0.644040048122406, accuracy= 62.81250000000001\n",
      "Epoch 780: train_loss = 0.6472709774971008, valid_loss= 0.6449717283248901, accuracy= 62.18749999999999\n",
      "Epoch 781: train_loss = 0.641306459903717, valid_loss= 0.6436982750892639, accuracy= 62.5\n",
      "Epoch 782: train_loss = 0.6478778123855591, valid_loss= 0.6425176858901978, accuracy= 62.81250000000001\n",
      "Epoch 783: train_loss = 0.6451177597045898, valid_loss= 0.6432883143424988, accuracy= 62.5\n",
      "Epoch 784: train_loss = 0.6381834745407104, valid_loss= 0.6453301310539246, accuracy= 62.18749999999999\n",
      "Epoch 785: train_loss = 0.6438612341880798, valid_loss= 0.6452855467796326, accuracy= 62.5\n",
      "Epoch 786: train_loss = 0.6395914554595947, valid_loss= 0.6449764370918274, accuracy= 62.81250000000001\n",
      "Epoch 787: train_loss = 0.638981819152832, valid_loss= 0.6451059579849243, accuracy= 62.81250000000001\n",
      "Epoch 788: train_loss = 0.6405012011528015, valid_loss= 0.6444370150566101, accuracy= 62.81250000000001\n",
      "Epoch 789: train_loss = 0.6386735439300537, valid_loss= 0.644375205039978, accuracy= 63.125\n",
      "Epoch 790: train_loss = 0.6398199200630188, valid_loss= 0.6450456976890564, accuracy= 62.81250000000001\n",
      "Epoch 791: train_loss = 0.6520199179649353, valid_loss= 0.6444904804229736, accuracy= 62.81250000000001\n",
      "Epoch 792: train_loss = 0.6465765833854675, valid_loss= 0.6439516544342041, accuracy= 62.81250000000001\n",
      "Epoch 793: train_loss = 0.6418028473854065, valid_loss= 0.6424610018730164, accuracy= 62.81250000000001\n",
      "Epoch 794: train_loss = 0.6475414633750916, valid_loss= 0.6415942311286926, accuracy= 63.125\n",
      "Epoch 795: train_loss = 0.6362333297729492, valid_loss= 0.642309844493866, accuracy= 63.125\n",
      "Epoch 796: train_loss = 0.6447960734367371, valid_loss= 0.6442813873291016, accuracy= 63.125\n",
      "Epoch 797: train_loss = 0.6425256133079529, valid_loss= 0.6442626714706421, accuracy= 63.4375\n",
      "Epoch 798: train_loss = 0.6424832344055176, valid_loss= 0.6427561044692993, accuracy= 63.125\n",
      "Epoch 799: train_loss = 0.6459261178970337, valid_loss= 0.6414397358894348, accuracy= 64.0625\n",
      "Epoch 800: train_loss = 0.6424161791801453, valid_loss= 0.642055332660675, accuracy= 62.81250000000001\n",
      "Epoch 801: train_loss = 0.6414892077445984, valid_loss= 0.6439294815063477, accuracy= 63.125\n",
      "Epoch 802: train_loss = 0.6449660658836365, valid_loss= 0.6439851522445679, accuracy= 62.81250000000001\n",
      "Epoch 803: train_loss = 0.6438055634498596, valid_loss= 0.6423625349998474, accuracy= 62.81250000000001\n",
      "Epoch 804: train_loss = 0.6459425091743469, valid_loss= 0.6412409543991089, accuracy= 64.0625\n",
      "Epoch 805: train_loss = 0.6413747072219849, valid_loss= 0.642035186290741, accuracy= 63.125\n",
      "Epoch 806: train_loss = 0.6370263695716858, valid_loss= 0.6419559717178345, accuracy= 63.125\n",
      "Epoch 807: train_loss = 0.644856333732605, valid_loss= 0.6422663927078247, accuracy= 63.4375\n",
      "Epoch 808: train_loss = 0.6551897525787354, valid_loss= 0.6416562795639038, accuracy= 63.125\n",
      "Epoch 809: train_loss = 0.6413986086845398, valid_loss= 0.6419751048088074, accuracy= 63.125\n",
      "Epoch 810: train_loss = 0.6460835933685303, valid_loss= 0.6420010924339294, accuracy= 62.81250000000001\n",
      "Epoch 811: train_loss = 0.6414827108383179, valid_loss= 0.6423665285110474, accuracy= 63.125\n",
      "Epoch 812: train_loss = 0.6454605460166931, valid_loss= 0.6419268250465393, accuracy= 62.81250000000001\n",
      "Epoch 813: train_loss = 0.6434313058853149, valid_loss= 0.6411126255989075, accuracy= 63.125\n",
      "Epoch 814: train_loss = 0.645455539226532, valid_loss= 0.6408733129501343, accuracy= 63.74999999999999\n",
      "Epoch 815: train_loss = 0.6460087895393372, valid_loss= 0.6413351893424988, accuracy= 63.4375\n",
      "Epoch 816: train_loss = 0.6350160837173462, valid_loss= 0.6429866552352905, accuracy= 63.74999999999999\n",
      "Epoch 817: train_loss = 0.6413190364837646, valid_loss= 0.6447868347167969, accuracy= 62.18749999999999\n",
      "Epoch 818: train_loss = 0.6455992460250854, valid_loss= 0.6451156735420227, accuracy= 63.125\n",
      "Epoch 819: train_loss = 0.6383785009384155, valid_loss= 0.6446914672851562, accuracy= 63.4375\n",
      "Epoch 820: train_loss = 0.6442958116531372, valid_loss= 0.6430188417434692, accuracy= 63.74999999999999\n",
      "Epoch 821: train_loss = 0.6349701285362244, valid_loss= 0.6437634229660034, accuracy= 63.74999999999999\n",
      "Epoch 822: train_loss = 0.6433980464935303, valid_loss= 0.6439555883407593, accuracy= 63.74999999999999\n",
      "Epoch 823: train_loss = 0.6440158486366272, valid_loss= 0.6443682909011841, accuracy= 62.81250000000001\n",
      "Epoch 824: train_loss = 0.6466948986053467, valid_loss= 0.6437923312187195, accuracy= 63.125\n",
      "Epoch 825: train_loss = 0.6387545466423035, valid_loss= 0.6438604593276978, accuracy= 63.4375\n",
      "Epoch 826: train_loss = 0.6441271305084229, valid_loss= 0.6446604132652283, accuracy= 64.0625\n",
      "Epoch 827: train_loss = 0.6332632899284363, valid_loss= 0.644877552986145, accuracy= 63.4375\n",
      "Epoch 828: train_loss = 0.6413092017173767, valid_loss= 0.6446180939674377, accuracy= 63.125\n",
      "Epoch 829: train_loss = 0.6384075284004211, valid_loss= 0.64383465051651, accuracy= 63.4375\n",
      "Epoch 830: train_loss = 0.6461139917373657, valid_loss= 0.6432682275772095, accuracy= 63.74999999999999\n",
      "Epoch 831: train_loss = 0.6441082954406738, valid_loss= 0.6436777710914612, accuracy= 62.5\n",
      "Epoch 832: train_loss = 0.64210045337677, valid_loss= 0.644861102104187, accuracy= 61.875\n",
      "Epoch 833: train_loss = 0.64202880859375, valid_loss= 0.6435409188270569, accuracy= 62.5\n",
      "Epoch 834: train_loss = 0.6440421342849731, valid_loss= 0.6426589488983154, accuracy= 62.81250000000001\n",
      "Epoch 835: train_loss = 0.6373764276504517, valid_loss= 0.6426886320114136, accuracy= 62.81250000000001\n",
      "Epoch 836: train_loss = 0.639858067035675, valid_loss= 0.6430221796035767, accuracy= 62.81250000000001\n",
      "Epoch 837: train_loss = 0.6418808698654175, valid_loss= 0.6444324254989624, accuracy= 63.125\n",
      "Epoch 838: train_loss = 0.6430739164352417, valid_loss= 0.6438561081886292, accuracy= 62.81250000000001\n",
      "Epoch 839: train_loss = 0.6432998776435852, valid_loss= 0.6428375244140625, accuracy= 62.81250000000001\n",
      "Epoch 840: train_loss = 0.636193573474884, valid_loss= 0.6431666612625122, accuracy= 62.81250000000001\n",
      "Epoch 841: train_loss = 0.6426475048065186, valid_loss= 0.6423846483230591, accuracy= 63.125\n",
      "Epoch 842: train_loss = 0.6362748146057129, valid_loss= 0.6434051394462585, accuracy= 63.125\n",
      "Epoch 843: train_loss = 0.638827383518219, valid_loss= 0.6431349515914917, accuracy= 62.81250000000001\n",
      "Epoch 844: train_loss = 0.6409116983413696, valid_loss= 0.6425943970680237, accuracy= 63.4375\n",
      "Epoch 845: train_loss = 0.6431751847267151, valid_loss= 0.6426220536231995, accuracy= 63.4375\n",
      "Epoch 846: train_loss = 0.6447242498397827, valid_loss= 0.642511785030365, accuracy= 63.125\n",
      "Epoch 847: train_loss = 0.6401239633560181, valid_loss= 0.6414880752563477, accuracy= 63.125\n",
      "Epoch 848: train_loss = 0.6421699523925781, valid_loss= 0.6414198875427246, accuracy= 63.4375\n",
      "Epoch 849: train_loss = 0.6390905380249023, valid_loss= 0.6413587331771851, accuracy= 63.125\n",
      "Epoch 850: train_loss = 0.6393383741378784, valid_loss= 0.6420283317565918, accuracy= 62.5\n",
      "Epoch 851: train_loss = 0.641526997089386, valid_loss= 0.6409717798233032, accuracy= 63.74999999999999\n",
      "Epoch 852: train_loss = 0.6463057398796082, valid_loss= 0.6412492990493774, accuracy= 62.5\n",
      "Epoch 853: train_loss = 0.6488281488418579, valid_loss= 0.6421345472335815, accuracy= 62.81250000000001\n",
      "Epoch 854: train_loss = 0.6435957551002502, valid_loss= 0.6427804231643677, accuracy= 63.125\n",
      "Epoch 855: train_loss = 0.6407484412193298, valid_loss= 0.6427217125892639, accuracy= 62.81250000000001\n",
      "Epoch 856: train_loss = 0.63932204246521, valid_loss= 0.6423283219337463, accuracy= 62.5\n",
      "Epoch 857: train_loss = 0.6397262215614319, valid_loss= 0.6407562494277954, accuracy= 63.74999999999999\n",
      "Epoch 858: train_loss = 0.6422143578529358, valid_loss= 0.6400666236877441, accuracy= 63.74999999999999\n",
      "Epoch 859: train_loss = 0.6366302967071533, valid_loss= 0.6417024731636047, accuracy= 63.125\n",
      "Epoch 860: train_loss = 0.636695146560669, valid_loss= 0.6430369019508362, accuracy= 62.5\n",
      "Epoch 861: train_loss = 0.6410052180290222, valid_loss= 0.6435778141021729, accuracy= 62.5\n",
      "Epoch 862: train_loss = 0.6401174068450928, valid_loss= 0.6422910690307617, accuracy= 62.81250000000001\n",
      "Epoch 863: train_loss = 0.6400298476219177, valid_loss= 0.6426298022270203, accuracy= 62.5\n",
      "Epoch 864: train_loss = 0.6375478506088257, valid_loss= 0.6422898173332214, accuracy= 62.5\n",
      "Epoch 865: train_loss = 0.6465802192687988, valid_loss= 0.6413955688476562, accuracy= 62.81250000000001\n",
      "Epoch 866: train_loss = 0.6388688087463379, valid_loss= 0.6408020257949829, accuracy= 62.81250000000001\n",
      "Epoch 867: train_loss = 0.6413893699645996, valid_loss= 0.6397076845169067, accuracy= 63.125\n",
      "Epoch 868: train_loss = 0.6485560536384583, valid_loss= 0.6392871141433716, accuracy= 62.81250000000001\n",
      "Epoch 869: train_loss = 0.6375207304954529, valid_loss= 0.6389581561088562, accuracy= 62.81250000000001\n",
      "Epoch 870: train_loss = 0.6380329728126526, valid_loss= 0.6394913792610168, accuracy= 62.18749999999999\n",
      "Epoch 871: train_loss = 0.6453524231910706, valid_loss= 0.6405444145202637, accuracy= 62.81250000000001\n",
      "Epoch 872: train_loss = 0.6461637020111084, valid_loss= 0.6418497562408447, accuracy= 63.125\n",
      "Epoch 873: train_loss = 0.634044349193573, valid_loss= 0.6419111490249634, accuracy= 62.81250000000001\n",
      "Epoch 874: train_loss = 0.638917863368988, valid_loss= 0.6415635943412781, accuracy= 62.81250000000001\n",
      "Epoch 875: train_loss = 0.6407986283302307, valid_loss= 0.640674889087677, accuracy= 64.0625\n",
      "Epoch 876: train_loss = 0.639908492565155, valid_loss= 0.6415536999702454, accuracy= 64.0625\n",
      "Epoch 877: train_loss = 0.6423128247261047, valid_loss= 0.6413387060165405, accuracy= 63.74999999999999\n",
      "Epoch 878: train_loss = 0.6489808559417725, valid_loss= 0.6429280042648315, accuracy= 62.5\n",
      "Epoch 879: train_loss = 0.6372260451316833, valid_loss= 0.6443793773651123, accuracy= 62.81250000000001\n",
      "Epoch 880: train_loss = 0.646321177482605, valid_loss= 0.6431720852851868, accuracy= 62.5\n",
      "Epoch 881: train_loss = 0.6421225666999817, valid_loss= 0.6419280767440796, accuracy= 62.81250000000001\n",
      "Epoch 882: train_loss = 0.6343470215797424, valid_loss= 0.6417689323425293, accuracy= 63.125\n",
      "Epoch 883: train_loss = 0.6384386420249939, valid_loss= 0.6424809694290161, accuracy= 63.125\n",
      "Epoch 884: train_loss = 0.6419049501419067, valid_loss= 0.6430633068084717, accuracy= 62.81250000000001\n",
      "Epoch 885: train_loss = 0.6354420185089111, valid_loss= 0.6418907642364502, accuracy= 63.4375\n",
      "Epoch 886: train_loss = 0.6377866268157959, valid_loss= 0.6417578458786011, accuracy= 64.0625\n",
      "Epoch 887: train_loss = 0.6320868730545044, valid_loss= 0.6419334411621094, accuracy= 64.0625\n",
      "Epoch 888: train_loss = 0.6344570517539978, valid_loss= 0.6412914991378784, accuracy= 64.0625\n",
      "Epoch 889: train_loss = 0.6411164999008179, valid_loss= 0.6422568559646606, accuracy= 63.74999999999999\n",
      "Epoch 890: train_loss = 0.6431699395179749, valid_loss= 0.6428804397583008, accuracy= 63.4375\n",
      "Epoch 891: train_loss = 0.6400192975997925, valid_loss= 0.6413031816482544, accuracy= 63.125\n",
      "Epoch 892: train_loss = 0.6375536322593689, valid_loss= 0.6399449706077576, accuracy= 63.74999999999999\n",
      "Epoch 893: train_loss = 0.6385253667831421, valid_loss= 0.6397626996040344, accuracy= 63.74999999999999\n",
      "Epoch 894: train_loss = 0.6393980979919434, valid_loss= 0.6404055953025818, accuracy= 63.4375\n",
      "Epoch 895: train_loss = 0.6455866694450378, valid_loss= 0.6405171155929565, accuracy= 63.74999999999999\n",
      "Epoch 896: train_loss = 0.6391990780830383, valid_loss= 0.6403783559799194, accuracy= 63.74999999999999\n",
      "Epoch 897: train_loss = 0.6495106220245361, valid_loss= 0.6400479674339294, accuracy= 63.74999999999999\n",
      "Epoch 898: train_loss = 0.6410477161407471, valid_loss= 0.6406482458114624, accuracy= 63.74999999999999\n",
      "Epoch 899: train_loss = 0.6397515535354614, valid_loss= 0.640503466129303, accuracy= 63.74999999999999\n",
      "Epoch 900: train_loss = 0.6403554081916809, valid_loss= 0.6415225267410278, accuracy= 62.5\n",
      "Epoch 901: train_loss = 0.6443714499473572, valid_loss= 0.6425898671150208, accuracy= 62.81250000000001\n",
      "Epoch 902: train_loss = 0.6354491114616394, valid_loss= 0.6425132155418396, accuracy= 62.81250000000001\n",
      "Epoch 903: train_loss = 0.643913984298706, valid_loss= 0.6415565609931946, accuracy= 62.81250000000001\n",
      "Epoch 904: train_loss = 0.6357051730155945, valid_loss= 0.6410514116287231, accuracy= 63.74999999999999\n",
      "Epoch 905: train_loss = 0.6355005502700806, valid_loss= 0.6419469118118286, accuracy= 62.81250000000001\n",
      "Epoch 906: train_loss = 0.6373597383499146, valid_loss= 0.6418112516403198, accuracy= 63.74999999999999\n",
      "Epoch 907: train_loss = 0.6378036737442017, valid_loss= 0.6429394483566284, accuracy= 62.5\n",
      "Epoch 908: train_loss = 0.6464848518371582, valid_loss= 0.6434043049812317, accuracy= 62.18749999999999\n",
      "Epoch 909: train_loss = 0.64154052734375, valid_loss= 0.6419347524642944, accuracy= 63.74999999999999\n",
      "Epoch 910: train_loss = 0.6432380080223083, valid_loss= 0.6406887769699097, accuracy= 63.74999999999999\n",
      "Epoch 911: train_loss = 0.6433799862861633, valid_loss= 0.6400283575057983, accuracy= 63.4375\n",
      "Epoch 912: train_loss = 0.6395884156227112, valid_loss= 0.6395903825759888, accuracy= 62.81250000000001\n",
      "Epoch 913: train_loss = 0.6399033665657043, valid_loss= 0.6406088471412659, accuracy= 64.375\n",
      "Epoch 914: train_loss = 0.6445463299751282, valid_loss= 0.6399616003036499, accuracy= 64.375\n",
      "Epoch 915: train_loss = 0.644059956073761, valid_loss= 0.6392823457717896, accuracy= 63.74999999999999\n",
      "Epoch 916: train_loss = 0.6419652104377747, valid_loss= 0.6395024061203003, accuracy= 63.125\n",
      "Epoch 917: train_loss = 0.6409813165664673, valid_loss= 0.641043484210968, accuracy= 62.81250000000001\n",
      "Epoch 918: train_loss = 0.637135922908783, valid_loss= 0.6415068507194519, accuracy= 62.18749999999999\n",
      "Epoch 919: train_loss = 0.6441895961761475, valid_loss= 0.6422799825668335, accuracy= 62.18749999999999\n",
      "Epoch 920: train_loss = 0.6449230313301086, valid_loss= 0.6411990523338318, accuracy= 63.74999999999999\n",
      "Epoch 921: train_loss = 0.6397825479507446, valid_loss= 0.6407607197761536, accuracy= 62.81250000000001\n",
      "Epoch 922: train_loss = 0.6436482071876526, valid_loss= 0.640734076499939, accuracy= 63.125\n",
      "Epoch 923: train_loss = 0.6423007249832153, valid_loss= 0.6414593458175659, accuracy= 62.5\n",
      "Epoch 924: train_loss = 0.6380773186683655, valid_loss= 0.6406995058059692, accuracy= 62.81250000000001\n",
      "Epoch 925: train_loss = 0.6396118402481079, valid_loss= 0.640434205532074, accuracy= 63.125\n",
      "Epoch 926: train_loss = 0.6462567448616028, valid_loss= 0.6401332020759583, accuracy= 63.4375\n",
      "Epoch 927: train_loss = 0.6412754654884338, valid_loss= 0.6404194831848145, accuracy= 63.74999999999999\n",
      "Epoch 928: train_loss = 0.6404700875282288, valid_loss= 0.640972912311554, accuracy= 63.125\n",
      "Epoch 929: train_loss = 0.6371519565582275, valid_loss= 0.6420238614082336, accuracy= 63.4375\n",
      "Epoch 930: train_loss = 0.6453442573547363, valid_loss= 0.6432662010192871, accuracy= 62.18749999999999\n",
      "Epoch 931: train_loss = 0.6375764608383179, valid_loss= 0.64205002784729, accuracy= 64.0625\n",
      "Epoch 932: train_loss = 0.6466475129127502, valid_loss= 0.6408001780509949, accuracy= 63.74999999999999\n",
      "Epoch 933: train_loss = 0.6377321481704712, valid_loss= 0.6402373313903809, accuracy= 63.74999999999999\n",
      "Epoch 934: train_loss = 0.6462618112564087, valid_loss= 0.6393565535545349, accuracy= 63.4375\n",
      "Epoch 935: train_loss = 0.6455681920051575, valid_loss= 0.6398574709892273, accuracy= 63.74999999999999\n",
      "Epoch 936: train_loss = 0.642934262752533, valid_loss= 0.639790952205658, accuracy= 63.125\n",
      "Epoch 937: train_loss = 0.6402702331542969, valid_loss= 0.639876663684845, accuracy= 62.18749999999999\n",
      "Epoch 938: train_loss = 0.6351597905158997, valid_loss= 0.6396706700325012, accuracy= 62.5\n",
      "Epoch 939: train_loss = 0.6433121562004089, valid_loss= 0.639736533164978, accuracy= 63.74999999999999\n",
      "Epoch 940: train_loss = 0.6409934163093567, valid_loss= 0.641025722026825, accuracy= 63.125\n",
      "Epoch 941: train_loss = 0.6435868740081787, valid_loss= 0.6394329071044922, accuracy= 63.74999999999999\n",
      "Epoch 942: train_loss = 0.637706995010376, valid_loss= 0.6376392245292664, accuracy= 64.0625\n",
      "Epoch 943: train_loss = 0.6372397541999817, valid_loss= 0.6381009817123413, accuracy= 64.0625\n",
      "Epoch 944: train_loss = 0.6405766010284424, valid_loss= 0.6403271555900574, accuracy= 63.4375\n",
      "Epoch 945: train_loss = 0.6371317505836487, valid_loss= 0.6423481106758118, accuracy= 63.4375\n",
      "Epoch 946: train_loss = 0.6468102931976318, valid_loss= 0.6414068937301636, accuracy= 64.375\n",
      "Epoch 947: train_loss = 0.6411464214324951, valid_loss= 0.6389366984367371, accuracy= 63.74999999999999\n",
      "Epoch 948: train_loss = 0.641563355922699, valid_loss= 0.6384254693984985, accuracy= 63.74999999999999\n",
      "Epoch 949: train_loss = 0.6376845836639404, valid_loss= 0.6396318674087524, accuracy= 63.74999999999999\n",
      "Epoch 950: train_loss = 0.6422955393791199, valid_loss= 0.639975368976593, accuracy= 64.375\n",
      "Epoch 951: train_loss = 0.6341963410377502, valid_loss= 0.6392866373062134, accuracy= 63.74999999999999\n",
      "Epoch 952: train_loss = 0.6370077729225159, valid_loss= 0.638640284538269, accuracy= 63.4375\n",
      "Epoch 953: train_loss = 0.6382306814193726, valid_loss= 0.6392451524734497, accuracy= 64.0625\n",
      "Epoch 954: train_loss = 0.6392315626144409, valid_loss= 0.6392236351966858, accuracy= 63.74999999999999\n",
      "Epoch 955: train_loss = 0.6363518834114075, valid_loss= 0.6409421563148499, accuracy= 62.5\n",
      "Epoch 956: train_loss = 0.6429650783538818, valid_loss= 0.6413501501083374, accuracy= 62.81250000000001\n",
      "Epoch 957: train_loss = 0.6407081484794617, valid_loss= 0.6408690214157104, accuracy= 62.5\n",
      "Epoch 958: train_loss = 0.6316256523132324, valid_loss= 0.6397359371185303, accuracy= 62.81250000000001\n",
      "Epoch 959: train_loss = 0.6402239799499512, valid_loss= 0.6390112638473511, accuracy= 64.0625\n",
      "Epoch 960: train_loss = 0.6366604566574097, valid_loss= 0.6386827230453491, accuracy= 63.4375\n",
      "Epoch 961: train_loss = 0.641244649887085, valid_loss= 0.6381285190582275, accuracy= 63.74999999999999\n",
      "Epoch 962: train_loss = 0.6385594606399536, valid_loss= 0.6377567052841187, accuracy= 63.74999999999999\n",
      "Epoch 963: train_loss = 0.6358909010887146, valid_loss= 0.6378827095031738, accuracy= 62.81250000000001\n",
      "Epoch 964: train_loss = 0.6360018849372864, valid_loss= 0.6372551918029785, accuracy= 63.4375\n",
      "Epoch 965: train_loss = 0.6362774968147278, valid_loss= 0.6369385719299316, accuracy= 63.125\n",
      "Epoch 966: train_loss = 0.6390290856361389, valid_loss= 0.636416494846344, accuracy= 63.125\n",
      "Epoch 967: train_loss = 0.6477381587028503, valid_loss= 0.6356774568557739, accuracy= 63.4375\n",
      "Epoch 968: train_loss = 0.6365554332733154, valid_loss= 0.6359736919403076, accuracy= 63.74999999999999\n",
      "Epoch 969: train_loss = 0.6417216062545776, valid_loss= 0.6364544630050659, accuracy= 63.125\n",
      "Epoch 970: train_loss = 0.6416893005371094, valid_loss= 0.6368026733398438, accuracy= 62.5\n",
      "Epoch 971: train_loss = 0.6355735659599304, valid_loss= 0.6373196244239807, accuracy= 62.5\n",
      "Epoch 972: train_loss = 0.6417640447616577, valid_loss= 0.6371731162071228, accuracy= 63.125\n",
      "Epoch 973: train_loss = 0.636579692363739, valid_loss= 0.6373904347419739, accuracy= 63.4375\n",
      "Epoch 974: train_loss = 0.6359708309173584, valid_loss= 0.6385061144828796, accuracy= 62.5\n",
      "Epoch 975: train_loss = 0.636532187461853, valid_loss= 0.6407989859580994, accuracy= 63.125\n",
      "Epoch 976: train_loss = 0.6327400803565979, valid_loss= 0.6404861807823181, accuracy= 62.81250000000001\n",
      "Epoch 977: train_loss = 0.6315056085586548, valid_loss= 0.6384239792823792, accuracy= 62.81250000000001\n",
      "Epoch 978: train_loss = 0.6399317979812622, valid_loss= 0.6372660398483276, accuracy= 63.74999999999999\n",
      "Epoch 979: train_loss = 0.6385077834129333, valid_loss= 0.636910617351532, accuracy= 64.0625\n",
      "Epoch 980: train_loss = 0.6333171725273132, valid_loss= 0.6375116109848022, accuracy= 62.81250000000001\n",
      "Epoch 981: train_loss = 0.6459499001502991, valid_loss= 0.6379920840263367, accuracy= 62.5\n",
      "Epoch 982: train_loss = 0.6326242685317993, valid_loss= 0.6385601758956909, accuracy= 62.18749999999999\n",
      "Epoch 983: train_loss = 0.6372938752174377, valid_loss= 0.6388000249862671, accuracy= 62.18749999999999\n",
      "Epoch 984: train_loss = 0.6332759857177734, valid_loss= 0.6379522085189819, accuracy= 62.81250000000001\n",
      "Epoch 985: train_loss = 0.6437941789627075, valid_loss= 0.6374056339263916, accuracy= 65.0\n",
      "Epoch 986: train_loss = 0.6399416923522949, valid_loss= 0.6384056806564331, accuracy= 62.5\n",
      "Epoch 987: train_loss = 0.6379355192184448, valid_loss= 0.6401957273483276, accuracy= 62.18749999999999\n",
      "Epoch 988: train_loss = 0.6376715898513794, valid_loss= 0.640028178691864, accuracy= 62.18749999999999\n",
      "Epoch 989: train_loss = 0.6381556987762451, valid_loss= 0.6373786926269531, accuracy= 61.5625\n",
      "Epoch 990: train_loss = 0.6317962408065796, valid_loss= 0.6362603902816772, accuracy= 63.74999999999999\n",
      "Epoch 991: train_loss = 0.6378312706947327, valid_loss= 0.636773943901062, accuracy= 62.5\n",
      "Epoch 992: train_loss = 0.6380999684333801, valid_loss= 0.6389974355697632, accuracy= 62.5\n",
      "Epoch 993: train_loss = 0.634369432926178, valid_loss= 0.6395220756530762, accuracy= 62.5\n",
      "Epoch 994: train_loss = 0.6336485147476196, valid_loss= 0.6391445994377136, accuracy= 62.5\n",
      "Epoch 995: train_loss = 0.6348314881324768, valid_loss= 0.6379445791244507, accuracy= 64.375\n",
      "Epoch 996: train_loss = 0.6398957967758179, valid_loss= 0.637525200843811, accuracy= 65.3125\n",
      "Epoch 997: train_loss = 0.636485755443573, valid_loss= 0.6380615234375, accuracy= 65.3125\n",
      "Epoch 998: train_loss = 0.6364279389381409, valid_loss= 0.6400220990180969, accuracy= 63.125\n",
      "Epoch 999: train_loss = 0.6403177380561829, valid_loss= 0.6415683031082153, accuracy= 61.5625\n",
      "Epoch 1000: train_loss = 0.6320899724960327, valid_loss= 0.6401588916778564, accuracy= 62.81250000000001\n",
      "Epoch 1001: train_loss = 0.636165976524353, valid_loss= 0.6386510133743286, accuracy= 64.0625\n",
      "Epoch 1002: train_loss = 0.6375816464424133, valid_loss= 0.6370061039924622, accuracy= 64.6875\n",
      "Epoch 1003: train_loss = 0.637393593788147, valid_loss= 0.6369001269340515, accuracy= 65.0\n",
      "Epoch 1004: train_loss = 0.6359383463859558, valid_loss= 0.6387083530426025, accuracy= 63.74999999999999\n",
      "Epoch 1005: train_loss = 0.6406105756759644, valid_loss= 0.6394620537757874, accuracy= 63.125\n",
      "Epoch 1006: train_loss = 0.6301285028457642, valid_loss= 0.6383488774299622, accuracy= 63.125\n",
      "Epoch 1007: train_loss = 0.633114218711853, valid_loss= 0.6364200115203857, accuracy= 65.625\n",
      "Epoch 1008: train_loss = 0.6430583596229553, valid_loss= 0.6346606612205505, accuracy= 65.3125\n",
      "Epoch 1009: train_loss = 0.644505500793457, valid_loss= 0.6352420449256897, accuracy= 64.375\n",
      "Epoch 1010: train_loss = 0.6349496841430664, valid_loss= 0.6361183524131775, accuracy= 62.5\n",
      "Epoch 1011: train_loss = 0.6405746936798096, valid_loss= 0.6357764005661011, accuracy= 62.5\n",
      "Epoch 1012: train_loss = 0.6349535584449768, valid_loss= 0.6347618103027344, accuracy= 64.0625\n",
      "Epoch 1013: train_loss = 0.6395550966262817, valid_loss= 0.6343852281570435, accuracy= 64.0625\n",
      "Epoch 1014: train_loss = 0.6390700936317444, valid_loss= 0.6355761289596558, accuracy= 63.4375\n",
      "Epoch 1015: train_loss = 0.6382731795310974, valid_loss= 0.6373373866081238, accuracy= 62.18749999999999\n",
      "Epoch 1016: train_loss = 0.6353674530982971, valid_loss= 0.637239396572113, accuracy= 63.125\n",
      "Epoch 1017: train_loss = 0.6389788389205933, valid_loss= 0.635757565498352, accuracy= 63.74999999999999\n",
      "Epoch 1018: train_loss = 0.6398859620094299, valid_loss= 0.6345470547676086, accuracy= 63.74999999999999\n",
      "Epoch 1019: train_loss = 0.6358195543289185, valid_loss= 0.634341299533844, accuracy= 64.0625\n",
      "Epoch 1020: train_loss = 0.6355106234550476, valid_loss= 0.6353939175605774, accuracy= 63.125\n",
      "Epoch 1021: train_loss = 0.6341262459754944, valid_loss= 0.6363235712051392, accuracy= 64.0625\n",
      "Epoch 1022: train_loss = 0.6361064910888672, valid_loss= 0.6358929872512817, accuracy= 64.375\n",
      "Epoch 1023: train_loss = 0.6339746713638306, valid_loss= 0.6349407434463501, accuracy= 64.0625\n",
      "Epoch 1024: train_loss = 0.6444256901741028, valid_loss= 0.6351402997970581, accuracy= 63.74999999999999\n",
      "Epoch 1025: train_loss = 0.6383131146430969, valid_loss= 0.6367011666297913, accuracy= 64.0625\n",
      "Epoch 1026: train_loss = 0.6391862034797668, valid_loss= 0.6370705366134644, accuracy= 64.0625\n",
      "Epoch 1027: train_loss = 0.6349655985832214, valid_loss= 0.6369789838790894, accuracy= 64.0625\n",
      "Epoch 1028: train_loss = 0.6389991641044617, valid_loss= 0.6367126703262329, accuracy= 63.4375\n",
      "Epoch 1029: train_loss = 0.6330452561378479, valid_loss= 0.636574923992157, accuracy= 63.4375\n",
      "Epoch 1030: train_loss = 0.6414600014686584, valid_loss= 0.6367820501327515, accuracy= 63.4375\n",
      "Epoch 1031: train_loss = 0.6402591466903687, valid_loss= 0.6362449526786804, accuracy= 63.125\n",
      "Epoch 1032: train_loss = 0.6396390199661255, valid_loss= 0.6360026597976685, accuracy= 64.0625\n",
      "Epoch 1033: train_loss = 0.6411833763122559, valid_loss= 0.6347947716712952, accuracy= 63.4375\n",
      "Epoch 1034: train_loss = 0.6384410858154297, valid_loss= 0.6355777382850647, accuracy= 63.4375\n",
      "Epoch 1035: train_loss = 0.6379760503768921, valid_loss= 0.6366655230522156, accuracy= 62.5\n",
      "Epoch 1036: train_loss = 0.6380939483642578, valid_loss= 0.6360200047492981, accuracy= 61.5625\n",
      "Epoch 1037: train_loss = 0.6430222988128662, valid_loss= 0.6352285146713257, accuracy= 62.81250000000001\n",
      "Epoch 1038: train_loss = 0.6394701600074768, valid_loss= 0.6352916359901428, accuracy= 63.4375\n",
      "Epoch 1039: train_loss = 0.630466639995575, valid_loss= 0.6365489363670349, accuracy= 62.18749999999999\n",
      "Epoch 1040: train_loss = 0.6308326721191406, valid_loss= 0.6378331184387207, accuracy= 62.18749999999999\n",
      "Epoch 1041: train_loss = 0.6408867239952087, valid_loss= 0.6370867490768433, accuracy= 65.3125\n",
      "Epoch 1042: train_loss = 0.633239209651947, valid_loss= 0.635324239730835, accuracy= 64.375\n",
      "Epoch 1043: train_loss = 0.6410260200500488, valid_loss= 0.6351694464683533, accuracy= 64.6875\n",
      "Epoch 1044: train_loss = 0.6351378560066223, valid_loss= 0.635536789894104, accuracy= 65.3125\n",
      "Epoch 1045: train_loss = 0.6456229090690613, valid_loss= 0.6354654431343079, accuracy= 64.6875\n",
      "Epoch 1046: train_loss = 0.6379824280738831, valid_loss= 0.6363471746444702, accuracy= 62.5\n",
      "Epoch 1047: train_loss = 0.6327399611473083, valid_loss= 0.6370691657066345, accuracy= 62.18749999999999\n",
      "Epoch 1048: train_loss = 0.6310910582542419, valid_loss= 0.6372159123420715, accuracy= 62.18749999999999\n",
      "Epoch 1049: train_loss = 0.6414121389389038, valid_loss= 0.6358555555343628, accuracy= 65.3125\n",
      "Epoch 1050: train_loss = 0.6372265815734863, valid_loss= 0.6353995203971863, accuracy= 65.0\n",
      "Epoch 1051: train_loss = 0.6329971551895142, valid_loss= 0.6355169415473938, accuracy= 65.9375\n",
      "Epoch 1052: train_loss = 0.6343176364898682, valid_loss= 0.6367994546890259, accuracy= 63.74999999999999\n",
      "Epoch 1053: train_loss = 0.6339038610458374, valid_loss= 0.6374480128288269, accuracy= 62.5\n",
      "Epoch 1054: train_loss = 0.638293981552124, valid_loss= 0.6372672915458679, accuracy= 62.5\n",
      "Epoch 1055: train_loss = 0.6342245936393738, valid_loss= 0.6334885358810425, accuracy= 63.74999999999999\n",
      "Epoch 1056: train_loss = 0.6366797089576721, valid_loss= 0.6326397657394409, accuracy= 64.0625\n",
      "Epoch 1057: train_loss = 0.6390587091445923, valid_loss= 0.6338440775871277, accuracy= 64.375\n",
      "Epoch 1058: train_loss = 0.6341290473937988, valid_loss= 0.6352413296699524, accuracy= 64.0625\n",
      "Epoch 1059: train_loss = 0.6322539448738098, valid_loss= 0.6349993348121643, accuracy= 63.4375\n",
      "Epoch 1060: train_loss = 0.630990207195282, valid_loss= 0.6344490051269531, accuracy= 63.4375\n",
      "Epoch 1061: train_loss = 0.6385044455528259, valid_loss= 0.6343914270401001, accuracy= 63.4375\n",
      "Epoch 1062: train_loss = 0.6425212025642395, valid_loss= 0.6345824003219604, accuracy= 63.125\n",
      "Epoch 1063: train_loss = 0.6387771368026733, valid_loss= 0.6361857056617737, accuracy= 63.74999999999999\n",
      "Epoch 1064: train_loss = 0.636354923248291, valid_loss= 0.6377111673355103, accuracy= 63.4375\n",
      "Epoch 1065: train_loss = 0.6333366632461548, valid_loss= 0.6368286609649658, accuracy= 63.74999999999999\n",
      "Epoch 1066: train_loss = 0.6300180554389954, valid_loss= 0.6366428136825562, accuracy= 63.74999999999999\n",
      "Epoch 1067: train_loss = 0.6313957571983337, valid_loss= 0.635667622089386, accuracy= 63.74999999999999\n",
      "Epoch 1068: train_loss = 0.6353629231452942, valid_loss= 0.6368069648742676, accuracy= 63.125\n",
      "Epoch 1069: train_loss = 0.6391059756278992, valid_loss= 0.6375692486763, accuracy= 63.4375\n",
      "Epoch 1070: train_loss = 0.6374314427375793, valid_loss= 0.6377435326576233, accuracy= 63.4375\n",
      "Epoch 1071: train_loss = 0.6354439854621887, valid_loss= 0.6375490427017212, accuracy= 62.5\n",
      "Epoch 1072: train_loss = 0.6442905068397522, valid_loss= 0.6360564827919006, accuracy= 63.74999999999999\n",
      "Epoch 1073: train_loss = 0.6323879957199097, valid_loss= 0.6350291967391968, accuracy= 64.375\n",
      "Epoch 1074: train_loss = 0.6258719563484192, valid_loss= 0.6351109743118286, accuracy= 63.4375\n",
      "Epoch 1075: train_loss = 0.6367532014846802, valid_loss= 0.6344641447067261, accuracy= 63.74999999999999\n",
      "Epoch 1076: train_loss = 0.6372716426849365, valid_loss= 0.634913980960846, accuracy= 63.4375\n",
      "Epoch 1077: train_loss = 0.6302793025970459, valid_loss= 0.6358203291893005, accuracy= 63.4375\n",
      "Epoch 1078: train_loss = 0.6326258778572083, valid_loss= 0.6365469694137573, accuracy= 63.74999999999999\n",
      "Epoch 1079: train_loss = 0.6389067769050598, valid_loss= 0.6364394426345825, accuracy= 63.74999999999999\n",
      "Epoch 1080: train_loss = 0.6347983479499817, valid_loss= 0.6357237696647644, accuracy= 64.6875\n",
      "Epoch 1081: train_loss = 0.6346113085746765, valid_loss= 0.63493812084198, accuracy= 65.9375\n",
      "Epoch 1082: train_loss = 0.6375726461410522, valid_loss= 0.6345189809799194, accuracy= 65.9375\n",
      "Epoch 1083: train_loss = 0.6368891596794128, valid_loss= 0.6339614987373352, accuracy= 65.9375\n",
      "Epoch 1084: train_loss = 0.6339941620826721, valid_loss= 0.6348159909248352, accuracy= 64.375\n",
      "Epoch 1085: train_loss = 0.62997967004776, valid_loss= 0.6346227526664734, accuracy= 64.6875\n",
      "Epoch 1086: train_loss = 0.6407273411750793, valid_loss= 0.6339813470840454, accuracy= 65.625\n",
      "Epoch 1087: train_loss = 0.6326920986175537, valid_loss= 0.6340290904045105, accuracy= 65.9375\n",
      "Epoch 1088: train_loss = 0.632609486579895, valid_loss= 0.6335553526878357, accuracy= 65.3125\n",
      "Epoch 1089: train_loss = 0.6409477591514587, valid_loss= 0.6340938806533813, accuracy= 65.0\n",
      "Epoch 1090: train_loss = 0.6295889019966125, valid_loss= 0.6353273391723633, accuracy= 64.6875\n",
      "Epoch 1091: train_loss = 0.642919659614563, valid_loss= 0.6362440586090088, accuracy= 65.3125\n",
      "Epoch 1092: train_loss = 0.6355752944946289, valid_loss= 0.637148380279541, accuracy= 65.9375\n",
      "Epoch 1093: train_loss = 0.6306005120277405, valid_loss= 0.6361016631126404, accuracy= 65.0\n",
      "Epoch 1094: train_loss = 0.640354335308075, valid_loss= 0.6347137689590454, accuracy= 65.3125\n",
      "Epoch 1095: train_loss = 0.6396303176879883, valid_loss= 0.6339215040206909, accuracy= 65.625\n",
      "Epoch 1096: train_loss = 0.6377639174461365, valid_loss= 0.6350067853927612, accuracy= 64.375\n",
      "Epoch 1097: train_loss = 0.6394444108009338, valid_loss= 0.6356356143951416, accuracy= 66.5625\n",
      "Epoch 1098: train_loss = 0.6380211710929871, valid_loss= 0.6343566179275513, accuracy= 65.625\n",
      "Epoch 1099: train_loss = 0.6332453489303589, valid_loss= 0.6333572864532471, accuracy= 65.625\n",
      "Epoch 1100: train_loss = 0.6297788023948669, valid_loss= 0.6333701014518738, accuracy= 65.625\n",
      "Epoch 1101: train_loss = 0.63467937707901, valid_loss= 0.6326693296432495, accuracy= 65.3125\n",
      "Epoch 1102: train_loss = 0.6386923789978027, valid_loss= 0.6335602402687073, accuracy= 65.3125\n",
      "Epoch 1103: train_loss = 0.6443041563034058, valid_loss= 0.63413405418396, accuracy= 65.9375\n",
      "Epoch 1104: train_loss = 0.6288460493087769, valid_loss= 0.6342822909355164, accuracy= 65.625\n",
      "Epoch 1105: train_loss = 0.6392128467559814, valid_loss= 0.6343809962272644, accuracy= 65.3125\n",
      "Epoch 1106: train_loss = 0.6361123919487, valid_loss= 0.6336182355880737, accuracy= 65.625\n",
      "Epoch 1107: train_loss = 0.6297191381454468, valid_loss= 0.6330094337463379, accuracy= 65.3125\n",
      "Epoch 1108: train_loss = 0.6299880146980286, valid_loss= 0.6339067220687866, accuracy= 66.25\n",
      "Epoch 1109: train_loss = 0.6292111277580261, valid_loss= 0.6358370184898376, accuracy= 64.6875\n",
      "Epoch 1110: train_loss = 0.6231549382209778, valid_loss= 0.6362817287445068, accuracy= 65.625\n",
      "Epoch 1111: train_loss = 0.637441098690033, valid_loss= 0.6341199278831482, accuracy= 65.0\n",
      "Epoch 1112: train_loss = 0.6385225057601929, valid_loss= 0.6323086023330688, accuracy= 65.3125\n",
      "Epoch 1113: train_loss = 0.6363343596458435, valid_loss= 0.6315754652023315, accuracy= 65.3125\n",
      "Epoch 1114: train_loss = 0.6280600428581238, valid_loss= 0.634411633014679, accuracy= 64.6875\n",
      "Epoch 1115: train_loss = 0.6423556804656982, valid_loss= 0.6352673172950745, accuracy= 64.0625\n",
      "Epoch 1116: train_loss = 0.6291373372077942, valid_loss= 0.6342415809631348, accuracy= 64.375\n",
      "Epoch 1117: train_loss = 0.6389365196228027, valid_loss= 0.6330129504203796, accuracy= 65.625\n",
      "Epoch 1118: train_loss = 0.6416404843330383, valid_loss= 0.6320740580558777, accuracy= 64.0625\n",
      "Epoch 1119: train_loss = 0.6387844681739807, valid_loss= 0.63217693567276, accuracy= 65.9375\n",
      "Epoch 1120: train_loss = 0.638340175151825, valid_loss= 0.6334419250488281, accuracy= 64.375\n",
      "Epoch 1121: train_loss = 0.6323009133338928, valid_loss= 0.6337624788284302, accuracy= 63.4375\n",
      "Epoch 1122: train_loss = 0.6340409517288208, valid_loss= 0.6314598321914673, accuracy= 65.3125\n",
      "Epoch 1123: train_loss = 0.6318899393081665, valid_loss= 0.6304478645324707, accuracy= 66.25\n",
      "Epoch 1124: train_loss = 0.6309863328933716, valid_loss= 0.6308864951133728, accuracy= 65.3125\n",
      "Epoch 1125: train_loss = 0.6304460763931274, valid_loss= 0.6321166753768921, accuracy= 63.4375\n",
      "Epoch 1126: train_loss = 0.6319001317024231, valid_loss= 0.6322314143180847, accuracy= 62.81250000000001\n",
      "Epoch 1127: train_loss = 0.6278632879257202, valid_loss= 0.6311436295509338, accuracy= 64.0625\n",
      "Epoch 1128: train_loss = 0.6386188864707947, valid_loss= 0.6297773122787476, accuracy= 65.625\n",
      "Epoch 1129: train_loss = 0.6238073110580444, valid_loss= 0.6309804916381836, accuracy= 62.81250000000001\n",
      "Epoch 1130: train_loss = 0.6362856030464172, valid_loss= 0.631281852722168, accuracy= 62.5\n",
      "Epoch 1131: train_loss = 0.6413217782974243, valid_loss= 0.6310142278671265, accuracy= 62.81250000000001\n",
      "Epoch 1132: train_loss = 0.6300410032272339, valid_loss= 0.6299300789833069, accuracy= 66.25\n",
      "Epoch 1133: train_loss = 0.6294070482254028, valid_loss= 0.6298554539680481, accuracy= 65.3125\n",
      "Epoch 1134: train_loss = 0.6249247193336487, valid_loss= 0.6316527128219604, accuracy= 64.6875\n",
      "Epoch 1135: train_loss = 0.6382994651794434, valid_loss= 0.630815327167511, accuracy= 65.625\n",
      "Epoch 1136: train_loss = 0.6316745281219482, valid_loss= 0.63154536485672, accuracy= 64.375\n",
      "Epoch 1137: train_loss = 0.6362430453300476, valid_loss= 0.6305606365203857, accuracy= 65.3125\n",
      "Epoch 1138: train_loss = 0.6405013799667358, valid_loss= 0.6297183036804199, accuracy= 65.3125\n",
      "Epoch 1139: train_loss = 0.636376678943634, valid_loss= 0.6291964054107666, accuracy= 65.3125\n",
      "Epoch 1140: train_loss = 0.6371709704399109, valid_loss= 0.629828929901123, accuracy= 64.375\n",
      "Epoch 1141: train_loss = 0.6317496299743652, valid_loss= 0.6309846043586731, accuracy= 61.875\n",
      "Epoch 1142: train_loss = 0.6314945816993713, valid_loss= 0.6305363178253174, accuracy= 64.6875\n",
      "Epoch 1143: train_loss = 0.6313688158988953, valid_loss= 0.6304497122764587, accuracy= 65.3125\n",
      "Epoch 1144: train_loss = 0.6356440782546997, valid_loss= 0.6297767758369446, accuracy= 65.625\n",
      "Epoch 1145: train_loss = 0.6363339424133301, valid_loss= 0.630000114440918, accuracy= 63.74999999999999\n",
      "Epoch 1146: train_loss = 0.6455352306365967, valid_loss= 0.6291331052780151, accuracy= 63.125\n",
      "Epoch 1147: train_loss = 0.6342862844467163, valid_loss= 0.6283503770828247, accuracy= 64.375\n",
      "Epoch 1148: train_loss = 0.6397454142570496, valid_loss= 0.6282826066017151, accuracy= 64.6875\n",
      "Epoch 1149: train_loss = 0.6323463320732117, valid_loss= 0.6292186379432678, accuracy= 62.18749999999999\n",
      "Epoch 1150: train_loss = 0.6375812292098999, valid_loss= 0.628841757774353, accuracy= 63.4375\n",
      "Epoch 1151: train_loss = 0.6445626616477966, valid_loss= 0.6278427839279175, accuracy= 65.0\n",
      "Epoch 1152: train_loss = 0.6342931985855103, valid_loss= 0.6284995079040527, accuracy= 63.74999999999999\n",
      "Epoch 1153: train_loss = 0.6280866861343384, valid_loss= 0.630380392074585, accuracy= 62.18749999999999\n",
      "Epoch 1154: train_loss = 0.6379503011703491, valid_loss= 0.6299611926078796, accuracy= 62.5\n",
      "Epoch 1155: train_loss = 0.6301787495613098, valid_loss= 0.6283054351806641, accuracy= 65.625\n",
      "Epoch 1156: train_loss = 0.639017641544342, valid_loss= 0.6276319026947021, accuracy= 65.3125\n",
      "Epoch 1157: train_loss = 0.6362519264221191, valid_loss= 0.6278867125511169, accuracy= 64.6875\n",
      "Epoch 1158: train_loss = 0.6260977983474731, valid_loss= 0.6279531121253967, accuracy= 65.3125\n",
      "Epoch 1159: train_loss = 0.6352784633636475, valid_loss= 0.6292627453804016, accuracy= 64.6875\n",
      "Epoch 1160: train_loss = 0.632371723651886, valid_loss= 0.6295018792152405, accuracy= 64.6875\n",
      "Epoch 1161: train_loss = 0.6394577622413635, valid_loss= 0.6280820369720459, accuracy= 65.625\n",
      "Epoch 1162: train_loss = 0.628790020942688, valid_loss= 0.6278746128082275, accuracy= 65.9375\n",
      "Epoch 1163: train_loss = 0.636542022228241, valid_loss= 0.6290042400360107, accuracy= 66.25\n",
      "Epoch 1164: train_loss = 0.6355476975440979, valid_loss= 0.6300656199455261, accuracy= 64.375\n",
      "Epoch 1165: train_loss = 0.6288594603538513, valid_loss= 0.6291815042495728, accuracy= 65.3125\n",
      "Epoch 1166: train_loss = 0.6327165961265564, valid_loss= 0.6286534667015076, accuracy= 65.625\n",
      "Epoch 1167: train_loss = 0.6303668022155762, valid_loss= 0.6288394927978516, accuracy= 65.625\n",
      "Epoch 1168: train_loss = 0.6353543996810913, valid_loss= 0.6288578510284424, accuracy= 65.9375\n",
      "Epoch 1169: train_loss = 0.6348813772201538, valid_loss= 0.6293148994445801, accuracy= 65.3125\n",
      "Epoch 1170: train_loss = 0.6257138848304749, valid_loss= 0.6290242075920105, accuracy= 66.25\n",
      "Epoch 1171: train_loss = 0.6295682191848755, valid_loss= 0.6292032599449158, accuracy= 66.25\n",
      "Epoch 1172: train_loss = 0.6277778148651123, valid_loss= 0.628872811794281, accuracy= 65.9375\n",
      "Epoch 1173: train_loss = 0.6320375800132751, valid_loss= 0.6299291849136353, accuracy= 66.25\n",
      "Epoch 1174: train_loss = 0.637541651725769, valid_loss= 0.6295672655105591, accuracy= 66.5625\n",
      "Epoch 1175: train_loss = 0.6269317269325256, valid_loss= 0.6292754411697388, accuracy= 66.25\n",
      "Epoch 1176: train_loss = 0.6338726878166199, valid_loss= 0.6298311948776245, accuracy= 66.25\n",
      "Epoch 1177: train_loss = 0.6301074624061584, valid_loss= 0.6302664875984192, accuracy= 64.6875\n",
      "Epoch 1178: train_loss = 0.6280445456504822, valid_loss= 0.629713773727417, accuracy= 65.3125\n",
      "Epoch 1179: train_loss = 0.6261286735534668, valid_loss= 0.6300421953201294, accuracy= 65.3125\n",
      "Epoch 1180: train_loss = 0.632523238658905, valid_loss= 0.628418505191803, accuracy= 65.0\n",
      "Epoch 1181: train_loss = 0.642000675201416, valid_loss= 0.6265970468521118, accuracy= 66.5625\n",
      "Epoch 1182: train_loss = 0.6309821009635925, valid_loss= 0.6270728707313538, accuracy= 65.0\n",
      "Epoch 1183: train_loss = 0.6380444765090942, valid_loss= 0.6288294792175293, accuracy= 64.375\n",
      "Epoch 1184: train_loss = 0.6326239109039307, valid_loss= 0.6312856078147888, accuracy= 63.4375\n",
      "Epoch 1185: train_loss = 0.6333471536636353, valid_loss= 0.6302677989006042, accuracy= 63.74999999999999\n",
      "Epoch 1186: train_loss = 0.6386955976486206, valid_loss= 0.627110481262207, accuracy= 65.0\n",
      "Epoch 1187: train_loss = 0.6313992142677307, valid_loss= 0.6262773275375366, accuracy= 65.3125\n",
      "Epoch 1188: train_loss = 0.6362969875335693, valid_loss= 0.6263357400894165, accuracy= 65.3125\n",
      "Epoch 1189: train_loss = 0.6324934363365173, valid_loss= 0.6286625266075134, accuracy= 62.18749999999999\n",
      "Epoch 1190: train_loss = 0.6318387389183044, valid_loss= 0.6305667757987976, accuracy= 63.4375\n",
      "Epoch 1191: train_loss = 0.6334213018417358, valid_loss= 0.6289084553718567, accuracy= 62.18749999999999\n",
      "Epoch 1192: train_loss = 0.6285218000411987, valid_loss= 0.6275610327720642, accuracy= 65.3125\n",
      "Epoch 1193: train_loss = 0.6299809813499451, valid_loss= 0.6264513731002808, accuracy= 67.5\n",
      "Epoch 1194: train_loss = 0.6329514384269714, valid_loss= 0.6277278065681458, accuracy= 66.25\n",
      "Epoch 1195: train_loss = 0.6382613778114319, valid_loss= 0.6301065683364868, accuracy= 64.375\n",
      "Epoch 1196: train_loss = 0.6367814540863037, valid_loss= 0.6326969861984253, accuracy= 62.18749999999999\n",
      "Epoch 1197: train_loss = 0.6381965279579163, valid_loss= 0.6293190717697144, accuracy= 63.74999999999999\n",
      "Epoch 1198: train_loss = 0.6295518279075623, valid_loss= 0.626298189163208, accuracy= 66.875\n",
      "Epoch 1199: train_loss = 0.6296166777610779, valid_loss= 0.6247314214706421, accuracy= 65.3125\n",
      "Epoch 1200: train_loss = 0.634770393371582, valid_loss= 0.6269897818565369, accuracy= 65.0\n",
      "Epoch 1201: train_loss = 0.6315034031867981, valid_loss= 0.6295733451843262, accuracy= 62.18749999999999\n",
      "Epoch 1202: train_loss = 0.6294015645980835, valid_loss= 0.6283015012741089, accuracy= 62.81250000000001\n",
      "Epoch 1203: train_loss = 0.6281081438064575, valid_loss= 0.6257878541946411, accuracy= 64.375\n",
      "Epoch 1204: train_loss = 0.6292701959609985, valid_loss= 0.6248980164527893, accuracy= 67.5\n",
      "Epoch 1205: train_loss = 0.6245372295379639, valid_loss= 0.6261197328567505, accuracy= 65.3125\n",
      "Epoch 1206: train_loss = 0.627980649471283, valid_loss= 0.6273665428161621, accuracy= 64.0625\n",
      "Epoch 1207: train_loss = 0.6371756196022034, valid_loss= 0.6246691942214966, accuracy= 65.625\n",
      "Epoch 1208: train_loss = 0.6325900554656982, valid_loss= 0.6237317323684692, accuracy= 66.875\n",
      "Epoch 1209: train_loss = 0.6376016736030579, valid_loss= 0.6263151168823242, accuracy= 63.4375\n",
      "Epoch 1210: train_loss = 0.6303839683532715, valid_loss= 0.6270212531089783, accuracy= 63.125\n",
      "Epoch 1211: train_loss = 0.6277188062667847, valid_loss= 0.6253716349601746, accuracy= 64.0625\n",
      "Epoch 1212: train_loss = 0.6321041584014893, valid_loss= 0.6244462728500366, accuracy= 66.25\n",
      "Epoch 1213: train_loss = 0.630972683429718, valid_loss= 0.6254239082336426, accuracy= 65.0\n",
      "Epoch 1214: train_loss = 0.6200700402259827, valid_loss= 0.6274527311325073, accuracy= 63.74999999999999\n",
      "Epoch 1215: train_loss = 0.6276262402534485, valid_loss= 0.62868332862854, accuracy= 63.74999999999999\n",
      "Epoch 1216: train_loss = 0.6304182410240173, valid_loss= 0.6263271570205688, accuracy= 67.5\n",
      "Epoch 1217: train_loss = 0.6388462781906128, valid_loss= 0.6245313882827759, accuracy= 66.875\n",
      "Epoch 1218: train_loss = 0.635330080986023, valid_loss= 0.624799907207489, accuracy= 66.5625\n",
      "Epoch 1219: train_loss = 0.6364452838897705, valid_loss= 0.6264580488204956, accuracy= 63.125\n",
      "Epoch 1220: train_loss = 0.622395396232605, valid_loss= 0.6262682676315308, accuracy= 63.4375\n",
      "Epoch 1221: train_loss = 0.6295309662818909, valid_loss= 0.6254383325576782, accuracy= 64.0625\n",
      "Epoch 1222: train_loss = 0.6339643001556396, valid_loss= 0.6242783665657043, accuracy= 65.9375\n",
      "Epoch 1223: train_loss = 0.6282328367233276, valid_loss= 0.6246741414070129, accuracy= 64.6875\n",
      "Epoch 1224: train_loss = 0.6255034804344177, valid_loss= 0.6237836480140686, accuracy= 66.25\n",
      "Epoch 1225: train_loss = 0.6332961916923523, valid_loss= 0.6239413022994995, accuracy= 65.0\n",
      "Epoch 1226: train_loss = 0.6290554404258728, valid_loss= 0.6236655116081238, accuracy= 64.375\n",
      "Epoch 1227: train_loss = 0.6334741115570068, valid_loss= 0.6240534782409668, accuracy= 64.6875\n",
      "Epoch 1228: train_loss = 0.6294193863868713, valid_loss= 0.6247718930244446, accuracy= 63.4375\n",
      "Epoch 1229: train_loss = 0.6355350017547607, valid_loss= 0.6247823238372803, accuracy= 65.0\n",
      "Epoch 1230: train_loss = 0.6336631178855896, valid_loss= 0.6244729161262512, accuracy= 65.0\n",
      "Epoch 1231: train_loss = 0.6257021427154541, valid_loss= 0.6244906187057495, accuracy= 66.5625\n",
      "Epoch 1232: train_loss = 0.625439465045929, valid_loss= 0.624057948589325, accuracy= 66.875\n",
      "Epoch 1233: train_loss = 0.6266810894012451, valid_loss= 0.6251837015151978, accuracy= 66.5625\n",
      "Epoch 1234: train_loss = 0.6306824088096619, valid_loss= 0.6265893578529358, accuracy= 64.6875\n",
      "Epoch 1235: train_loss = 0.6322624683380127, valid_loss= 0.6254469156265259, accuracy= 66.5625\n",
      "Epoch 1236: train_loss = 0.6367127895355225, valid_loss= 0.6223281621932983, accuracy= 65.0\n",
      "Epoch 1237: train_loss = 0.6269471645355225, valid_loss= 0.6229032278060913, accuracy= 66.5625\n",
      "Epoch 1238: train_loss = 0.6340848207473755, valid_loss= 0.6240209341049194, accuracy= 66.5625\n",
      "Epoch 1239: train_loss = 0.6333789229393005, valid_loss= 0.6247837543487549, accuracy= 66.875\n",
      "Epoch 1240: train_loss = 0.6335369348526001, valid_loss= 0.6247795224189758, accuracy= 67.5\n",
      "Epoch 1241: train_loss = 0.6329979300498962, valid_loss= 0.6238731741905212, accuracy= 67.5\n",
      "Epoch 1242: train_loss = 0.6309531927108765, valid_loss= 0.6230860948562622, accuracy= 66.5625\n",
      "Epoch 1243: train_loss = 0.6280681490898132, valid_loss= 0.62356036901474, accuracy= 67.1875\n",
      "Epoch 1244: train_loss = 0.6324228048324585, valid_loss= 0.6247141361236572, accuracy= 65.0\n",
      "Epoch 1245: train_loss = 0.6293269395828247, valid_loss= 0.6245852708816528, accuracy= 64.6875\n",
      "Epoch 1246: train_loss = 0.6318883299827576, valid_loss= 0.6239279508590698, accuracy= 65.3125\n",
      "Epoch 1247: train_loss = 0.6286143660545349, valid_loss= 0.6234648823738098, accuracy= 66.5625\n",
      "Epoch 1248: train_loss = 0.6243327856063843, valid_loss= 0.6236873865127563, accuracy= 66.25\n",
      "Epoch 1249: train_loss = 0.630928099155426, valid_loss= 0.6237837076187134, accuracy= 67.1875\n",
      "Epoch 1250: train_loss = 0.6272974610328674, valid_loss= 0.6237848997116089, accuracy= 67.1875\n",
      "Epoch 1251: train_loss = 0.6298513412475586, valid_loss= 0.6232689619064331, accuracy= 66.25\n",
      "Epoch 1252: train_loss = 0.6358634829521179, valid_loss= 0.624113142490387, accuracy= 67.5\n",
      "Epoch 1253: train_loss = 0.6327639818191528, valid_loss= 0.6236292123794556, accuracy= 67.5\n",
      "Epoch 1254: train_loss = 0.631628692150116, valid_loss= 0.6236217021942139, accuracy= 64.6875\n",
      "Epoch 1255: train_loss = 0.6321812272071838, valid_loss= 0.6238187551498413, accuracy= 65.0\n",
      "Epoch 1256: train_loss = 0.6347688436508179, valid_loss= 0.6217957139015198, accuracy= 66.875\n",
      "Epoch 1257: train_loss = 0.6319659948348999, valid_loss= 0.6218037009239197, accuracy= 67.1875\n",
      "Epoch 1258: train_loss = 0.6248375773429871, valid_loss= 0.6238034963607788, accuracy= 63.74999999999999\n",
      "Epoch 1259: train_loss = 0.62654709815979, valid_loss= 0.6246941685676575, accuracy= 63.74999999999999\n",
      "Epoch 1260: train_loss = 0.6247988939285278, valid_loss= 0.6243826150894165, accuracy= 65.9375\n",
      "Epoch 1261: train_loss = 0.6194401383399963, valid_loss= 0.623741626739502, accuracy= 66.875\n",
      "Epoch 1262: train_loss = 0.6305297017097473, valid_loss= 0.6229544878005981, accuracy= 66.5625\n",
      "Epoch 1263: train_loss = 0.6324684023857117, valid_loss= 0.6250090003013611, accuracy= 67.1875\n",
      "Epoch 1264: train_loss = 0.6286107897758484, valid_loss= 0.6256610155105591, accuracy= 67.5\n",
      "Epoch 1265: train_loss = 0.6256387829780579, valid_loss= 0.6228348016738892, accuracy= 66.5625\n",
      "Epoch 1266: train_loss = 0.6356092691421509, valid_loss= 0.6216960549354553, accuracy= 65.9375\n",
      "Epoch 1267: train_loss = 0.6248267889022827, valid_loss= 0.6222373843193054, accuracy= 66.875\n",
      "Epoch 1268: train_loss = 0.628641664981842, valid_loss= 0.6214767098426819, accuracy= 67.5\n",
      "Epoch 1269: train_loss = 0.6308553814888, valid_loss= 0.6205968260765076, accuracy= 67.5\n",
      "Epoch 1270: train_loss = 0.6241171956062317, valid_loss= 0.6208614110946655, accuracy= 67.1875\n",
      "Epoch 1271: train_loss = 0.6301680207252502, valid_loss= 0.6230427622795105, accuracy= 65.625\n",
      "Epoch 1272: train_loss = 0.6318395733833313, valid_loss= 0.6224273443222046, accuracy= 66.25\n",
      "Epoch 1273: train_loss = 0.6353118419647217, valid_loss= 0.6208086013793945, accuracy= 68.125\n",
      "Epoch 1274: train_loss = 0.6203110218048096, valid_loss= 0.6200909614562988, accuracy= 67.5\n",
      "Epoch 1275: train_loss = 0.6327957510948181, valid_loss= 0.6208598613739014, accuracy= 68.125\n",
      "Epoch 1276: train_loss = 0.6240249872207642, valid_loss= 0.6217949986457825, accuracy= 65.625\n",
      "Epoch 1277: train_loss = 0.6341819167137146, valid_loss= 0.6209717988967896, accuracy= 65.9375\n",
      "Epoch 1278: train_loss = 0.6330440044403076, valid_loss= 0.6198338270187378, accuracy= 66.5625\n",
      "Epoch 1279: train_loss = 0.6306607127189636, valid_loss= 0.6203270554542542, accuracy= 65.9375\n",
      "Epoch 1280: train_loss = 0.6260106563568115, valid_loss= 0.6209243535995483, accuracy= 66.875\n",
      "Epoch 1281: train_loss = 0.6204914450645447, valid_loss= 0.6220203042030334, accuracy= 66.25\n",
      "Epoch 1282: train_loss = 0.615734875202179, valid_loss= 0.6224212050437927, accuracy= 65.9375\n",
      "Epoch 1283: train_loss = 0.6340111494064331, valid_loss= 0.6204542517662048, accuracy= 66.5625\n",
      "Epoch 1284: train_loss = 0.6322304606437683, valid_loss= 0.620121955871582, accuracy= 67.1875\n",
      "Epoch 1285: train_loss = 0.6308730840682983, valid_loss= 0.6218948364257812, accuracy= 67.1875\n",
      "Epoch 1286: train_loss = 0.6274629235267639, valid_loss= 0.6210877895355225, accuracy= 66.875\n",
      "Epoch 1287: train_loss = 0.6336745023727417, valid_loss= 0.6198875308036804, accuracy= 66.5625\n",
      "Epoch 1288: train_loss = 0.625873863697052, valid_loss= 0.6198332905769348, accuracy= 66.5625\n",
      "Epoch 1289: train_loss = 0.6283241510391235, valid_loss= 0.6189324259757996, accuracy= 66.25\n",
      "Epoch 1290: train_loss = 0.6299887895584106, valid_loss= 0.6202927827835083, accuracy= 67.1875\n",
      "Epoch 1291: train_loss = 0.6288514733314514, valid_loss= 0.621749758720398, accuracy= 65.9375\n",
      "Epoch 1292: train_loss = 0.6357953548431396, valid_loss= 0.6200288534164429, accuracy= 66.5625\n",
      "Epoch 1293: train_loss = 0.6312934160232544, valid_loss= 0.618514358997345, accuracy= 67.1875\n",
      "Epoch 1294: train_loss = 0.626427412033081, valid_loss= 0.618707001209259, accuracy= 66.25\n",
      "Epoch 1295: train_loss = 0.6285760998725891, valid_loss= 0.6210415959358215, accuracy= 66.5625\n",
      "Epoch 1296: train_loss = 0.6273838877677917, valid_loss= 0.6220403909683228, accuracy= 66.875\n",
      "Epoch 1297: train_loss = 0.6237369775772095, valid_loss= 0.6224836707115173, accuracy= 66.875\n",
      "Epoch 1298: train_loss = 0.6238637566566467, valid_loss= 0.6219078898429871, accuracy= 67.5\n",
      "Epoch 1299: train_loss = 0.6183724999427795, valid_loss= 0.6211332082748413, accuracy= 65.9375\n",
      "Epoch 1300: train_loss = 0.627251386642456, valid_loss= 0.619683563709259, accuracy= 65.625\n",
      "Epoch 1301: train_loss = 0.6354695558547974, valid_loss= 0.6195980906486511, accuracy= 65.625\n",
      "Epoch 1302: train_loss = 0.6320980787277222, valid_loss= 0.6225208640098572, accuracy= 66.5625\n",
      "Epoch 1303: train_loss = 0.6265078186988831, valid_loss= 0.6218594908714294, accuracy= 65.9375\n",
      "Epoch 1304: train_loss = 0.6230234503746033, valid_loss= 0.6207429766654968, accuracy= 67.8125\n",
      "Epoch 1305: train_loss = 0.6252830624580383, valid_loss= 0.6218636631965637, accuracy= 65.625\n",
      "Epoch 1306: train_loss = 0.6159003376960754, valid_loss= 0.6204891800880432, accuracy= 67.5\n",
      "Epoch 1307: train_loss = 0.6284435391426086, valid_loss= 0.6182143092155457, accuracy= 66.25\n",
      "Epoch 1308: train_loss = 0.6259057521820068, valid_loss= 0.618759036064148, accuracy= 65.9375\n",
      "Epoch 1309: train_loss = 0.6314762234687805, valid_loss= 0.6211534738540649, accuracy= 65.625\n",
      "Epoch 1310: train_loss = 0.6246854662895203, valid_loss= 0.6240654587745667, accuracy= 65.0\n",
      "Epoch 1311: train_loss = 0.6333944797515869, valid_loss= 0.6201574206352234, accuracy= 66.5625\n",
      "Epoch 1312: train_loss = 0.6204532384872437, valid_loss= 0.6177903413772583, accuracy= 66.25\n",
      "Epoch 1313: train_loss = 0.6300162672996521, valid_loss= 0.617511510848999, accuracy= 67.5\n",
      "Epoch 1314: train_loss = 0.6294255256652832, valid_loss= 0.6193743944168091, accuracy= 65.625\n",
      "Epoch 1315: train_loss = 0.6352317333221436, valid_loss= 0.6201649904251099, accuracy= 65.0\n",
      "Epoch 1316: train_loss = 0.6292100548744202, valid_loss= 0.6186670064926147, accuracy= 65.625\n",
      "Epoch 1317: train_loss = 0.6214184165000916, valid_loss= 0.6194095015525818, accuracy= 65.625\n",
      "Epoch 1318: train_loss = 0.6236388087272644, valid_loss= 0.6188795566558838, accuracy= 65.625\n",
      "Epoch 1319: train_loss = 0.6300860643386841, valid_loss= 0.6176097393035889, accuracy= 67.1875\n",
      "Epoch 1320: train_loss = 0.6231054067611694, valid_loss= 0.6175840497016907, accuracy= 66.25\n",
      "Epoch 1321: train_loss = 0.628960371017456, valid_loss= 0.6190498471260071, accuracy= 67.1875\n",
      "Epoch 1322: train_loss = 0.6234077215194702, valid_loss= 0.6176787614822388, accuracy= 66.875\n",
      "Epoch 1323: train_loss = 0.6223048567771912, valid_loss= 0.6164201498031616, accuracy= 66.5625\n",
      "Epoch 1324: train_loss = 0.6343703269958496, valid_loss= 0.616776168346405, accuracy= 67.1875\n",
      "Epoch 1325: train_loss = 0.6224281191825867, valid_loss= 0.6181530952453613, accuracy= 67.1875\n",
      "Epoch 1326: train_loss = 0.631330132484436, valid_loss= 0.6175381541252136, accuracy= 65.9375\n",
      "Epoch 1327: train_loss = 0.6229273080825806, valid_loss= 0.6170936226844788, accuracy= 66.875\n",
      "Epoch 1328: train_loss = 0.6267268657684326, valid_loss= 0.6163371801376343, accuracy= 65.3125\n",
      "Epoch 1329: train_loss = 0.6376540064811707, valid_loss= 0.6142715215682983, accuracy= 67.5\n",
      "Epoch 1330: train_loss = 0.6214013695716858, valid_loss= 0.6136817336082458, accuracy= 67.5\n",
      "Epoch 1331: train_loss = 0.6304348111152649, valid_loss= 0.6147547364234924, accuracy= 66.875\n",
      "Epoch 1332: train_loss = 0.6253983974456787, valid_loss= 0.6157870888710022, accuracy= 67.5\n",
      "Epoch 1333: train_loss = 0.6207286715507507, valid_loss= 0.6165252923965454, accuracy= 66.5625\n",
      "Epoch 1334: train_loss = 0.6292390823364258, valid_loss= 0.6150990128517151, accuracy= 67.5\n",
      "Epoch 1335: train_loss = 0.6214430928230286, valid_loss= 0.6169445514678955, accuracy= 66.5625\n",
      "Epoch 1336: train_loss = 0.6296993494033813, valid_loss= 0.6152125597000122, accuracy= 66.5625\n",
      "Epoch 1337: train_loss = 0.6251588463783264, valid_loss= 0.6146854162216187, accuracy= 66.875\n",
      "Epoch 1338: train_loss = 0.6195954084396362, valid_loss= 0.6157328486442566, accuracy= 66.5625\n",
      "Epoch 1339: train_loss = 0.6262503862380981, valid_loss= 0.6151694655418396, accuracy= 66.875\n",
      "Epoch 1340: train_loss = 0.6218713521957397, valid_loss= 0.6166135668754578, accuracy= 67.5\n",
      "Epoch 1341: train_loss = 0.6160818338394165, valid_loss= 0.6180549263954163, accuracy= 66.5625\n",
      "Epoch 1342: train_loss = 0.6232503652572632, valid_loss= 0.6157416105270386, accuracy= 67.5\n",
      "Epoch 1343: train_loss = 0.6286934018135071, valid_loss= 0.6136443614959717, accuracy= 66.875\n",
      "Epoch 1344: train_loss = 0.6310808658599854, valid_loss= 0.6145076751708984, accuracy= 67.1875\n",
      "Epoch 1345: train_loss = 0.6283388733863831, valid_loss= 0.6155441999435425, accuracy= 66.25\n",
      "Epoch 1346: train_loss = 0.6287804841995239, valid_loss= 0.6165418028831482, accuracy= 65.3125\n",
      "Epoch 1347: train_loss = 0.6301701664924622, valid_loss= 0.6138679385185242, accuracy= 66.25\n",
      "Epoch 1348: train_loss = 0.6245793700218201, valid_loss= 0.612817645072937, accuracy= 66.25\n",
      "Epoch 1349: train_loss = 0.6330682635307312, valid_loss= 0.6137043833732605, accuracy= 66.5625\n",
      "Epoch 1350: train_loss = 0.6197205185890198, valid_loss= 0.6144840121269226, accuracy= 66.875\n",
      "Epoch 1351: train_loss = 0.6237801909446716, valid_loss= 0.6164186596870422, accuracy= 65.9375\n",
      "Epoch 1352: train_loss = 0.6210798025131226, valid_loss= 0.6148074269294739, accuracy= 67.5\n",
      "Epoch 1353: train_loss = 0.622897207736969, valid_loss= 0.611823558807373, accuracy= 66.875\n",
      "Epoch 1354: train_loss = 0.6199902892112732, valid_loss= 0.6124394536018372, accuracy= 67.5\n",
      "Epoch 1355: train_loss = 0.6267699599266052, valid_loss= 0.6138671040534973, accuracy= 67.1875\n",
      "Epoch 1356: train_loss = 0.6232374310493469, valid_loss= 0.6142243146896362, accuracy= 66.25\n",
      "Epoch 1357: train_loss = 0.6136041879653931, valid_loss= 0.61368727684021, accuracy= 66.25\n",
      "Epoch 1358: train_loss = 0.6213763356208801, valid_loss= 0.6139061450958252, accuracy= 65.9375\n",
      "Epoch 1359: train_loss = 0.6218217611312866, valid_loss= 0.6134125590324402, accuracy= 68.4375\n",
      "Epoch 1360: train_loss = 0.6208091974258423, valid_loss= 0.6128036975860596, accuracy= 68.125\n",
      "Epoch 1361: train_loss = 0.6311554312705994, valid_loss= 0.6119811534881592, accuracy= 68.125\n",
      "Epoch 1362: train_loss = 0.6148434281349182, valid_loss= 0.612575888633728, accuracy= 68.75\n",
      "Epoch 1363: train_loss = 0.6251753568649292, valid_loss= 0.6152563691139221, accuracy= 67.8125\n",
      "Epoch 1364: train_loss = 0.627826452255249, valid_loss= 0.6114555597305298, accuracy= 68.125\n",
      "Epoch 1365: train_loss = 0.6248481273651123, valid_loss= 0.6086946725845337, accuracy= 67.5\n",
      "Epoch 1366: train_loss = 0.6290878653526306, valid_loss= 0.6083346009254456, accuracy= 67.5\n",
      "Epoch 1367: train_loss = 0.6272789835929871, valid_loss= 0.6103603839874268, accuracy= 68.125\n",
      "Epoch 1368: train_loss = 0.6276266574859619, valid_loss= 0.612071692943573, accuracy= 66.875\n",
      "Epoch 1369: train_loss = 0.6211152076721191, valid_loss= 0.6097239255905151, accuracy= 68.4375\n",
      "Epoch 1370: train_loss = 0.6219461560249329, valid_loss= 0.6088175177574158, accuracy= 68.4375\n",
      "Epoch 1371: train_loss = 0.6238490343093872, valid_loss= 0.6088653802871704, accuracy= 68.125\n",
      "Epoch 1372: train_loss = 0.6330571174621582, valid_loss= 0.6102679371833801, accuracy= 66.875\n",
      "Epoch 1373: train_loss = 0.6264451146125793, valid_loss= 0.6097766757011414, accuracy= 66.5625\n",
      "Epoch 1374: train_loss = 0.6234601140022278, valid_loss= 0.6100419759750366, accuracy= 67.1875\n",
      "Epoch 1375: train_loss = 0.6243160367012024, valid_loss= 0.6101716160774231, accuracy= 68.125\n",
      "Epoch 1376: train_loss = 0.6230393052101135, valid_loss= 0.6117671728134155, accuracy= 68.125\n",
      "Epoch 1377: train_loss = 0.6196226477622986, valid_loss= 0.6162568926811218, accuracy= 65.9375\n",
      "Epoch 1378: train_loss = 0.6233639717102051, valid_loss= 0.6122475862503052, accuracy= 67.5\n",
      "Epoch 1379: train_loss = 0.6287165284156799, valid_loss= 0.6096152663230896, accuracy= 66.5625\n",
      "Epoch 1380: train_loss = 0.6193728446960449, valid_loss= 0.6104612350463867, accuracy= 67.5\n",
      "Epoch 1381: train_loss = 0.6221828460693359, valid_loss= 0.6138892769813538, accuracy= 67.5\n",
      "Epoch 1382: train_loss = 0.6108906269073486, valid_loss= 0.6141759753227234, accuracy= 67.1875\n",
      "Epoch 1383: train_loss = 0.631203830242157, valid_loss= 0.6099358201026917, accuracy= 66.875\n",
      "Epoch 1384: train_loss = 0.625377357006073, valid_loss= 0.6100788116455078, accuracy= 66.875\n",
      "Epoch 1385: train_loss = 0.6159334182739258, valid_loss= 0.6123428344726562, accuracy= 68.4375\n",
      "Epoch 1386: train_loss = 0.6203674077987671, valid_loss= 0.6131011247634888, accuracy= 68.4375\n",
      "Epoch 1387: train_loss = 0.6254786252975464, valid_loss= 0.6099612712860107, accuracy= 67.5\n",
      "Epoch 1388: train_loss = 0.6301035284996033, valid_loss= 0.6094394326210022, accuracy= 67.8125\n",
      "Epoch 1389: train_loss = 0.6232708096504211, valid_loss= 0.6084063053131104, accuracy= 68.125\n",
      "Epoch 1390: train_loss = 0.6264201998710632, valid_loss= 0.6097906827926636, accuracy= 68.4375\n",
      "Epoch 1391: train_loss = 0.6227468252182007, valid_loss= 0.608607828617096, accuracy= 68.75\n",
      "Epoch 1392: train_loss = 0.6190521121025085, valid_loss= 0.6076713800430298, accuracy= 67.1875\n",
      "Epoch 1393: train_loss = 0.6207566261291504, valid_loss= 0.6081714034080505, accuracy= 67.8125\n",
      "Epoch 1394: train_loss = 0.6230663657188416, valid_loss= 0.6090313196182251, accuracy= 67.5\n",
      "Epoch 1395: train_loss = 0.6207935810089111, valid_loss= 0.6078497171401978, accuracy= 68.125\n",
      "Epoch 1396: train_loss = 0.6240568161010742, valid_loss= 0.6074274182319641, accuracy= 68.125\n",
      "Epoch 1397: train_loss = 0.6175646781921387, valid_loss= 0.606922447681427, accuracy= 68.4375\n",
      "Epoch 1398: train_loss = 0.6227269768714905, valid_loss= 0.6061396598815918, accuracy= 68.4375\n",
      "Epoch 1399: train_loss = 0.6234183311462402, valid_loss= 0.605073094367981, accuracy= 68.4375\n",
      "Epoch 1400: train_loss = 0.622258186340332, valid_loss= 0.6074843406677246, accuracy= 67.5\n",
      "Epoch 1401: train_loss = 0.6197794079780579, valid_loss= 0.6090751886367798, accuracy= 67.1875\n",
      "Epoch 1402: train_loss = 0.6184738278388977, valid_loss= 0.6059646010398865, accuracy= 68.75\n",
      "Epoch 1403: train_loss = 0.6210519075393677, valid_loss= 0.6055298447608948, accuracy= 67.5\n",
      "Epoch 1404: train_loss = 0.6155058145523071, valid_loss= 0.6062109470367432, accuracy= 68.4375\n",
      "Epoch 1405: train_loss = 0.6097554564476013, valid_loss= 0.6077576279640198, accuracy= 68.75\n",
      "Epoch 1406: train_loss = 0.6381534934043884, valid_loss= 0.6039878726005554, accuracy= 66.25\n",
      "Epoch 1407: train_loss = 0.6210842728614807, valid_loss= 0.6055680513381958, accuracy= 67.8125\n",
      "Epoch 1408: train_loss = 0.6151483654975891, valid_loss= 0.6120109558105469, accuracy= 65.0\n",
      "Epoch 1409: train_loss = 0.6241636276245117, valid_loss= 0.604548454284668, accuracy= 68.4375\n",
      "Epoch 1410: train_loss = 0.6190476417541504, valid_loss= 0.603305995464325, accuracy= 68.4375\n",
      "Epoch 1411: train_loss = 0.6246432065963745, valid_loss= 0.6016737818717957, accuracy= 68.4375\n",
      "Epoch 1412: train_loss = 0.619612991809845, valid_loss= 0.6021409034729004, accuracy= 68.4375\n",
      "Epoch 1413: train_loss = 0.6198609471321106, valid_loss= 0.6018524765968323, accuracy= 67.8125\n",
      "Epoch 1414: train_loss = 0.6089718341827393, valid_loss= 0.6009420156478882, accuracy= 68.4375\n",
      "Epoch 1415: train_loss = 0.6127162575721741, valid_loss= 0.6009743213653564, accuracy= 68.75\n",
      "Epoch 1416: train_loss = 0.6123732924461365, valid_loss= 0.6030532717704773, accuracy= 68.4375\n",
      "Epoch 1417: train_loss = 0.6142292022705078, valid_loss= 0.5999873876571655, accuracy= 68.75\n",
      "Epoch 1418: train_loss = 0.6195501685142517, valid_loss= 0.6012662053108215, accuracy= 69.375\n",
      "Epoch 1419: train_loss = 0.6193967461585999, valid_loss= 0.6049751043319702, accuracy= 67.5\n",
      "Epoch 1420: train_loss = 0.6219547986984253, valid_loss= 0.6008278131484985, accuracy= 69.375\n",
      "Epoch 1421: train_loss = 0.619347333908081, valid_loss= 0.5993635654449463, accuracy= 69.6875\n",
      "Epoch 1422: train_loss = 0.6136168837547302, valid_loss= 0.604302704334259, accuracy= 67.1875\n",
      "Epoch 1423: train_loss = 0.6151869297027588, valid_loss= 0.6017494797706604, accuracy= 68.75\n",
      "Epoch 1424: train_loss = 0.6183711886405945, valid_loss= 0.5980668663978577, accuracy= 67.1875\n",
      "Epoch 1425: train_loss = 0.6179289221763611, valid_loss= 0.5996034741401672, accuracy= 69.375\n",
      "Epoch 1426: train_loss = 0.609414279460907, valid_loss= 0.6093065738677979, accuracy= 67.8125\n",
      "Epoch 1427: train_loss = 0.6204622387886047, valid_loss= 0.6007376909255981, accuracy= 69.375\n",
      "Epoch 1428: train_loss = 0.6186904907226562, valid_loss= 0.5983022451400757, accuracy= 67.8125\n",
      "Epoch 1429: train_loss = 0.622209906578064, valid_loss= 0.6002119183540344, accuracy= 69.375\n",
      "Epoch 1430: train_loss = 0.6124863028526306, valid_loss= 0.6018820405006409, accuracy= 68.4375\n",
      "Epoch 1431: train_loss = 0.6179413199424744, valid_loss= 0.6002819538116455, accuracy= 68.4375\n",
      "Epoch 1432: train_loss = 0.6242879033088684, valid_loss= 0.5984320640563965, accuracy= 69.0625\n",
      "Epoch 1433: train_loss = 0.6232563853263855, valid_loss= 0.5984196662902832, accuracy= 69.0625\n",
      "Epoch 1434: train_loss = 0.6110550761222839, valid_loss= 0.5991182923316956, accuracy= 68.125\n",
      "Epoch 1435: train_loss = 0.6161690354347229, valid_loss= 0.6027802228927612, accuracy= 69.375\n",
      "Epoch 1436: train_loss = 0.6109055280685425, valid_loss= 0.6004157662391663, accuracy= 67.8125\n",
      "Epoch 1437: train_loss = 0.6224825382232666, valid_loss= 0.5980840921401978, accuracy= 68.125\n",
      "Epoch 1438: train_loss = 0.6080785989761353, valid_loss= 0.5984582304954529, accuracy= 68.4375\n",
      "Epoch 1439: train_loss = 0.6171720027923584, valid_loss= 0.599791407585144, accuracy= 68.125\n",
      "Epoch 1440: train_loss = 0.6253503561019897, valid_loss= 0.597186267375946, accuracy= 68.75\n",
      "Epoch 1441: train_loss = 0.6234779953956604, valid_loss= 0.5967692732810974, accuracy= 68.4375\n",
      "Epoch 1442: train_loss = 0.6114547252655029, valid_loss= 0.5993561148643494, accuracy= 69.0625\n",
      "Epoch 1443: train_loss = 0.6207113862037659, valid_loss= 0.5970112085342407, accuracy= 68.4375\n",
      "Epoch 1444: train_loss = 0.6169370412826538, valid_loss= 0.5950327515602112, accuracy= 68.4375\n",
      "Epoch 1445: train_loss = 0.614980936050415, valid_loss= 0.5949501991271973, accuracy= 68.75\n",
      "Epoch 1446: train_loss = 0.6250082850456238, valid_loss= 0.5934492349624634, accuracy= 68.4375\n",
      "Epoch 1447: train_loss = 0.6173954010009766, valid_loss= 0.5920654535293579, accuracy= 68.4375\n",
      "Epoch 1448: train_loss = 0.608973503112793, valid_loss= 0.5926896333694458, accuracy= 68.4375\n",
      "Epoch 1449: train_loss = 0.6233528852462769, valid_loss= 0.5944442749023438, accuracy= 69.0625\n",
      "Epoch 1450: train_loss = 0.6163163185119629, valid_loss= 0.5926368236541748, accuracy= 68.75\n",
      "Epoch 1451: train_loss = 0.6112270355224609, valid_loss= 0.5922234058380127, accuracy= 68.75\n",
      "Epoch 1452: train_loss = 0.620452880859375, valid_loss= 0.5921494960784912, accuracy= 68.4375\n",
      "Epoch 1453: train_loss = 0.6177515387535095, valid_loss= 0.5931698083877563, accuracy= 69.0625\n",
      "Epoch 1454: train_loss = 0.621647834777832, valid_loss= 0.5939887762069702, accuracy= 69.0625\n",
      "Epoch 1455: train_loss = 0.6107069849967957, valid_loss= 0.5951858758926392, accuracy= 69.0625\n",
      "Epoch 1456: train_loss = 0.6145294904708862, valid_loss= 0.593173086643219, accuracy= 68.125\n",
      "Epoch 1457: train_loss = 0.6270317435264587, valid_loss= 0.5953811407089233, accuracy= 69.0625\n",
      "Epoch 1458: train_loss = 0.6216380596160889, valid_loss= 0.5957459807395935, accuracy= 69.375\n",
      "Epoch 1459: train_loss = 0.6076671481132507, valid_loss= 0.5947452187538147, accuracy= 68.75\n",
      "Epoch 1460: train_loss = 0.6168760657310486, valid_loss= 0.5951929092407227, accuracy= 68.75\n",
      "Epoch 1461: train_loss = 0.6167147159576416, valid_loss= 0.5955284833908081, accuracy= 69.0625\n",
      "Epoch 1462: train_loss = 0.6114636063575745, valid_loss= 0.5929733514785767, accuracy= 68.125\n",
      "Epoch 1463: train_loss = 0.6127730011940002, valid_loss= 0.5930821895599365, accuracy= 68.75\n",
      "Epoch 1464: train_loss = 0.605980634689331, valid_loss= 0.5966814160346985, accuracy= 69.375\n",
      "Epoch 1465: train_loss = 0.6131542921066284, valid_loss= 0.5900946855545044, accuracy= 68.125\n",
      "Epoch 1466: train_loss = 0.6046314835548401, valid_loss= 0.5907802581787109, accuracy= 68.4375\n",
      "Epoch 1467: train_loss = 0.5994647145271301, valid_loss= 0.5998692512512207, accuracy= 67.1875\n",
      "Epoch 1468: train_loss = 0.629967212677002, valid_loss= 0.5889565348625183, accuracy= 67.5\n",
      "Epoch 1469: train_loss = 0.6147354245185852, valid_loss= 0.5899483561515808, accuracy= 68.75\n",
      "Epoch 1470: train_loss = 0.6119092106819153, valid_loss= 0.5917347073554993, accuracy= 68.75\n",
      "Epoch 1471: train_loss = 0.6113991141319275, valid_loss= 0.5929709672927856, accuracy= 69.0625\n",
      "Epoch 1472: train_loss = 0.6148315668106079, valid_loss= 0.5894266963005066, accuracy= 68.125\n",
      "Epoch 1473: train_loss = 0.6205323934555054, valid_loss= 0.5890840291976929, accuracy= 67.1875\n",
      "Epoch 1474: train_loss = 0.6145419478416443, valid_loss= 0.5953623652458191, accuracy= 69.6875\n",
      "Epoch 1475: train_loss = 0.6132605671882629, valid_loss= 0.5898477435112, accuracy= 69.375\n",
      "Epoch 1476: train_loss = 0.616468608379364, valid_loss= 0.5871374607086182, accuracy= 67.8125\n",
      "Epoch 1477: train_loss = 0.6233308911323547, valid_loss= 0.5879837274551392, accuracy= 68.4375\n",
      "Epoch 1478: train_loss = 0.6212405562400818, valid_loss= 0.5933684706687927, accuracy= 69.375\n",
      "Epoch 1479: train_loss = 0.6101927161216736, valid_loss= 0.5861016511917114, accuracy= 67.8125\n",
      "Epoch 1480: train_loss = 0.6134010553359985, valid_loss= 0.5857412815093994, accuracy= 69.0625\n",
      "Epoch 1481: train_loss = 0.6106662154197693, valid_loss= 0.5880982875823975, accuracy= 69.0625\n",
      "Epoch 1482: train_loss = 0.610990047454834, valid_loss= 0.5861076712608337, accuracy= 68.4375\n",
      "Epoch 1483: train_loss = 0.6140563488006592, valid_loss= 0.589515745639801, accuracy= 68.4375\n",
      "Epoch 1484: train_loss = 0.6122993230819702, valid_loss= 0.5855907201766968, accuracy= 69.0625\n",
      "Epoch 1485: train_loss = 0.6141617298126221, valid_loss= 0.588176429271698, accuracy= 67.5\n",
      "Epoch 1486: train_loss = 0.6127711534500122, valid_loss= 0.5929166674613953, accuracy= 70.3125\n",
      "Epoch 1487: train_loss = 0.6122392416000366, valid_loss= 0.5895687341690063, accuracy= 68.4375\n",
      "Epoch 1488: train_loss = 0.613570511341095, valid_loss= 0.588175356388092, accuracy= 67.1875\n",
      "Epoch 1489: train_loss = 0.6231914758682251, valid_loss= 0.5873841047286987, accuracy= 68.125\n",
      "Epoch 1490: train_loss = 0.6116681694984436, valid_loss= 0.5929957628250122, accuracy= 69.375\n",
      "Epoch 1491: train_loss = 0.6083472371101379, valid_loss= 0.5878790616989136, accuracy= 67.8125\n",
      "Epoch 1492: train_loss = 0.6108949780464172, valid_loss= 0.5878670811653137, accuracy= 68.125\n",
      "Epoch 1493: train_loss = 0.6136061549186707, valid_loss= 0.5901873707771301, accuracy= 68.75\n",
      "Epoch 1494: train_loss = 0.6214084029197693, valid_loss= 0.5889628529548645, accuracy= 69.0625\n",
      "Epoch 1495: train_loss = 0.6121820211410522, valid_loss= 0.588263988494873, accuracy= 67.8125\n",
      "Epoch 1496: train_loss = 0.6040521264076233, valid_loss= 0.5890083312988281, accuracy= 68.4375\n",
      "Epoch 1497: train_loss = 0.6124427318572998, valid_loss= 0.5880433320999146, accuracy= 69.0625\n",
      "Epoch 1498: train_loss = 0.6161070466041565, valid_loss= 0.5861624479293823, accuracy= 69.0625\n",
      "Epoch 1499: train_loss = 0.6151236891746521, valid_loss= 0.5852888226509094, accuracy= 68.4375\n",
      "Epoch 1500: train_loss = 0.6264395117759705, valid_loss= 0.5864591598510742, accuracy= 69.0625\n",
      "Epoch 1501: train_loss = 0.6163185238838196, valid_loss= 0.5917848348617554, accuracy= 68.125\n",
      "Epoch 1502: train_loss = 0.6185606718063354, valid_loss= 0.5871555209159851, accuracy= 68.125\n",
      "Epoch 1503: train_loss = 0.5989387631416321, valid_loss= 0.5847893357276917, accuracy= 69.6875\n",
      "Epoch 1504: train_loss = 0.6105620861053467, valid_loss= 0.5858147740364075, accuracy= 69.0625\n",
      "Epoch 1505: train_loss = 0.6059594750404358, valid_loss= 0.5846787095069885, accuracy= 69.0625\n",
      "Epoch 1506: train_loss = 0.6058081984519958, valid_loss= 0.5843715667724609, accuracy= 69.375\n",
      "Epoch 1507: train_loss = 0.6137981414794922, valid_loss= 0.5896158814430237, accuracy= 69.0625\n",
      "Epoch 1508: train_loss = 0.6070297956466675, valid_loss= 0.5866308808326721, accuracy= 68.75\n",
      "Epoch 1509: train_loss = 0.5986765027046204, valid_loss= 0.5842798352241516, accuracy= 69.0625\n",
      "Epoch 1510: train_loss = 0.6057763695716858, valid_loss= 0.5849303603172302, accuracy= 68.125\n",
      "Epoch 1511: train_loss = 0.614952802658081, valid_loss= 0.5860685110092163, accuracy= 69.0625\n",
      "Epoch 1512: train_loss = 0.6105893850326538, valid_loss= 0.581344723701477, accuracy= 68.4375\n",
      "Epoch 1513: train_loss = 0.606539785861969, valid_loss= 0.5806995034217834, accuracy= 68.4375\n",
      "Epoch 1514: train_loss = 0.6081409454345703, valid_loss= 0.5796669721603394, accuracy= 68.125\n",
      "Epoch 1515: train_loss = 0.6079632043838501, valid_loss= 0.5791156888008118, accuracy= 68.75\n",
      "Epoch 1516: train_loss = 0.6037716269493103, valid_loss= 0.580638587474823, accuracy= 68.4375\n",
      "Epoch 1517: train_loss = 0.6110156774520874, valid_loss= 0.5809349417686462, accuracy= 68.125\n",
      "Epoch 1518: train_loss = 0.597424328327179, valid_loss= 0.5791910290718079, accuracy= 68.4375\n",
      "Epoch 1519: train_loss = 0.6067584156990051, valid_loss= 0.5797983407974243, accuracy= 68.4375\n",
      "Epoch 1520: train_loss = 0.6042612791061401, valid_loss= 0.5806375741958618, accuracy= 68.4375\n",
      "Epoch 1521: train_loss = 0.6105958223342896, valid_loss= 0.5800992250442505, accuracy= 67.5\n",
      "Epoch 1522: train_loss = 0.6144391298294067, valid_loss= 0.5958418250083923, accuracy= 70.0\n",
      "Epoch 1523: train_loss = 0.6196290254592896, valid_loss= 0.5799221396446228, accuracy= 68.125\n",
      "Epoch 1524: train_loss = 0.6095367670059204, valid_loss= 0.5804765224456787, accuracy= 68.125\n",
      "Epoch 1525: train_loss = 0.6084650158882141, valid_loss= 0.582595705986023, accuracy= 68.75\n",
      "Epoch 1526: train_loss = 0.615727961063385, valid_loss= 0.5788846611976624, accuracy= 68.4375\n",
      "Epoch 1527: train_loss = 0.6019985675811768, valid_loss= 0.5793134570121765, accuracy= 69.375\n",
      "Epoch 1528: train_loss = 0.6113619804382324, valid_loss= 0.5819045305252075, accuracy= 69.6875\n",
      "Epoch 1529: train_loss = 0.6055052280426025, valid_loss= 0.5809618234634399, accuracy= 69.0625\n",
      "Epoch 1530: train_loss = 0.5966253280639648, valid_loss= 0.583276093006134, accuracy= 68.75\n",
      "Epoch 1531: train_loss = 0.6111008524894714, valid_loss= 0.5806795954704285, accuracy= 68.75\n",
      "Epoch 1532: train_loss = 0.6037852168083191, valid_loss= 0.5807268619537354, accuracy= 67.5\n",
      "Epoch 1533: train_loss = 0.6149219870567322, valid_loss= 0.5900618433952332, accuracy= 69.375\n",
      "Epoch 1534: train_loss = 0.6011641025543213, valid_loss= 0.5790949463844299, accuracy= 68.4375\n",
      "Epoch 1535: train_loss = 0.5929946303367615, valid_loss= 0.5769141912460327, accuracy= 69.0625\n",
      "Epoch 1536: train_loss = 0.6006746292114258, valid_loss= 0.5768628716468811, accuracy= 68.75\n",
      "Epoch 1537: train_loss = 0.6131381392478943, valid_loss= 0.5754075050354004, accuracy= 68.125\n",
      "Epoch 1538: train_loss = 0.6099960207939148, valid_loss= 0.5836378931999207, accuracy= 68.75\n",
      "Epoch 1539: train_loss = 0.6061626672744751, valid_loss= 0.577043354511261, accuracy= 66.875\n",
      "Epoch 1540: train_loss = 0.6018512845039368, valid_loss= 0.5807655453681946, accuracy= 68.75\n",
      "Epoch 1541: train_loss = 0.6072831153869629, valid_loss= 0.5809677839279175, accuracy= 68.75\n",
      "Epoch 1542: train_loss = 0.6116486191749573, valid_loss= 0.5793684720993042, accuracy= 67.8125\n",
      "Epoch 1543: train_loss = 0.608677089214325, valid_loss= 0.5838341116905212, accuracy= 69.375\n",
      "Epoch 1544: train_loss = 0.6031349301338196, valid_loss= 0.5795490145683289, accuracy= 69.375\n",
      "Epoch 1545: train_loss = 0.6112145781517029, valid_loss= 0.5790241956710815, accuracy= 69.0625\n",
      "Epoch 1546: train_loss = 0.6113108992576599, valid_loss= 0.5789422988891602, accuracy= 69.375\n",
      "Epoch 1547: train_loss = 0.5953377485275269, valid_loss= 0.5776434540748596, accuracy= 69.0625\n",
      "Epoch 1548: train_loss = 0.60477215051651, valid_loss= 0.576352596282959, accuracy= 69.0625\n",
      "Epoch 1549: train_loss = 0.5995330810546875, valid_loss= 0.5768592953681946, accuracy= 68.75\n",
      "Epoch 1550: train_loss = 0.6021572947502136, valid_loss= 0.5777437090873718, accuracy= 68.4375\n",
      "Epoch 1551: train_loss = 0.5997580289840698, valid_loss= 0.5773695707321167, accuracy= 68.125\n",
      "Epoch 1552: train_loss = 0.5952216982841492, valid_loss= 0.5769292712211609, accuracy= 68.4375\n",
      "Epoch 1553: train_loss = 0.5992283821105957, valid_loss= 0.5887593626976013, accuracy= 71.25\n",
      "Epoch 1554: train_loss = 0.6084998846054077, valid_loss= 0.5779467821121216, accuracy= 69.0625\n",
      "Epoch 1555: train_loss = 0.6125872731208801, valid_loss= 0.5759302377700806, accuracy= 68.75\n",
      "Epoch 1556: train_loss = 0.6139712333679199, valid_loss= 0.5770334005355835, accuracy= 69.0625\n",
      "Epoch 1557: train_loss = 0.6081831455230713, valid_loss= 0.5825316309928894, accuracy= 70.0\n",
      "Epoch 1558: train_loss = 0.6038645505905151, valid_loss= 0.5779560208320618, accuracy= 69.0625\n",
      "Epoch 1559: train_loss = 0.6003627181053162, valid_loss= 0.5786013007164001, accuracy= 68.75\n",
      "Epoch 1560: train_loss = 0.6037296056747437, valid_loss= 0.5785059332847595, accuracy= 68.75\n",
      "Epoch 1561: train_loss = 0.6070222854614258, valid_loss= 0.5819042921066284, accuracy= 68.4375\n",
      "Epoch 1562: train_loss = 0.6092363595962524, valid_loss= 0.6216514110565186, accuracy= 67.5\n",
      "Epoch 1563: train_loss = 0.6014047861099243, valid_loss= 0.5868211388587952, accuracy= 65.3125\n",
      "Epoch 1564: train_loss = 0.6168385744094849, valid_loss= 0.5775747299194336, accuracy= 68.125\n",
      "Epoch 1565: train_loss = 0.6095408201217651, valid_loss= 0.6006038784980774, accuracy= 67.5\n",
      "Epoch 1566: train_loss = 0.6179153323173523, valid_loss= 0.5839531421661377, accuracy= 67.8125\n",
      "Epoch 1567: train_loss = 0.6153628826141357, valid_loss= 0.5803508162498474, accuracy= 68.75\n",
      "Epoch 1568: train_loss = 0.6094426512718201, valid_loss= 0.5817834734916687, accuracy= 67.8125\n",
      "Epoch 1569: train_loss = 0.6069019436836243, valid_loss= 0.5774920582771301, accuracy= 70.0\n",
      "Epoch 1570: train_loss = 0.5994772911071777, valid_loss= 0.5767368674278259, accuracy= 69.6875\n",
      "Epoch 1571: train_loss = 0.6082072854042053, valid_loss= 0.5778146982192993, accuracy= 70.0\n",
      "Epoch 1572: train_loss = 0.5997636318206787, valid_loss= 0.5742923021316528, accuracy= 69.0625\n",
      "Epoch 1573: train_loss = 0.5993004441261292, valid_loss= 0.5729581117630005, accuracy= 68.125\n",
      "Epoch 1574: train_loss = 0.6092360615730286, valid_loss= 0.5778564810752869, accuracy= 69.6875\n",
      "Epoch 1575: train_loss = 0.5947922468185425, valid_loss= 0.5738359093666077, accuracy= 69.0625\n",
      "Epoch 1576: train_loss = 0.6039638519287109, valid_loss= 0.5730911493301392, accuracy= 69.0625\n",
      "Epoch 1577: train_loss = 0.5997319221496582, valid_loss= 0.5735985040664673, accuracy= 68.75\n",
      "Epoch 1578: train_loss = 0.6046034693717957, valid_loss= 0.576774001121521, accuracy= 69.0625\n",
      "Epoch 1579: train_loss = 0.6019071936607361, valid_loss= 0.5733605623245239, accuracy= 69.6875\n",
      "Epoch 1580: train_loss = 0.5937565565109253, valid_loss= 0.5838502645492554, accuracy= 70.0\n",
      "Epoch 1581: train_loss = 0.6006209850311279, valid_loss= 0.5722008943557739, accuracy= 70.0\n",
      "Epoch 1582: train_loss = 0.5963399410247803, valid_loss= 0.5760465264320374, accuracy= 68.75\n",
      "Epoch 1583: train_loss = 0.5980889797210693, valid_loss= 0.571820855140686, accuracy= 70.3125\n",
      "Epoch 1584: train_loss = 0.6048821210861206, valid_loss= 0.576138973236084, accuracy= 68.4375\n",
      "Epoch 1585: train_loss = 0.5928887128829956, valid_loss= 0.5723056197166443, accuracy= 69.0625\n",
      "Epoch 1586: train_loss = 0.5965413451194763, valid_loss= 0.5715190172195435, accuracy= 69.0625\n",
      "Epoch 1587: train_loss = 0.589946448802948, valid_loss= 0.5731112957000732, accuracy= 68.4375\n",
      "Epoch 1588: train_loss = 0.6082841157913208, valid_loss= 0.5845836997032166, accuracy= 66.5625\n",
      "Epoch 1589: train_loss = 0.6041315793991089, valid_loss= 0.6041789054870605, accuracy= 67.8125\n",
      "Epoch 1590: train_loss = 0.6166792511940002, valid_loss= 0.5977516770362854, accuracy= 66.5625\n",
      "Epoch 1591: train_loss = 0.6192975044250488, valid_loss= 0.5786355137825012, accuracy= 70.3125\n",
      "Epoch 1592: train_loss = 0.6025567054748535, valid_loss= 0.5929229855537415, accuracy= 68.4375\n",
      "Epoch 1593: train_loss = 0.6078217029571533, valid_loss= 0.6118186116218567, accuracy= 65.9375\n",
      "Epoch 1594: train_loss = 0.6362662315368652, valid_loss= 0.5812558531761169, accuracy= 69.375\n",
      "Epoch 1595: train_loss = 0.6043916344642639, valid_loss= 0.6280962228775024, accuracy= 64.0625\n",
      "Epoch 1596: train_loss = 0.6343095898628235, valid_loss= 0.5906111598014832, accuracy= 69.0625\n",
      "Epoch 1597: train_loss = 0.6115145087242126, valid_loss= 0.5860685110092163, accuracy= 68.75\n",
      "Epoch 1598: train_loss = 0.6094516515731812, valid_loss= 0.6032980680465698, accuracy= 67.5\n",
      "Epoch 1599: train_loss = 0.6202552318572998, valid_loss= 0.5808200836181641, accuracy= 68.75\n",
      "Epoch 1600: train_loss = 0.6092477440834045, valid_loss= 0.5800334215164185, accuracy= 68.75\n",
      "Epoch 1601: train_loss = 0.6005216240882874, valid_loss= 0.5931850075721741, accuracy= 68.75\n",
      "Epoch 1602: train_loss = 0.6052926182746887, valid_loss= 0.5780378580093384, accuracy= 68.4375\n",
      "Epoch 1603: train_loss = 0.5954765677452087, valid_loss= 0.5776012539863586, accuracy= 69.0625\n",
      "Epoch 1604: train_loss = 0.5909435749053955, valid_loss= 0.5860716104507446, accuracy= 67.5\n",
      "Epoch 1605: train_loss = 0.6007232666015625, valid_loss= 0.57732093334198, accuracy= 68.125\n",
      "Epoch 1606: train_loss = 0.6103146076202393, valid_loss= 0.5771497488021851, accuracy= 68.125\n",
      "Epoch 1607: train_loss = 0.5934930443763733, valid_loss= 0.5857957601547241, accuracy= 69.375\n",
      "Epoch 1608: train_loss = 0.5980451703071594, valid_loss= 0.5759621858596802, accuracy= 68.75\n",
      "Epoch 1609: train_loss = 0.6056000590324402, valid_loss= 0.5756643414497375, accuracy= 69.6875\n",
      "Epoch 1610: train_loss = 0.6057112812995911, valid_loss= 0.5719558000564575, accuracy= 68.125\n",
      "Epoch 1611: train_loss = 0.6135936975479126, valid_loss= 0.5742177367210388, accuracy= 70.625\n",
      "Epoch 1612: train_loss = 0.6085737347602844, valid_loss= 0.5782899856567383, accuracy= 71.5625\n",
      "Epoch 1613: train_loss = 0.6052249073982239, valid_loss= 0.5715247988700867, accuracy= 69.6875\n",
      "Epoch 1614: train_loss = 0.5994289517402649, valid_loss= 0.5716217756271362, accuracy= 68.4375\n",
      "Epoch 1615: train_loss = 0.5949424505233765, valid_loss= 0.5762939453125, accuracy= 69.6875\n",
      "Epoch 1616: train_loss = 0.5989912748336792, valid_loss= 0.5732625722885132, accuracy= 70.3125\n",
      "Epoch 1617: train_loss = 0.5998927354812622, valid_loss= 0.5858251452445984, accuracy= 70.3125\n",
      "Epoch 1618: train_loss = 0.5975676774978638, valid_loss= 0.5697304010391235, accuracy= 69.0625\n",
      "Epoch 1619: train_loss = 0.5942731499671936, valid_loss= 0.5688087344169617, accuracy= 69.0625\n",
      "Epoch 1620: train_loss = 0.6049791574478149, valid_loss= 0.5760653018951416, accuracy= 70.9375\n",
      "Epoch 1621: train_loss = 0.5956745147705078, valid_loss= 0.5711867213249207, accuracy= 70.0\n",
      "Epoch 1622: train_loss = 0.6028159260749817, valid_loss= 0.5769961476325989, accuracy= 71.875\n",
      "Epoch 1623: train_loss = 0.5912706255912781, valid_loss= 0.5661980509757996, accuracy= 69.375\n",
      "Epoch 1624: train_loss = 0.5907732844352722, valid_loss= 0.5675322413444519, accuracy= 69.0625\n",
      "Epoch 1625: train_loss = 0.6004546880722046, valid_loss= 0.5673457384109497, accuracy= 71.5625\n",
      "Epoch 1626: train_loss = 0.5945090651512146, valid_loss= 0.5957282185554504, accuracy= 69.375\n",
      "Epoch 1627: train_loss = 0.6142175197601318, valid_loss= 0.6119576692581177, accuracy= 63.4375\n",
      "Epoch 1628: train_loss = 0.6398763060569763, valid_loss= 0.5817469358444214, accuracy= 69.375\n",
      "Epoch 1629: train_loss = 0.6008658409118652, valid_loss= 0.590886116027832, accuracy= 68.4375\n",
      "Epoch 1630: train_loss = 0.6043621897697449, valid_loss= 0.5886145830154419, accuracy= 67.8125\n",
      "Epoch 1631: train_loss = 0.6098785400390625, valid_loss= 0.5753841400146484, accuracy= 70.0\n",
      "Epoch 1632: train_loss = 0.5913107991218567, valid_loss= 0.6037195920944214, accuracy= 66.5625\n",
      "Epoch 1633: train_loss = 0.6106464862823486, valid_loss= 0.5844471454620361, accuracy= 69.375\n",
      "Epoch 1634: train_loss = 0.6122267842292786, valid_loss= 0.574983537197113, accuracy= 69.6875\n",
      "Epoch 1635: train_loss = 0.5962443947792053, valid_loss= 0.6089320778846741, accuracy= 66.875\n",
      "Epoch 1636: train_loss = 0.6122876405715942, valid_loss= 0.5815677642822266, accuracy= 67.8125\n",
      "Epoch 1637: train_loss = 0.6138272881507874, valid_loss= 0.5728965401649475, accuracy= 68.4375\n",
      "Epoch 1638: train_loss = 0.5875392556190491, valid_loss= 0.5961671471595764, accuracy= 67.8125\n",
      "Epoch 1639: train_loss = 0.6122822761535645, valid_loss= 0.5815569758415222, accuracy= 66.5625\n",
      "Epoch 1640: train_loss = 0.6092168092727661, valid_loss= 0.5721573829650879, accuracy= 68.4375\n",
      "Epoch 1641: train_loss = 0.5974574685096741, valid_loss= 0.6021418571472168, accuracy= 68.125\n",
      "Epoch 1642: train_loss = 0.6035968661308289, valid_loss= 0.5818325877189636, accuracy= 66.5625\n",
      "Epoch 1643: train_loss = 0.6041387915611267, valid_loss= 0.5721664428710938, accuracy= 68.75\n",
      "Epoch 1644: train_loss = 0.5888541340827942, valid_loss= 0.5925060510635376, accuracy= 69.375\n",
      "Epoch 1645: train_loss = 0.5995267033576965, valid_loss= 0.5777648687362671, accuracy= 70.3125\n",
      "Epoch 1646: train_loss = 0.6158011555671692, valid_loss= 0.5719512701034546, accuracy= 69.6875\n",
      "Epoch 1647: train_loss = 0.5867474675178528, valid_loss= 0.5741232633590698, accuracy= 70.3125\n",
      "Epoch 1648: train_loss = 0.5850639939308167, valid_loss= 0.5682505369186401, accuracy= 69.6875\n",
      "Epoch 1649: train_loss = 0.5899094939231873, valid_loss= 0.5669825673103333, accuracy= 70.0\n",
      "Epoch 1650: train_loss = 0.591370701789856, valid_loss= 0.5709239840507507, accuracy= 69.0625\n",
      "Epoch 1651: train_loss = 0.594169557094574, valid_loss= 0.5687787532806396, accuracy= 70.0\n",
      "Epoch 1652: train_loss = 0.5985232591629028, valid_loss= 0.5765469074249268, accuracy= 69.6875\n",
      "Epoch 1653: train_loss = 0.5889220237731934, valid_loss= 0.5666099190711975, accuracy= 69.375\n",
      "Epoch 1654: train_loss = 0.5881531834602356, valid_loss= 0.5821176171302795, accuracy= 69.0625\n",
      "Epoch 1655: train_loss = 0.6057794094085693, valid_loss= 0.5725221633911133, accuracy= 69.0625\n",
      "Epoch 1656: train_loss = 0.5972055792808533, valid_loss= 0.587835431098938, accuracy= 70.9375\n",
      "Epoch 1657: train_loss = 0.5959989428520203, valid_loss= 0.5665792226791382, accuracy= 69.375\n",
      "Epoch 1658: train_loss = 0.6065874099731445, valid_loss= 0.5654486417770386, accuracy= 69.375\n",
      "Epoch 1659: train_loss = 0.5907682776451111, valid_loss= 0.5731406807899475, accuracy= 70.625\n",
      "Epoch 1660: train_loss = 0.6034502387046814, valid_loss= 0.5673693418502808, accuracy= 69.6875\n",
      "Epoch 1661: train_loss = 0.5950026512145996, valid_loss= 0.5675415992736816, accuracy= 70.625\n",
      "Epoch 1662: train_loss = 0.5934917330741882, valid_loss= 0.5743091106414795, accuracy= 71.5625\n",
      "Epoch 1663: train_loss = 0.5992410778999329, valid_loss= 0.5679463148117065, accuracy= 68.75\n",
      "Epoch 1664: train_loss = 0.5960688591003418, valid_loss= 0.5711125731468201, accuracy= 70.625\n",
      "Epoch 1665: train_loss = 0.5955294966697693, valid_loss= 0.5654601454734802, accuracy= 70.9375\n",
      "Epoch 1666: train_loss = 0.5926764607429504, valid_loss= 0.590612530708313, accuracy= 70.0\n",
      "Epoch 1667: train_loss = 0.607305109500885, valid_loss= 0.6164209842681885, accuracy= 63.74999999999999\n",
      "Epoch 1668: train_loss = 0.630392849445343, valid_loss= 0.5833410620689392, accuracy= 68.4375\n",
      "Epoch 1669: train_loss = 0.6148766875267029, valid_loss= 0.5782275199890137, accuracy= 68.4375\n",
      "Epoch 1670: train_loss = 0.5916251540184021, valid_loss= 0.5759441256523132, accuracy= 69.6875\n",
      "Epoch 1671: train_loss = 0.6002873182296753, valid_loss= 0.5720062255859375, accuracy= 70.3125\n",
      "Epoch 1672: train_loss = 0.5863474607467651, valid_loss= 0.5938708186149597, accuracy= 69.375\n",
      "Epoch 1673: train_loss = 0.6066133975982666, valid_loss= 0.5932056903839111, accuracy= 66.25\n",
      "Epoch 1674: train_loss = 0.6239404678344727, valid_loss= 0.5851410031318665, accuracy= 70.0\n",
      "Epoch 1675: train_loss = 0.5895118713378906, valid_loss= 0.5725855231285095, accuracy= 69.0625\n",
      "Epoch 1676: train_loss = 0.5899128913879395, valid_loss= 0.5756088495254517, accuracy= 66.5625\n",
      "Epoch 1677: train_loss = 0.6158573627471924, valid_loss= 0.5929383039474487, accuracy= 69.375\n",
      "Epoch 1678: train_loss = 0.5955690145492554, valid_loss= 0.5735061764717102, accuracy= 70.3125\n",
      "Epoch 1679: train_loss = 0.6009671092033386, valid_loss= 0.5675181150436401, accuracy= 68.75\n",
      "Epoch 1680: train_loss = 0.5937668681144714, valid_loss= 0.5986379384994507, accuracy= 68.125\n",
      "Epoch 1681: train_loss = 0.6006144285202026, valid_loss= 0.59950190782547, accuracy= 66.875\n",
      "Epoch 1682: train_loss = 0.6200117468833923, valid_loss= 0.568997859954834, accuracy= 70.3125\n",
      "Epoch 1683: train_loss = 0.595443606376648, valid_loss= 0.6066092252731323, accuracy= 66.875\n",
      "Epoch 1684: train_loss = 0.6168100237846375, valid_loss= 0.6291800141334534, accuracy= 60.3125\n",
      "Epoch 1685: train_loss = 0.6521590948104858, valid_loss= 0.5838603973388672, accuracy= 69.375\n",
      "Epoch 1686: train_loss = 0.6041885018348694, valid_loss= 0.61902916431427, accuracy= 64.0625\n",
      "Epoch 1687: train_loss = 0.6187986731529236, valid_loss= 0.5798828601837158, accuracy= 69.0625\n",
      "Epoch 1688: train_loss = 0.6013920307159424, valid_loss= 0.5828749537467957, accuracy= 68.75\n",
      "Epoch 1689: train_loss = 0.5974556803703308, valid_loss= 0.5753452181816101, accuracy= 70.3125\n",
      "Epoch 1690: train_loss = 0.5870097875595093, valid_loss= 0.5740674734115601, accuracy= 69.375\n",
      "Epoch 1691: train_loss = 0.6001935005187988, valid_loss= 0.5677832365036011, accuracy= 71.875\n",
      "Epoch 1692: train_loss = 0.5979675054550171, valid_loss= 0.574833869934082, accuracy= 69.375\n",
      "Epoch 1693: train_loss = 0.5912677645683289, valid_loss= 0.5665143132209778, accuracy= 71.25\n",
      "Epoch 1694: train_loss = 0.5926711559295654, valid_loss= 0.5771668553352356, accuracy= 70.0\n",
      "Epoch 1695: train_loss = 0.5978100895881653, valid_loss= 0.5738179087638855, accuracy= 67.8125\n",
      "Epoch 1696: train_loss = 0.5967161655426025, valid_loss= 0.5804730653762817, accuracy= 70.0\n",
      "Epoch 1697: train_loss = 0.6045595407485962, valid_loss= 0.570624589920044, accuracy= 70.9375\n",
      "Epoch 1698: train_loss = 0.5996918082237244, valid_loss= 0.5656365156173706, accuracy= 70.3125\n",
      "Epoch 1699: train_loss = 0.5893380641937256, valid_loss= 0.5683398842811584, accuracy= 70.3125\n",
      "Epoch 1700: train_loss = 0.5810502171516418, valid_loss= 0.5615774393081665, accuracy= 69.375\n",
      "Epoch 1701: train_loss = 0.5961301922798157, valid_loss= 0.5670253038406372, accuracy= 69.6875\n",
      "Epoch 1702: train_loss = 0.5836299061775208, valid_loss= 0.5613530278205872, accuracy= 70.9375\n",
      "Epoch 1703: train_loss = 0.5837039351463318, valid_loss= 0.5736099481582642, accuracy= 71.25\n",
      "Epoch 1704: train_loss = 0.600003182888031, valid_loss= 0.6115075945854187, accuracy= 64.6875\n",
      "Epoch 1705: train_loss = 0.6280439496040344, valid_loss= 0.6258114576339722, accuracy= 68.125\n",
      "Epoch 1706: train_loss = 0.6206054091453552, valid_loss= 0.6064695119857788, accuracy= 65.0\n",
      "Epoch 1707: train_loss = 0.6244978904724121, valid_loss= 0.5782473087310791, accuracy= 70.0\n",
      "Epoch 1708: train_loss = 0.5926699638366699, valid_loss= 0.6241117715835571, accuracy= 65.625\n",
      "Epoch 1709: train_loss = 0.6290478110313416, valid_loss= 0.5802575945854187, accuracy= 69.375\n",
      "Epoch 1710: train_loss = 0.592162549495697, valid_loss= 0.5784968137741089, accuracy= 69.0625\n",
      "Epoch 1711: train_loss = 0.5997633934020996, valid_loss= 0.5996201038360596, accuracy= 67.8125\n",
      "Epoch 1712: train_loss = 0.6053049564361572, valid_loss= 0.571487307548523, accuracy= 68.4375\n",
      "Epoch 1713: train_loss = 0.5909422636032104, valid_loss= 0.5697927474975586, accuracy= 69.0625\n",
      "Epoch 1714: train_loss = 0.5928082466125488, valid_loss= 0.5807896256446838, accuracy= 69.375\n",
      "Epoch 1715: train_loss = 0.5876136422157288, valid_loss= 0.5661781430244446, accuracy= 68.75\n",
      "Epoch 1716: train_loss = 0.5854148864746094, valid_loss= 0.5656769871711731, accuracy= 71.875\n",
      "Epoch 1717: train_loss = 0.5855323672294617, valid_loss= 0.5781048536300659, accuracy= 70.3125\n",
      "Epoch 1718: train_loss = 0.587073564529419, valid_loss= 0.5614098310470581, accuracy= 70.3125\n",
      "Epoch 1719: train_loss = 0.6018024682998657, valid_loss= 0.5613869428634644, accuracy= 69.0625\n",
      "Epoch 1720: train_loss = 0.5870273113250732, valid_loss= 0.5610613822937012, accuracy= 69.6875\n",
      "Epoch 1721: train_loss = 0.5872235298156738, valid_loss= 0.5581405758857727, accuracy= 70.625\n",
      "Epoch 1722: train_loss = 0.583858072757721, valid_loss= 0.559012770652771, accuracy= 70.625\n",
      "Epoch 1723: train_loss = 0.5877010226249695, valid_loss= 0.5615103244781494, accuracy= 70.9375\n",
      "Epoch 1724: train_loss = 0.572563111782074, valid_loss= 0.5588523745536804, accuracy= 70.9375\n",
      "Epoch 1725: train_loss = 0.5951992869377136, valid_loss= 0.5613453984260559, accuracy= 71.25\n",
      "Epoch 1726: train_loss = 0.5888950824737549, valid_loss= 0.6341519951820374, accuracy= 69.375\n",
      "Epoch 1727: train_loss = 0.641814112663269, valid_loss= 0.7095882296562195, accuracy= 51.5625\n",
      "Epoch 1728: train_loss = 0.7229828238487244, valid_loss= 0.629319965839386, accuracy= 65.3125\n",
      "Epoch 1729: train_loss = 0.6402232646942139, valid_loss= 0.6384540796279907, accuracy= 60.3125\n",
      "Epoch 1730: train_loss = 0.6529726386070251, valid_loss= 0.6478660106658936, accuracy= 61.25000000000001\n",
      "Epoch 1731: train_loss = 0.6504135131835938, valid_loss= 0.5985191464424133, accuracy= 64.375\n",
      "Epoch 1732: train_loss = 0.6092497706413269, valid_loss= 0.6000591516494751, accuracy= 67.8125\n",
      "Epoch 1733: train_loss = 0.6290421485900879, valid_loss= 0.5863538980484009, accuracy= 68.75\n",
      "Epoch 1734: train_loss = 0.6010233163833618, valid_loss= 0.6138127446174622, accuracy= 67.5\n",
      "Epoch 1735: train_loss = 0.6135441660881042, valid_loss= 0.584802508354187, accuracy= 67.5\n",
      "Epoch 1736: train_loss = 0.5970730781555176, valid_loss= 0.5808402895927429, accuracy= 69.6875\n",
      "Epoch 1737: train_loss = 0.6039472818374634, valid_loss= 0.579750657081604, accuracy= 68.75\n",
      "Epoch 1738: train_loss = 0.5966535210609436, valid_loss= 0.5895258188247681, accuracy= 67.5\n",
      "Epoch 1739: train_loss = 0.6037605404853821, valid_loss= 0.5758420825004578, accuracy= 69.6875\n",
      "Epoch 1740: train_loss = 0.5936369895935059, valid_loss= 0.5773585438728333, accuracy= 68.75\n",
      "Epoch 1741: train_loss = 0.5948137044906616, valid_loss= 0.5675928592681885, accuracy= 69.375\n",
      "Epoch 1742: train_loss = 0.587144136428833, valid_loss= 0.5645266771316528, accuracy= 70.0\n",
      "Epoch 1743: train_loss = 0.5874929428100586, valid_loss= 0.5760579109191895, accuracy= 70.9375\n",
      "Epoch 1744: train_loss = 0.5919724702835083, valid_loss= 0.5670508146286011, accuracy= 70.3125\n",
      "Epoch 1745: train_loss = 0.6020446419715881, valid_loss= 0.5788949728012085, accuracy= 72.1875\n",
      "Epoch 1746: train_loss = 0.5832259654998779, valid_loss= 0.5625496506690979, accuracy= 71.25\n",
      "Epoch 1747: train_loss = 0.5891507267951965, valid_loss= 0.5624566078186035, accuracy= 69.0625\n",
      "Epoch 1748: train_loss = 0.5860642194747925, valid_loss= 0.5773574709892273, accuracy= 72.1875\n",
      "Epoch 1749: train_loss = 0.5899030566215515, valid_loss= 0.5714612603187561, accuracy= 69.6875\n",
      "Epoch 1750: train_loss = 0.5932350158691406, valid_loss= 0.5824989676475525, accuracy= 70.9375\n",
      "Epoch 1751: train_loss = 0.5860175490379333, valid_loss= 0.5657763481140137, accuracy= 71.25\n",
      "Epoch 1752: train_loss = 0.5981053113937378, valid_loss= 0.5698642134666443, accuracy= 69.375\n",
      "Epoch 1753: train_loss = 0.5983134508132935, valid_loss= 0.5707648992538452, accuracy= 69.0625\n",
      "Epoch 1754: train_loss = 0.5955879092216492, valid_loss= 0.5855811834335327, accuracy= 70.3125\n",
      "Epoch 1755: train_loss = 0.6015562415122986, valid_loss= 0.5693183541297913, accuracy= 70.3125\n",
      "Epoch 1756: train_loss = 0.5947017669677734, valid_loss= 0.567475438117981, accuracy= 71.5625\n",
      "Epoch 1757: train_loss = 0.5834615230560303, valid_loss= 0.5686718821525574, accuracy= 71.25\n",
      "Epoch 1758: train_loss = 0.5924288034439087, valid_loss= 0.5657676458358765, accuracy= 70.9375\n",
      "Epoch 1759: train_loss = 0.5894100666046143, valid_loss= 0.5707355737686157, accuracy= 70.625\n",
      "Epoch 1760: train_loss = 0.5910905599594116, valid_loss= 0.5615910887718201, accuracy= 70.3125\n",
      "Epoch 1761: train_loss = 0.5804805755615234, valid_loss= 0.5692959427833557, accuracy= 70.0\n",
      "Epoch 1762: train_loss = 0.595295250415802, valid_loss= 0.5679506063461304, accuracy= 69.375\n",
      "Epoch 1763: train_loss = 0.602056622505188, valid_loss= 0.5769191384315491, accuracy= 70.0\n",
      "Epoch 1764: train_loss = 0.5975505709648132, valid_loss= 0.5679596066474915, accuracy= 71.25\n",
      "Epoch 1765: train_loss = 0.5915286540985107, valid_loss= 0.5752997398376465, accuracy= 69.6875\n",
      "Epoch 1766: train_loss = 0.6008559465408325, valid_loss= 0.5739924311637878, accuracy= 70.3125\n",
      "Epoch 1767: train_loss = 0.5909774303436279, valid_loss= 0.5685246586799622, accuracy= 70.0\n",
      "Epoch 1768: train_loss = 0.6024715304374695, valid_loss= 0.5612319707870483, accuracy= 70.0\n",
      "Epoch 1769: train_loss = 0.5812302827835083, valid_loss= 0.5623756051063538, accuracy= 70.9375\n",
      "Epoch 1770: train_loss = 0.5867812037467957, valid_loss= 0.575158417224884, accuracy= 72.1875\n",
      "Epoch 1771: train_loss = 0.5824135541915894, valid_loss= 0.5756230354309082, accuracy= 69.6875\n",
      "Epoch 1772: train_loss = 0.602866530418396, valid_loss= 0.5834916830062866, accuracy= 69.0625\n",
      "Epoch 1773: train_loss = 0.5958932638168335, valid_loss= 0.5816341042518616, accuracy= 69.0625\n",
      "Epoch 1774: train_loss = 0.5929518938064575, valid_loss= 0.5832257270812988, accuracy= 69.6875\n",
      "Epoch 1775: train_loss = 0.5863804817199707, valid_loss= 0.5618418455123901, accuracy= 70.3125\n",
      "Epoch 1776: train_loss = 0.5985053777694702, valid_loss= 0.5611599683761597, accuracy= 70.9375\n",
      "Epoch 1777: train_loss = 0.5743595957756042, valid_loss= 0.567458987236023, accuracy= 70.3125\n",
      "Epoch 1778: train_loss = 0.5785955786705017, valid_loss= 0.5665825605392456, accuracy= 68.75\n",
      "Epoch 1779: train_loss = 0.5985029339790344, valid_loss= 0.6020781397819519, accuracy= 70.9375\n",
      "Epoch 1780: train_loss = 0.6007267236709595, valid_loss= 0.6491320133209229, accuracy= 57.8125\n",
      "Epoch 1781: train_loss = 0.6563560366630554, valid_loss= 0.5733335018157959, accuracy= 70.0\n",
      "Epoch 1782: train_loss = 0.5941014289855957, valid_loss= 0.6268616318702698, accuracy= 66.5625\n",
      "Epoch 1783: train_loss = 0.6274776458740234, valid_loss= 0.5951899290084839, accuracy= 69.0625\n",
      "Epoch 1784: train_loss = 0.6176402568817139, valid_loss= 0.5746137499809265, accuracy= 69.0625\n",
      "Epoch 1785: train_loss = 0.5884262919425964, valid_loss= 0.6068681478500366, accuracy= 66.875\n",
      "Epoch 1786: train_loss = 0.5974392890930176, valid_loss= 0.5693582892417908, accuracy= 70.9375\n",
      "Epoch 1787: train_loss = 0.5915753245353699, valid_loss= 0.5723474621772766, accuracy= 70.9375\n",
      "Epoch 1788: train_loss = 0.5918717980384827, valid_loss= 0.5860439538955688, accuracy= 70.3125\n",
      "Epoch 1789: train_loss = 0.5857074856758118, valid_loss= 0.5662078857421875, accuracy= 69.6875\n",
      "Epoch 1790: train_loss = 0.586172342300415, valid_loss= 0.5648930072784424, accuracy= 69.375\n",
      "Epoch 1791: train_loss = 0.5833370685577393, valid_loss= 0.5910830497741699, accuracy= 69.6875\n",
      "Epoch 1792: train_loss = 0.6078521013259888, valid_loss= 0.578578770160675, accuracy= 67.8125\n",
      "Epoch 1793: train_loss = 0.6064842939376831, valid_loss= 0.5656704902648926, accuracy= 70.625\n",
      "Epoch 1794: train_loss = 0.5851485133171082, valid_loss= 0.5802053809165955, accuracy= 70.0\n",
      "Epoch 1795: train_loss = 0.5947638750076294, valid_loss= 0.5858532190322876, accuracy= 68.125\n",
      "Epoch 1796: train_loss = 0.6148058176040649, valid_loss= 0.5723849534988403, accuracy= 69.0625\n",
      "Epoch 1797: train_loss = 0.5906845927238464, valid_loss= 0.5681267380714417, accuracy= 71.25\n",
      "Epoch 1798: train_loss = 0.5838401317596436, valid_loss= 0.5656525492668152, accuracy= 69.0625\n",
      "Epoch 1799: train_loss = 0.59169602394104, valid_loss= 0.5771824717521667, accuracy= 69.6875\n",
      "Epoch 1800: train_loss = 0.5893188714981079, valid_loss= 0.5645080804824829, accuracy= 70.625\n",
      "Epoch 1801: train_loss = 0.5888403654098511, valid_loss= 0.5647454261779785, accuracy= 70.625\n",
      "Epoch 1802: train_loss = 0.5825620293617249, valid_loss= 0.5605889558792114, accuracy= 70.0\n",
      "Epoch 1803: train_loss = 0.5878561735153198, valid_loss= 0.5605900287628174, accuracy= 70.3125\n",
      "Epoch 1804: train_loss = 0.5728091597557068, valid_loss= 0.5789073705673218, accuracy= 70.0\n",
      "Epoch 1805: train_loss = 0.5758586525917053, valid_loss= 0.5813488960266113, accuracy= 66.5625\n",
      "Epoch 1806: train_loss = 0.6091386675834656, valid_loss= 0.5887478590011597, accuracy= 69.0625\n",
      "Epoch 1807: train_loss = 0.6076534390449524, valid_loss= 0.5777552723884583, accuracy= 67.5\n",
      "Epoch 1808: train_loss = 0.5982407927513123, valid_loss= 0.56513512134552, accuracy= 70.9375\n",
      "Epoch 1809: train_loss = 0.5823415517807007, valid_loss= 0.5720439553260803, accuracy= 69.375\n",
      "Epoch 1810: train_loss = 0.591351330280304, valid_loss= 0.6036454439163208, accuracy= 65.3125\n",
      "Epoch 1811: train_loss = 0.6218854188919067, valid_loss= 0.5642868280410767, accuracy= 70.625\n",
      "Epoch 1812: train_loss = 0.5904472470283508, valid_loss= 0.589339554309845, accuracy= 67.8125\n",
      "Epoch 1813: train_loss = 0.5956649780273438, valid_loss= 0.5864903330802917, accuracy= 69.0625\n",
      "Epoch 1814: train_loss = 0.6088203191757202, valid_loss= 0.5661695599555969, accuracy= 70.625\n",
      "Epoch 1815: train_loss = 0.5845335721969604, valid_loss= 0.5891229510307312, accuracy= 67.5\n",
      "Epoch 1816: train_loss = 0.5990162491798401, valid_loss= 0.5776135325431824, accuracy= 70.625\n",
      "Epoch 1817: train_loss = 0.5920442342758179, valid_loss= 0.5675572156906128, accuracy= 71.25\n",
      "Epoch 1818: train_loss = 0.5872846245765686, valid_loss= 0.5623100996017456, accuracy= 69.6875\n",
      "Epoch 1819: train_loss = 0.580012857913971, valid_loss= 0.5632089376449585, accuracy= 68.75\n",
      "Epoch 1820: train_loss = 0.5793986320495605, valid_loss= 0.6082548499107361, accuracy= 69.375\n",
      "Epoch 1821: train_loss = 0.609014630317688, valid_loss= 0.6211682558059692, accuracy= 62.5\n",
      "Epoch 1822: train_loss = 0.6378687620162964, valid_loss= 0.5643777847290039, accuracy= 70.3125\n",
      "Epoch 1823: train_loss = 0.5994622707366943, valid_loss= 0.6025405526161194, accuracy= 67.8125\n",
      "Epoch 1824: train_loss = 0.6064635515213013, valid_loss= 0.5842278599739075, accuracy= 69.375\n",
      "Epoch 1825: train_loss = 0.6086970567703247, valid_loss= 0.572656512260437, accuracy= 69.6875\n",
      "Epoch 1826: train_loss = 0.5954276323318481, valid_loss= 0.6117311716079712, accuracy= 66.5625\n",
      "Epoch 1827: train_loss = 0.5990726351737976, valid_loss= 0.5692030787467957, accuracy= 69.375\n",
      "Epoch 1828: train_loss = 0.5854202508926392, valid_loss= 0.5670291185379028, accuracy= 68.75\n",
      "Epoch 1829: train_loss = 0.5775286555290222, valid_loss= 0.6034512519836426, accuracy= 69.375\n",
      "Epoch 1830: train_loss = 0.6049981713294983, valid_loss= 0.5724238753318787, accuracy= 69.0625\n",
      "Epoch 1831: train_loss = 0.6137894988059998, valid_loss= 0.5650643110275269, accuracy= 69.6875\n",
      "Epoch 1832: train_loss = 0.5793856382369995, valid_loss= 0.6162070631980896, accuracy= 67.8125\n",
      "Epoch 1833: train_loss = 0.611562967300415, valid_loss= 0.5928786396980286, accuracy= 66.5625\n",
      "Epoch 1834: train_loss = 0.6224923729896545, valid_loss= 0.5670274496078491, accuracy= 69.6875\n",
      "Epoch 1835: train_loss = 0.5821337699890137, valid_loss= 0.6291101574897766, accuracy= 66.5625\n",
      "Epoch 1836: train_loss = 0.6408707499504089, valid_loss= 0.5852698087692261, accuracy= 70.625\n",
      "Epoch 1837: train_loss = 0.5997610092163086, valid_loss= 0.5834572315216064, accuracy= 69.6875\n",
      "Epoch 1838: train_loss = 0.6071299910545349, valid_loss= 0.5873531103134155, accuracy= 67.8125\n",
      "Epoch 1839: train_loss = 0.6049987077713013, valid_loss= 0.5806369185447693, accuracy= 67.5\n",
      "Epoch 1840: train_loss = 0.5889408588409424, valid_loss= 0.5734189748764038, accuracy= 69.6875\n",
      "Epoch 1841: train_loss = 0.5992435216903687, valid_loss= 0.5654662251472473, accuracy= 70.3125\n",
      "Epoch 1842: train_loss = 0.5879436135292053, valid_loss= 0.5805108547210693, accuracy= 69.375\n",
      "Epoch 1843: train_loss = 0.5846671462059021, valid_loss= 0.5713891386985779, accuracy= 70.0\n",
      "Epoch 1844: train_loss = 0.5890874862670898, valid_loss= 0.5697602033615112, accuracy= 70.3125\n",
      "Epoch 1845: train_loss = 0.5838035345077515, valid_loss= 0.5593914985656738, accuracy= 70.0\n",
      "Epoch 1846: train_loss = 0.584748387336731, valid_loss= 0.5613201856613159, accuracy= 70.625\n",
      "Epoch 1847: train_loss = 0.5751606225967407, valid_loss= 0.5942004323005676, accuracy= 70.3125\n",
      "Epoch 1848: train_loss = 0.6047804951667786, valid_loss= 0.6412860155105591, accuracy= 60.9375\n",
      "Epoch 1849: train_loss = 0.6631326079368591, valid_loss= 0.5682891011238098, accuracy= 69.375\n",
      "Epoch 1850: train_loss = 0.5875449180603027, valid_loss= 0.6046978235244751, accuracy= 66.5625\n",
      "Epoch 1851: train_loss = 0.5997461080551147, valid_loss= 0.5795964002609253, accuracy= 69.0625\n",
      "Epoch 1852: train_loss = 0.595352292060852, valid_loss= 0.5744006037712097, accuracy= 70.3125\n",
      "Epoch 1853: train_loss = 0.5925683379173279, valid_loss= 0.5808169841766357, accuracy= 68.125\n",
      "Epoch 1854: train_loss = 0.5972820520401001, valid_loss= 0.5677121877670288, accuracy= 70.0\n",
      "Epoch 1855: train_loss = 0.5814268589019775, valid_loss= 0.5644864439964294, accuracy= 69.6875\n",
      "Epoch 1856: train_loss = 0.5808919072151184, valid_loss= 0.5684946775436401, accuracy= 71.5625\n",
      "Epoch 1857: train_loss = 0.5774791836738586, valid_loss= 0.5594232678413391, accuracy= 70.0\n",
      "Epoch 1858: train_loss = 0.5831927061080933, valid_loss= 0.5601693987846375, accuracy= 69.6875\n",
      "Epoch 1859: train_loss = 0.5735133290290833, valid_loss= 0.5663835406303406, accuracy= 70.3125\n",
      "Epoch 1860: train_loss = 0.5920114517211914, valid_loss= 0.5689517259597778, accuracy= 69.6875\n",
      "Epoch 1861: train_loss = 0.5845296382904053, valid_loss= 0.6088786125183105, accuracy= 69.0625\n",
      "Epoch 1862: train_loss = 0.6139728426933289, valid_loss= 0.6015457510948181, accuracy= 65.3125\n",
      "Epoch 1863: train_loss = 0.6242457032203674, valid_loss= 0.5637567043304443, accuracy= 71.875\n",
      "Epoch 1864: train_loss = 0.575384795665741, valid_loss= 0.5933812260627747, accuracy= 68.125\n",
      "Epoch 1865: train_loss = 0.5966711044311523, valid_loss= 0.5883797407150269, accuracy= 68.125\n",
      "Epoch 1866: train_loss = 0.6143893599510193, valid_loss= 0.5647854208946228, accuracy= 70.9375\n",
      "Epoch 1867: train_loss = 0.5789975523948669, valid_loss= 0.6182876825332642, accuracy= 66.5625\n",
      "Epoch 1868: train_loss = 0.6308711171150208, valid_loss= 0.6026397943496704, accuracy= 66.875\n",
      "Epoch 1869: train_loss = 0.6291773319244385, valid_loss= 0.5801657438278198, accuracy= 67.8125\n",
      "Epoch 1870: train_loss = 0.6014379858970642, valid_loss= 0.6093173623085022, accuracy= 65.9375\n",
      "Epoch 1871: train_loss = 0.6056229472160339, valid_loss= 0.5776345133781433, accuracy= 67.1875\n",
      "Epoch 1872: train_loss = 0.588343620300293, valid_loss= 0.5764104127883911, accuracy= 69.375\n",
      "Epoch 1873: train_loss = 0.5971867442131042, valid_loss= 0.5709003210067749, accuracy= 70.3125\n",
      "Epoch 1874: train_loss = 0.5930770635604858, valid_loss= 0.5750369429588318, accuracy= 70.3125\n",
      "Epoch 1875: train_loss = 0.5868934392929077, valid_loss= 0.5656963586807251, accuracy= 68.75\n",
      "Epoch 1876: train_loss = 0.5783682465553284, valid_loss= 0.5694805979728699, accuracy= 71.25\n",
      "Epoch 1877: train_loss = 0.5890386700630188, valid_loss= 0.5605367422103882, accuracy= 69.6875\n",
      "Epoch 1878: train_loss = 0.5849078297615051, valid_loss= 0.558230996131897, accuracy= 70.3125\n",
      "Epoch 1879: train_loss = 0.5868707299232483, valid_loss= 0.5574921369552612, accuracy= 70.9375\n",
      "Epoch 1880: train_loss = 0.5737107396125793, valid_loss= 0.5517727732658386, accuracy= 72.5\n",
      "Epoch 1881: train_loss = 0.5935368537902832, valid_loss= 0.5528174638748169, accuracy= 72.1875\n",
      "Epoch 1882: train_loss = 0.5673757791519165, valid_loss= 0.5509509444236755, accuracy= 72.5\n",
      "Epoch 1883: train_loss = 0.5871421694755554, valid_loss= 0.550873875617981, accuracy= 72.1875\n",
      "Epoch 1884: train_loss = 0.5869640707969666, valid_loss= 0.5549033880233765, accuracy= 71.5625\n",
      "Epoch 1885: train_loss = 0.5865815281867981, valid_loss= 0.5557657480239868, accuracy= 71.5625\n",
      "Epoch 1886: train_loss = 0.5845125317573547, valid_loss= 0.5778848528862, accuracy= 70.625\n",
      "Epoch 1887: train_loss = 0.5951879620552063, valid_loss= 0.5970951914787292, accuracy= 66.25\n",
      "Epoch 1888: train_loss = 0.6136263012886047, valid_loss= 0.5719408392906189, accuracy= 69.0625\n",
      "Epoch 1889: train_loss = 0.591475248336792, valid_loss= 0.5636661648750305, accuracy= 71.5625\n",
      "Epoch 1890: train_loss = 0.5814907550811768, valid_loss= 0.5635480880737305, accuracy= 69.0625\n",
      "Epoch 1891: train_loss = 0.5884329080581665, valid_loss= 0.5705207586288452, accuracy= 70.9375\n",
      "Epoch 1892: train_loss = 0.5796233415603638, valid_loss= 0.564742386341095, accuracy= 68.4375\n",
      "Epoch 1893: train_loss = 0.5787869691848755, valid_loss= 0.5658405423164368, accuracy= 70.0\n",
      "Epoch 1894: train_loss = 0.5718646049499512, valid_loss= 0.5617024302482605, accuracy= 69.375\n",
      "Epoch 1895: train_loss = 0.5683671236038208, valid_loss= 0.5581401586532593, accuracy= 70.9375\n",
      "Epoch 1896: train_loss = 0.5871688723564148, valid_loss= 0.5635227560997009, accuracy= 69.6875\n",
      "Epoch 1897: train_loss = 0.5844881534576416, valid_loss= 0.5841419696807861, accuracy= 70.9375\n",
      "Epoch 1898: train_loss = 0.598194420337677, valid_loss= 0.6290911436080933, accuracy= 60.62499999999999\n",
      "Epoch 1899: train_loss = 0.6399703025817871, valid_loss= 0.5822478532791138, accuracy= 68.75\n",
      "Epoch 1900: train_loss = 0.5955641865730286, valid_loss= 0.5724421739578247, accuracy= 69.375\n",
      "Epoch 1901: train_loss = 0.5855751037597656, valid_loss= 0.5747290253639221, accuracy= 70.9375\n",
      "Epoch 1902: train_loss = 0.597011148929596, valid_loss= 0.567562460899353, accuracy= 69.0625\n",
      "Epoch 1903: train_loss = 0.579666256904602, valid_loss= 0.5728272795677185, accuracy= 69.375\n",
      "Epoch 1904: train_loss = 0.5844336748123169, valid_loss= 0.5631493330001831, accuracy= 69.6875\n",
      "Epoch 1905: train_loss = 0.5812397003173828, valid_loss= 0.5642331838607788, accuracy= 70.9375\n",
      "Epoch 1906: train_loss = 0.581357479095459, valid_loss= 0.5633784532546997, accuracy= 71.25\n",
      "Epoch 1907: train_loss = 0.586713433265686, valid_loss= 0.5591439604759216, accuracy= 71.875\n",
      "Epoch 1908: train_loss = 0.5888240337371826, valid_loss= 0.5687845349311829, accuracy= 70.625\n",
      "Epoch 1909: train_loss = 0.5968611240386963, valid_loss= 0.569218099117279, accuracy= 68.4375\n",
      "Epoch 1910: train_loss = 0.5920894145965576, valid_loss= 0.602555513381958, accuracy= 67.8125\n",
      "Epoch 1911: train_loss = 0.617081344127655, valid_loss= 0.6108511686325073, accuracy= 63.4375\n",
      "Epoch 1912: train_loss = 0.6275274157524109, valid_loss= 0.5606978535652161, accuracy= 71.5625\n",
      "Epoch 1913: train_loss = 0.5811685919761658, valid_loss= 0.6041305065155029, accuracy= 66.25\n",
      "Epoch 1914: train_loss = 0.607647716999054, valid_loss= 0.5878391265869141, accuracy= 69.375\n",
      "Epoch 1915: train_loss = 0.6072942018508911, valid_loss= 0.5704280734062195, accuracy= 70.3125\n",
      "Epoch 1916: train_loss = 0.5961772799491882, valid_loss= 0.5952209830284119, accuracy= 66.875\n",
      "Epoch 1917: train_loss = 0.5885722041130066, valid_loss= 0.5660651326179504, accuracy= 70.3125\n",
      "Epoch 1918: train_loss = 0.5885330438613892, valid_loss= 0.5743117332458496, accuracy= 70.3125\n",
      "Epoch 1919: train_loss = 0.6014957427978516, valid_loss= 0.5889289379119873, accuracy= 69.0625\n",
      "Epoch 1920: train_loss = 0.5894340872764587, valid_loss= 0.5623037219047546, accuracy= 69.375\n",
      "Epoch 1921: train_loss = 0.5785226821899414, valid_loss= 0.5614477396011353, accuracy= 69.6875\n",
      "Epoch 1922: train_loss = 0.5816022157669067, valid_loss= 0.5619162321090698, accuracy= 70.9375\n",
      "Epoch 1923: train_loss = 0.5762088298797607, valid_loss= 0.5599689483642578, accuracy= 70.9375\n",
      "Epoch 1924: train_loss = 0.577627420425415, valid_loss= 0.5994609594345093, accuracy= 70.0\n",
      "Epoch 1925: train_loss = 0.5921828150749207, valid_loss= 0.6383653283119202, accuracy= 60.3125\n",
      "Epoch 1926: train_loss = 0.6566421985626221, valid_loss= 0.5677858591079712, accuracy= 70.0\n",
      "Epoch 1927: train_loss = 0.5822020173072815, valid_loss= 0.6012464165687561, accuracy= 67.5\n",
      "Epoch 1928: train_loss = 0.6001940369606018, valid_loss= 0.6074093580245972, accuracy= 64.6875\n",
      "Epoch 1929: train_loss = 0.6221451759338379, valid_loss= 0.5762968063354492, accuracy= 70.625\n",
      "Epoch 1930: train_loss = 0.5940634608268738, valid_loss= 0.6236749887466431, accuracy= 65.0\n",
      "Epoch 1931: train_loss = 0.6248190402984619, valid_loss= 0.5708633661270142, accuracy= 68.4375\n",
      "Epoch 1932: train_loss = 0.589032769203186, valid_loss= 0.5769573450088501, accuracy= 70.3125\n",
      "Epoch 1933: train_loss = 0.5959295630455017, valid_loss= 0.5741884112358093, accuracy= 69.0625\n",
      "Epoch 1934: train_loss = 0.5824471116065979, valid_loss= 0.5756418108940125, accuracy= 69.6875\n",
      "Epoch 1935: train_loss = 0.5854001641273499, valid_loss= 0.5635589361190796, accuracy= 69.375\n",
      "Epoch 1936: train_loss = 0.5754036903381348, valid_loss= 0.5624185800552368, accuracy= 69.6875\n",
      "Epoch 1937: train_loss = 0.5760129690170288, valid_loss= 0.5695053935050964, accuracy= 70.3125\n",
      "Epoch 1938: train_loss = 0.5823984146118164, valid_loss= 0.5714325904846191, accuracy= 67.8125\n",
      "Epoch 1939: train_loss = 0.6027711033821106, valid_loss= 0.5816454291343689, accuracy= 70.0\n",
      "Epoch 1940: train_loss = 0.5896270275115967, valid_loss= 0.5651850700378418, accuracy= 70.625\n",
      "Epoch 1941: train_loss = 0.5806559324264526, valid_loss= 0.5602657198905945, accuracy= 71.5625\n",
      "Epoch 1942: train_loss = 0.5869144201278687, valid_loss= 0.5656418800354004, accuracy= 70.3125\n",
      "Epoch 1943: train_loss = 0.578840434551239, valid_loss= 0.5571684241294861, accuracy= 70.9375\n",
      "Epoch 1944: train_loss = 0.570582389831543, valid_loss= 0.556148886680603, accuracy= 71.5625\n",
      "Epoch 1945: train_loss = 0.5735048651695251, valid_loss= 0.5538052320480347, accuracy= 72.5\n",
      "Epoch 1946: train_loss = 0.5733890533447266, valid_loss= 0.5542672276496887, accuracy= 72.1875\n",
      "Epoch 1947: train_loss = 0.5766839981079102, valid_loss= 0.552186131477356, accuracy= 71.25\n",
      "Epoch 1948: train_loss = 0.5742961764335632, valid_loss= 0.6011391878128052, accuracy= 69.6875\n",
      "Epoch 1949: train_loss = 0.6005707383155823, valid_loss= 0.7032979130744934, accuracy= 53.43750000000001\n",
      "Epoch 1950: train_loss = 0.7175107598304749, valid_loss= 0.5902400612831116, accuracy= 69.6875\n",
      "Epoch 1951: train_loss = 0.6130520105361938, valid_loss= 0.6709243059158325, accuracy= 60.62499999999999\n",
      "Epoch 1952: train_loss = 0.655545175075531, valid_loss= 0.5895704030990601, accuracy= 66.5625\n",
      "Epoch 1953: train_loss = 0.6043558120727539, valid_loss= 0.5994663238525391, accuracy= 69.0625\n",
      "Epoch 1954: train_loss = 0.6144073605537415, valid_loss= 0.5922849774360657, accuracy= 70.0\n",
      "Epoch 1955: train_loss = 0.6084911227226257, valid_loss= 0.5856053233146667, accuracy= 65.9375\n",
      "Epoch 1956: train_loss = 0.5908057689666748, valid_loss= 0.6014665961265564, accuracy= 66.25\n",
      "Epoch 1957: train_loss = 0.6055191159248352, valid_loss= 0.571609377861023, accuracy= 70.0\n",
      "Epoch 1958: train_loss = 0.5884608030319214, valid_loss= 0.5701322555541992, accuracy= 69.6875\n",
      "Epoch 1959: train_loss = 0.5931023955345154, valid_loss= 0.5771058797836304, accuracy= 69.375\n",
      "Epoch 1960: train_loss = 0.5864702463150024, valid_loss= 0.5619970560073853, accuracy= 70.625\n",
      "Epoch 1961: train_loss = 0.584862232208252, valid_loss= 0.5603482723236084, accuracy= 71.25\n",
      "Epoch 1962: train_loss = 0.5960881114006042, valid_loss= 0.5596002340316772, accuracy= 70.0\n",
      "Epoch 1963: train_loss = 0.5854193568229675, valid_loss= 0.5720307230949402, accuracy= 71.5625\n",
      "Epoch 1964: train_loss = 0.5799558162689209, valid_loss= 0.5622409582138062, accuracy= 71.5625\n",
      "Epoch 1965: train_loss = 0.578113853931427, valid_loss= 0.5669281482696533, accuracy= 72.1875\n",
      "Epoch 1966: train_loss = 0.5825737714767456, valid_loss= 0.5552172660827637, accuracy= 70.9375\n",
      "Epoch 1967: train_loss = 0.581546425819397, valid_loss= 0.5677700042724609, accuracy= 69.6875\n",
      "Epoch 1968: train_loss = 0.5758967995643616, valid_loss= 0.5572448968887329, accuracy= 70.625\n",
      "Epoch 1969: train_loss = 0.5817063450813293, valid_loss= 0.5710620880126953, accuracy= 70.0\n",
      "Epoch 1970: train_loss = 0.5745469927787781, valid_loss= 0.5695104002952576, accuracy= 68.4375\n",
      "Epoch 1971: train_loss = 0.5966328382492065, valid_loss= 0.6032934188842773, accuracy= 70.0\n",
      "Epoch 1972: train_loss = 0.5907184481620789, valid_loss= 0.6061375141143799, accuracy= 64.6875\n",
      "Epoch 1973: train_loss = 0.6303970217704773, valid_loss= 0.5623916387557983, accuracy= 70.3125\n",
      "Epoch 1974: train_loss = 0.5745108127593994, valid_loss= 0.6124154329299927, accuracy= 66.25\n",
      "Epoch 1975: train_loss = 0.6178148984909058, valid_loss= 0.60004723072052, accuracy= 67.5\n",
      "Epoch 1976: train_loss = 0.6234027743339539, valid_loss= 0.5850491523742676, accuracy= 69.6875\n",
      "Epoch 1977: train_loss = 0.6006208658218384, valid_loss= 0.5995126962661743, accuracy= 66.25\n",
      "Epoch 1978: train_loss = 0.6002267599105835, valid_loss= 0.5767573118209839, accuracy= 68.75\n",
      "Epoch 1979: train_loss = 0.5934363603591919, valid_loss= 0.5728918313980103, accuracy= 70.3125\n",
      "Epoch 1980: train_loss = 0.5833206176757812, valid_loss= 0.5659381151199341, accuracy= 70.0\n",
      "Epoch 1981: train_loss = 0.5911831259727478, valid_loss= 0.5859330892562866, accuracy= 69.6875\n",
      "Epoch 1982: train_loss = 0.6066235899925232, valid_loss= 0.566699743270874, accuracy= 70.3125\n",
      "Epoch 1983: train_loss = 0.5877898335456848, valid_loss= 0.5600560903549194, accuracy= 71.875\n",
      "Epoch 1984: train_loss = 0.5760709643363953, valid_loss= 0.5795710682868958, accuracy= 69.6875\n",
      "Epoch 1985: train_loss = 0.5980321764945984, valid_loss= 0.5811278820037842, accuracy= 67.5\n",
      "Epoch 1986: train_loss = 0.5956742763519287, valid_loss= 0.5734415054321289, accuracy= 70.3125\n",
      "Epoch 1987: train_loss = 0.5775725245475769, valid_loss= 0.5574729442596436, accuracy= 71.25\n",
      "Epoch 1988: train_loss = 0.5781137347221375, valid_loss= 0.5576916337013245, accuracy= 71.25\n",
      "Epoch 1989: train_loss = 0.571143388748169, valid_loss= 0.571956217288971, accuracy= 69.6875\n",
      "Epoch 1990: train_loss = 0.5716853141784668, valid_loss= 0.5612071752548218, accuracy= 70.625\n",
      "Epoch 1991: train_loss = 0.5848734378814697, valid_loss= 0.5741081833839417, accuracy= 70.625\n",
      "Epoch 1992: train_loss = 0.574305534362793, valid_loss= 0.5566856861114502, accuracy= 70.9375\n",
      "Epoch 1993: train_loss = 0.5815833210945129, valid_loss= 0.5731039643287659, accuracy= 70.0\n",
      "Epoch 1994: train_loss = 0.5823786854743958, valid_loss= 0.5701879262924194, accuracy= 68.125\n",
      "Epoch 1995: train_loss = 0.5971418023109436, valid_loss= 0.5722354650497437, accuracy= 70.625\n",
      "Epoch 1996: train_loss = 0.592042863368988, valid_loss= 0.5553884506225586, accuracy= 71.875\n",
      "Epoch 1997: train_loss = 0.581891655921936, valid_loss= 0.5639466643333435, accuracy= 70.625\n",
      "Epoch 1998: train_loss = 0.5742568373680115, valid_loss= 0.5543095469474792, accuracy= 71.875\n",
      "Epoch 1999: train_loss = 0.5779582858085632, valid_loss= 0.5672303438186646, accuracy= 71.5625\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 2000\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=0.1, momentum=0.7)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    train_loss = 0.0\n",
    "    model2.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model2(inputs)\n",
    "\n",
    "        loss = loss_fn(pred,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss_list.append(train_loss/len(train_loader))\n",
    "\n",
    "    model2.eval()\n",
    "    valid_loss, correct = 0, 0\n",
    "    size = len(valid_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            pred = model2(inputs)\n",
    "            loss = loss_fn(pred,labels)\n",
    "            valid_loss += loss.item()\n",
    "            binary_pred = (pred >= 0.5).float()\n",
    "            correct += (binary_pred==labels).sum().item()\n",
    "\n",
    "        correct /= size\n",
    "        valid_loss/=len(valid_loader)\n",
    "\n",
    "        accuracy_list.append(correct)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "\n",
    "        if valid_loss < min_valid_loss:\n",
    "            min_valid_loss = valid_loss\n",
    "            best_model = model2\n",
    "            torch.save(model2, 'best-model.pt')\n",
    "            torch.save(model2.state_dict(), 'best-model-parameters.pt')\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss = {train_loss_list[epoch]}, valid_loss= {valid_loss_list[epoch]}, accuracy= {correct*100}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1964a2bdf10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACafElEQVR4nOzdeVwU5R8H8M/MXsgtIoeK4n1foRJaqYmilmlaqWmmmaU/LZMsJcurUssyOyw7vCpNy9QszVI88kBRvC9UFPEAPJBTYa/5/bGwO7M7swfsshzf9+vFy92ZZ2aeYZH58jzf53kYjuM4EEIIIYRUcqy7K0AIIYQQ4gwU1BBCCCGkSqCghhBCCCFVAgU1hBBCCKkSKKghhBBCSJVAQQ0hhBBCqgQKagghhBBSJVBQQwghhJAqQe7uCpQXvV6PmzdvwsfHBwzDuLs6hBBCCLEDx3HIy8tDnTp1wLLW22KqTVBz8+ZNhIWFubsahBBCCCmFa9euoV69elbLVJugxsfHB4Dhm+Lr6+vm2hBCCCHEHrm5uQgLCzM+x62pNkFNSZeTr68vBTWEEEJIJWNP6gglChNCCCGkSqCghhBCCCFVAgU1hBBCCKkSKKghhBBCSJVAQQ0hhBBCqoRSBTVLlixBeHg4PDw8EBkZicTERMmyPXr0AMMwFl9PPPEEAECj0WDatGlo27YtvLy8UKdOHYwaNQo3b94UnCc8PNziHAsWLChN9QkhhBBSBTkc1Kxbtw6xsbGYNWsWjh49ivbt2yMmJga3bt0SLb9hwwakp6cbv06fPg2ZTIZnn30WAHD//n0cPXoU7733Ho4ePYoNGzYgOTkZTz31lMW55s6dKzjXa6+95mj1CSGEEFJFOTxPzaJFizBu3DiMGTMGALB06VJs2bIFy5cvx/Tp0y3KBwQECN6vXbsWnp6exqDGz88P27dvF5T56quv0KVLF6SlpaF+/frG7T4+PggJCXG0yoQQQgipBhxqqVGr1UhKSkJ0dLTpBCyL6OhoJCQk2HWOZcuWYdiwYfDy8pIsk5OTA4Zh4O/vL9i+YMEC1KpVCx07dsTChQuh1WodqT4hhBBCqjCHWmru3LkDnU6H4OBgwfbg4GCcP3/e5vGJiYk4ffo0li1bJlmmsLAQ06ZNw/DhwwUz/77++ut46KGHEBAQgAMHDiAuLg7p6elYtGiR6HmKiopQVFRkfJ+bm2uzfoQQQgipvMp1mYRly5ahbdu26NKli+h+jUaD5557DhzH4ZtvvhHsi42NNb5u164dlEolXn31VcyfPx8qlcriXPPnz8ecOXOcewOEEEIIqbAc6n4KDAyETCZDZmamYHtmZqbNXJeCggKsXbsWY8eOFd1fEtBcvXoV27dvt7k+U2RkJLRaLVJTU0X3x8XFIScnx/h17do1q+cjhBBCSOXmUFCjVCoRERGB+Ph44za9Xo/4+HhERUVZPfa3335DUVERRo4cabGvJKC5ePEiduzYgVq1atmsy/Hjx8GyLIKCgkT3q1Qq4+KVtIglIYSQ8pJ9X42le1KQkVPo7qpUOw53P8XGxuLFF19Ep06d0KVLFyxevBgFBQXG0VCjRo1C3bp1MX/+fMFxy5Ytw6BBgywCFo1Gg2eeeQZHjx7FX3/9BZ1Oh4yMDACGkVNKpRIJCQk4dOgQevbsCR8fHyQkJGDKlCkYOXIkatasWdp7J4QQQpwu9tcT2Hn+FtYdvoZdU3u4uzrVisNBzdChQ3H79m3MnDkTGRkZ6NChA7Zt22ZMHk5LSwPLChuAkpOTsW/fPvz7778W57tx4wY2b94MAOjQoYNg365du9CjRw+oVCqsXbsWs2fPRlFRERo2bIgpU6YI8mwIIYSQimB3smHetit3Ctxck+qH4TiOc3clykNubi78/PyQk5NDXVGEEEJcplHcFuiLn6ypC55wb2WqAEee37T2EyGEEEKqBApqCCGEEFIlUFBDCCGEOFG1yOmooCioIYQQQkiVQEGNk1STfGtCCCE2MO6uQDVGQU0Z7blwG01nbMXAJfvdXRVCCCGkWqOgpoxkDAONjoNaq3d3VQghhJBqjYKaMlLKDd9CCmoIIYRUJal3CvD01/ux/Wym7cIVBAU1ZVQS1BRRUEMIIaQKefO3EziWlo1xPx5xd1XsRkFNGSllxS01OgpqCCGEVB3Z99XuroLDKKgpI+p+IoQQQioGCmrKSEVBDSGEEFIhUFBTRsaWGup+IoQQQtyKgpoyUhTn1Oj0HHR6moCPEEKqO3oSuA8FNWVU0lIDUBcUIYQQ4k4U1JRRyegngIIaQgghtEyCO1FQU0YKmenHt0inc2NNCCGEVATU/eQ+FNSUEcMwNKybEEIIqQAoqHEClYyCGkIIIQbU/eQ+FNQ4AQ3rJoQQUoK6n9yHghonoO4nQgghxP0oqHECCmoIIYSUoO4n96GgxgmUlFNDCCGkWC3koBebBBb0TChvcndXoCqQsYa4nCYUJoQQslU5HbWZHLynGQ1ggLurU61QS40TMIwhqNFxFNUQQkh1V5vJAQD0ZpPcXJPqh4IaJyiZVFhPQQ0hhBDiNhTUOAFb3FLDUVBDCCGkiijphahMKKhxAmP3E+WEEUIIqSIq4x/qlChcVlcT8FXWqzitCIGe+9ndtSGEEEKqLQpqykpzH2G6a8hjWKRVwqiWEEIIqSqo+6msGMO3kIGehnQTQgipMiinpjpiZYZ/wEFHUQ0hhJAqojLm1FBQU1bFLTUsOBrSTQghhLgRBTVlZQxq9KCYhhBCSFVB3U/VES+ooZYaQgghVUkNFLq7Cg6hoKaseN1PlFNDCCGkqhhVuBrnPF7C4+xRd1fFbhTUlBVjShSmhhpCCCFVxSj1OgDAXMVK91bEARTUlFVxnyPDUKIwIYQQ4k6lCmqWLFmC8PBweHh4IDIyEomJiZJle/ToAYZhLL6eeOIJYxmO4zBz5kyEhoaiRo0aiI6OxsWLFwXnycrKwogRI+Dr6wt/f3+MHTsW+fn5pam+cwlyatxcF0IIIaQaczioWbduHWJjYzFr1iwcPXoU7du3R0xMDG7duiVafsOGDUhPTzd+nT59GjKZDM8++6yxzMcff4wvvvgCS5cuxaFDh+Dl5YWYmBgUFpoSlEaMGIEzZ85g+/bt+Ouvv/Dff//hlVdeKcUtO1lxUCODHjpqqSGEEELcxuGgZtGiRRg3bhzGjBmDVq1aYenSpfD09MTy5ctFywcEBCAkJMT4tX37dnh6ehqDGo7jsHjxYrz77rsYOHAg2rVrhx9//BE3b97Epk2bAADnzp3Dtm3b8MMPPyAyMhKPPPIIvvzyS6xduxY3b94s/d07Ay9RuDJOVEQIIYRUFQ4FNWq1GklJSYiOjjadgGURHR2NhIQEu86xbNkyDBs2DF5eXgCAK1euICMjQ3BOPz8/REZGGs+ZkJAAf39/dOrUyVgmOjoaLMvi0KFDotcpKipCbm6u4MslimcUZsBBT/1PhBBCiNs4FNTcuXMHOp0OwcHBgu3BwcHIyMiweXxiYiJOnz6Nl19+2bit5Dhr58zIyEBQUJBgv1wuR0BAgOR158+fDz8/P+NXWFiY7RssDcqpIYQQQiqEch39tGzZMrRt2xZdunRx+bXi4uKQk5Nj/Lp27ZprLsTLqaHRT4QQQoj7OBTUBAYGQiaTITMzU7A9MzMTISEhVo8tKCjA2rVrMXbsWMH2kuOsnTMkJMQiEVmr1SIrK0vyuiqVCr6+voIvlzCu0s3hYmYFGI1FCCGkQuBQ+ZYZqOwcCmqUSiUiIiIQHx9v3KbX6xEfH4+oqCirx/72228oKirCyJEjBdsbNmyIkJAQwTlzc3Nx6NAh4zmjoqKQnZ2NpKQkY5mdO3dCr9cjMjLSkVtwvuJ5alhwWHfERa1BhBBCKh0G1Hpf3uSOHhAbG4sXX3wRnTp1QpcuXbB48WIUFBRgzJgxAIBRo0ahbt26mD9/vuC4ZcuWYdCgQahVq5ZgO8MweOONN/DBBx+gadOmaNiwId577z3UqVMHgwYNAgC0bNkSffv2xbhx47B06VJoNBpMmjQJw4YNQ506dUp5607Cm1GYEEIIIe7jcFAzdOhQ3L59GzNnzkRGRgY6dOiAbdu2GRN909LSwLLCBqDk5GTs27cP//77r+g53377bRQUFOCVV15BdnY2HnnkEWzbtg0eHh7GMqtXr8akSZPQq1cvsCyLIUOG4IsvvnC0+s7HSxQmhBBCiPswXDWZXCU3Nxd+fn7Iyclxbn5Nzg3gs1ZQczK00a7GhQ/7Oe/chBBCKp/ZfgCA/3Rt8dj7+9xcmTIovo/rXCDqzUlxWzUceX7T2k9lxZt8r2UdFyUjE0IIqXQoUbj8UVBTVrygRqenLihCCCEGlChc/iioKauSoIbhoNVSUEMIIYS4CwU1ZVW8TAIAaqkhhBBiRN1P5Y+CmrJiTD+0ep3WjRUhhBBCqjcKasqKMX0Lr2UVYNWBVPfVhRBCCKnGKKgpK15Qw4DDrM1n3FgZQgghpPqioKaseEENTcBHCCGEuA8FNWXFmBKFaakEQgghxH0oqCkrXkuNjFpqCCGEELehoKaszHJqAEBN89UQQggh5Y6CmrISyal5oNG5qzaEEEJItUVBTVnx5qkpyalZ+M95d9WGEEIIqbYoqCkrhgFnXP/J0FLz88E0d9aIEEIIqZYoqHEG3qKWhBBCCHEPCmqcgYIaQgghxO0oqHEGs+4nQgghhJQ/CmqcoTioYRhqqSGEEELchYIaJ2CKZxWmyfcIIYQQ96Ggxhkop4YQQghxOwpqnKF4rhrKqSGEEELch4IaZyjJqaGWGkIIIcRtKKhxBup+IoQQQtyOghpnYClRmBBCCHE3CmqcgVpqCCGEELejoMYZjDk11FJDCCGEuAsFNc5ALTWEEEKI21FQ4wzGId0U1BBCCCHuQkGNM9DaT4QQQojbUVDjDMXLJFBQQwghhLgPBTXOQDk1hBBCzHBg3F2FaoeCGmcoCWp4q3TP3nzGXbUhhBBSAdAs8+WPghpnEMmpWXkg1U2VIYQQQpyH4ypPixMFNc4gUwAAFNAJNt/JL3JHbQghhFQAVaX7iWEqT4sTBTXOIFMCAHo19RdsvnHvgRsqQwghpCKg7qfyR0GNMxQHNc93ChVs1ur10Ok5TPg5CYt3XHBHzQghhJBqg4IaZ5DJAQBys+4njY7D/kt38PfpDCzecdEdNSOEEELKhHJqqpvilhro1ILNWh2H+2qdyAGEEEJI5VDlc2qWLFmC8PBweHh4IDIyEomJiVbLZ2dnY+LEiQgNDYVKpUKzZs2wdetW4/7w8HAwDGPxNXHiRGOZHj16WOwfP358aarvfBJBjVqnA8dVnh8GQgghzlNVEoUrE7mjB6xbtw6xsbFYunQpIiMjsXjxYsTExCA5ORlBQUEW5dVqNXr37o2goCCsX78edevWxdWrV+Hv728sc/jwYeh0phaN06dPo3fv3nj22WcF5xo3bhzmzp1rfO/p6elo9V2jePQTdBp4ohD34QEAyHmggVImc2PFCCGEuEtVSRSuTN1PDgc1ixYtwrhx4zBmzBgAwNKlS7FlyxYsX74c06dPtyi/fPlyZGVl4cCBA1AoDA//8PBwQZnatWsL3i9YsACNGzdG9+7dBds9PT0REhLiaJVdLzfd8O/WqTjrAfxP/Tq26h/GzexCNKhVQQIvQgghpIpzqPtJrVYjKSkJ0dHRphOwLKKjo5GQkCB6zObNmxEVFYWJEyciODgYbdq0wbx58wQtM+bX+Pnnn/HSSy+BYYTR4erVqxEYGIg2bdogLi4O9+/fl6xrUVERcnNzBV8uc13Y/faZ4hsAwKZjN/DD3iuuuy4hhJAKi7qfyp9DLTV37tyBTqdDcHCwYHtwcDDOnz8veszly5exc+dOjBgxAlu3bsWlS5fwv//9DxqNBrNmzbIov2nTJmRnZ2P06NGC7c8//zwaNGiAOnXq4OTJk5g2bRqSk5OxYcMG0evOnz8fc+bMceT2Sq/BI8DVfca3d+EDALh4K798rk8IIYQQx7ufHKXX6xEUFITvvvsOMpkMERERuHHjBhYuXCga1Cxbtgz9+vVDnTp1BNtfeeUV4+u2bdsiNDQUvXr1QkpKCho3bmxxnri4OMTGxhrf5+bmIiwszIl3xjPsZ+CjcOPbW5y/aDG9ngPLUuROCCGEuIJD3U+BgYGQyWTIzMwUbM/MzJTMdQkNDUWzZs0g4yXMtmzZEhkZGVCrhaOFrl69ih07duDll1+2WZfIyEgAwKVLl0T3q1Qq+Pr6Cr5cpkZNoFk/49s7nJ9osf8u3nZdHQghhFQoVSVRuMoO6VYqlYiIiEB8fLxxm16vR3x8PKKiokSP6datGy5dugS93rTY44ULFxAaGgqlUikou2LFCgQFBeGJJ56wWZfjx48DMARNFYK3aeQXx4h/W2kCPkIIIcR1HJ6nJjY2Ft9//z1WrVqFc+fOYcKECSgoKDCOhho1ahTi4uKM5SdMmICsrCxMnjwZFy5cwJYtWzBv3jzBHDSAIThasWIFXnzxRcjlwl6xlJQUvP/++0hKSkJqaio2b96MUaNG4bHHHkO7du1Kc9/O1/Md48seDb1Fixy/ll1OlSGEEOJuVSVRuEoP6R46dChu376NmTNnIiMjAx06dMC2bduMycNpaWlgWVOsFBYWhn/++QdTpkxBu3btULduXUyePBnTpk0TnHfHjh1IS0vDSy+9ZHFNpVKJHTt2YPHixSgoKEBYWBiGDBmCd99919Hqu45PCDD0Z2DdSLBa6YUsb+UW4oMt5+DtIcfcp1pDLqNJnQkhhBBnYLhqMuVtbm4u/Pz8kJOT47r8mks7gJ+HQB/cFo2uxokWUcpYqHWGrrifxnbBo01ri5YjhBBSSc025FXu1rVHj/f/c3NlyqD4Pq7payNsrnj+anlw5PlNzQTOpDBMtMdopFtqSgIawBDgEEIIIRVZGFt5BrnQU9WZFDUM/2oL7SpOw7sJIYQQ56GgxpmMLTXSMx3z6fTVouePEEIIKRcU1DhTSUuNusCu4vrqkc5ECCGElAsKapypRoDhX10RasB2FxTFNIQQQojzUFDjTEovQO4BAKjF5NksrtNz+DEhFbuTb7m6ZoQQQkiVR0GNMzEM4FcPANCasb0697G0bMz84wxGrzjs6poRQgghVR4FNc7WoCsAoBWbZrPojWz7EooJIYQQYhsFNc5WMxwAUI+xPa6fcmoIIYQQ56GgxtmKk4V9YbsV5rek68bXWt6kfIQQQghxHAU1zuZhmMLZh3Gsa+l2fpErakMIIYRUGxTUOJvKENR4Q3qpBDEvLEt0RW0IIYSQaoOCGmdT+QBwPKi5dCvfFbUhhBBCqg0KapytJKhhHAtqCCGEEFI2FNQ4W3H3Uy15IYZ3CYOXUgYAGNihjjtrRQghhFR5cndXoMopbqlhdGrMf6o5PhjUFim383FfrcMfx2+6uXKEEEKqEr2ew/tbzqJDmD8Gdqjr7uq4HbXUOJvKBwBjeJ15BjKWQbNgH2jsGLLd+cMd+POEKfC5fDvf6nFqrR5rDqXhWhZN4kcIIdXRv2czsWJ/KiavPe7uqlQIFNQ4GysDglsbXp/ZYNzcMtTX5qG384rw2i/HcDuvCH8cv4HHP92DV39Kwn8XbuP0jRxjmd3Jt8BxHJbuScE7G0/h8U93I+V2Pr6Iv4i8Qo1LbosQQkjFc7eApgPho+4nV2jeD8g8DeRlGjd5q+ToEOaP49eybR6eW6jB93svAwB2nr+FnecNC15emd8fPT/ZjfwiLRYP7YD9l+4AADQ6DjGf/QetnsPN7AdYMKSd4HxHUrOg03N4qEFNKGQUxxJCCKmaKKhxhYBGhn/v3xFsDvXzwPFrtg/nOE50CYXJa48jv0gLAIg/fwv8Ilq94V1iapbgmJvZD/DM0gQAhtaivyc/at89EEIIKRNaCaf80Z/truBV2/BvgTCoead/S7sOv3r3Ps7czLXYvpmXb3P06j3R/zHmwVDKbdP8N+fSLc9JCCHENZhyuAatIShEQY0reNYy/JtxUrA5LMATLUJ8bB4+dtURm2VuZD/AkatZFtv1HIeDl+9ixsZTyCvU2JWgXBpqrR6x645j47HrtgsTQggh5YC6n1yhpKUGAO5cAgKbuOQyepEIXc9xGPbdQQDAhcw8jHy4QanOvf/SHey9eAcvRDXA5dv58PFQoEOYv3H/r0euYcOxG9hw7Ab8ayjRs0WQxTnu5BfBQyGDt4p+zAghhLgePW1cwa+e6fW9VEFQwzCubZDU8xpmDqfew+HUezaP4TgO72w8hdreKsT2aQ4AGPHDIQDA0j0pxnIp8/pDxhrqfzdfbdw+ZuVhpC54QnDOnPsadPpgBxQyBhc/7F/q+yGEEELsRd1PrsAwQINHDK8Ls8v10jeyHV+eYfbmM/gl8Rq+2HnJarnv/rtsfM3ZSIE7fdMwBF2jow5fQkj1RL/9yh8FNa5Sw9/wr1lQUx6JY9bM23pOkDCcc1+DVQlXje85K1lnaw+n8coJ9+25cBvPfHPAmJisdlEuT3lJz3mAy7dpkVFCSOm5+/d9dURBjat4+Bv+fZAt2FzSfeMu3/13Gf0+34ub2Q8Qt+Ektp5OF+zXiSXqFNPyWl3MS724PBFHrt7D5LXHcDP7ATRa5wY1t3ILse10utX6OVPU/J14/NM9uFegtl1YxMZj1/Hc0gTczqOJsQghpLxQUOMqEi017g5qSnRdsBO/JF5D3IZTgu1aPYfzGeJDv7X8hB2JFp3TN3LRdcFO/Mhr/Snxz5kMdF+4CyfsmIDQXN/P92L8z0fx80HL8zqbnhc4Xb9XutXWp6w7gcTULHy07byzqkUIqWQqW/eTvpz+aHQlCmpcpaSlpjBHsFnOC2qm92uBb1+IKMdK2bb9bCY2HRNfeFOr48BxHHLua2z+Z913yTRHT0mX1qs/JeHq3fsYs/Kw6DHWur6yiltMdpzLlCzjLPyus7IGobRsBSHElpz7GqxNTEPOfcd/XzgrDJn1x2l0/nAH7uZX7tZlCmpcpaSl5r5wLhm5zPSQHN+9MWJah6BZsHc5Vsy61345BqkBWhqdHnEbTqH93H+ReMVyjhwp5rFKVoEaD9Q6wbYLmXmInBdvbIn57cg1/JiQKloHVyvSOi+ooYmxCCG2TPrlKKZvOIVJvxx1Wx1WJVzF3QK1IMeyMqKgxlV8Qg3/nv8LyL9t3Cy29pKvh6K8amUXqbwVjY7D2sOGdR4OORDU6EWe7IvjLwjex204hVt5RXh302kUanR4a/1JzPzjDG7lFgrKHbychc93XAQAJGfk4dWfjuB8Ri60Oj3O3MyRbO0pKNJi2HcJWLH/is36Fml1NstURiv3X8Hjn+zGTTtHyOUVapDzgFqaCCkte/8k2nvxjuDfiqiydE1RUOMq/Llq1g43vpSL/OXv76ksjxrZ7Y5E8+MDTeke9odT7+Hq3QLBtiSz+XO0vP8w/T7fa3xdoLa85ufxF5DzQIOYxf/hnzOZeG5pAt5efxJPfLEPS3aJD0tfeSAVBy9nYc6fZ23Wt0hjaqkpa2Kyi6clcsjsP8/i8p0CLPjbdp6PXs+h7ex/0X7Ovygs5edOCKk6TlzPdncV7EJBjav4hZleXzflkMhYy2/5rAGt0DTIG/MHty2Pmtl0PC3bqed7a/0JvLHuuGDbkav30OSdrcZEWn6sd+WOKQC6r9ZanE/PAe//ZQpOcgu12HDsBgBgya4Ui/IALFoc1Fq9ZN8xP6fGmaOtOI5DbgXIsVHbMTKN3wVHI7gIKZ3K0bZhn/IaeVpWFNS4imeA8P2RFQDEW2rCAjyxPbY7hnepj3efsG/RS1e6fKfAdiEHXL/3AMdEAiWtnsM3uw1BCCvRpPHOxtOi2w9eviu6XaplRGs2CWCfz/Yg4oMd2HoqHWduCpO5+S01Gn3ZcngYXgP0xDVH0W72v5ViYVH+5IoVqbWJEGKGEvcEKKhxFfMnwV9vANeTBInCYlQKmevqVEFxHAepfFyp4d9iwWGJvEINDqTcEfxloTMLTlLv3gcA/G/1UQz77qCgv5ifUyP114m1kVpStp7KAACs3J/q8LHOZE+Qwr9vVy/tQQghzkJrP5WnHx7H6EH/4a+TQPt6fnYf5qWUieaWVBWJV7IcfnBKjUpiAIxZcRhHrt7D3IGtMSoqHIAwZ8dcXqEWGr0eKtYQUPK7Z8xbeABg5/lMvLH2OPq2CcHdfDV8ayhwM/sBfn450iIRXOy2ZDYCW1ez51vNjwEppCGEVBbUUuNKb1h2nXS6+j12T+2BX8dH2X2a/97uKbnv6Y51S1W1imTodwetPjj/Oik+b46UI1cNSchrDqVh47HruJVXaLM/mP8Q5+eT7DiXiZ8SUvH17kv484ShHi+tPILcQi1+PXId8edvYeOxGzh0JQt7L942Py0A4FZeIYYXr5xeUi9bybdFWh1OXs/Giv1XynXUQUkLlI6atAkRdfl2vkPzyUgNvKhsKkuDLbXUuJJ/mOW2B/cQHujl0GlqeavQv22IsfuCb97TbbGxOElWzEP1/XHUyYm/rmBtiPikNccstkk9cvktPucz8jBl3Qk0DPRCpwY1rV7fMFuyoaWGH9Qs2yccAj6gfR3Jc6i14rWat+UcEsxygLaeSsdT7etAxjIWrVRHUrPwzNIE4/sALyUGdnB98Dp78xlsP5uJra8/WmmSAgkpT1fuFODxT/cAAFIXPGHXMeZzchHXKlVLzZIlSxAeHg4PDw9ERkYiMTHRavns7GxMnDgRoaGhUKlUaNasGbZu3WrcP3v2bDAMI/hq0aKF4ByFhYWYOHEiatWqBW9vbwwZMgSZma6fXdbp9I79gNf1rwHA8GATU0MpnYPTsb4/1r0ahYNxvRy6ZmUg1i0EiHeVXLlTgKvFOTRShC010p+RPbk05gth3hVZP6qgSIvIefF4edURi32zNp8RvD+XnocDKXdw+kaORVlnWnkgFTeyH2B14lVBUCM2zxAh1dEhiQEK1lS2ea8qSYOMJIdbatatW4fY2FgsXboUkZGRWLx4MWJiYpCcnIygoCCL8mq1Gr1790ZQUBDWr1+PunXr4urVq/D39xeUa926NXbs2GGqmFxYtSlTpmDLli347bff4Ofnh0mTJmHw4MHYv3+/o7fgXpzOENiw4sEI/wfqxMw+8FAa4s7Y6Ga4lvUAl+/k41qWYfK0NeMiRc+xfnwUUm7no0+rEChkLEL8PJx6C9b8PDYSI5cdcvl1HP1FkZhqfbJArV6P345cw5JdlxDVOFCynPUWDMO+N387YdzCMMClW5arfSdcvou7BWrEn7+Fnw9exdn0XHwwsA1YlrEYzHAj+wGe/97wPX24UQA+GtIODWo51trnCJ2OE3Q/UUxDSOk9ULt+FnRi4nBQs2jRIowbNw5jxowBACxduhRbtmzB8uXLMX36dIvyy5cvR1ZWFg4cOACFwjBzbnh4uGVF5HKEhISIXjMnJwfLli3DmjVr8PjjjwMAVqxYgZYtW+LgwYN4+OGHHb0N97n4L7BuJDD8F8P7a4cNw79rNbYo6udZPNPw1QQErH0eq/rOR17zIZiy7jgGtK+DrhIPXy+VHEM717dZlXb1/HDyunP/+q9Xs4ZTzyclM1e8nzqvyHJeG3MnRSaR0nEcvv3vMlLv3kfq3TTJY/+0I78ny6xlJj2n0KLMLV79391kyL2KaR2CR5oE4qzZkO+0LFMr08HLWZi45ij+eu1Rm/WQwtj4W0yr5wR5PNRSQ0jplXbSUlI6DnU/qdVqJCUlITo62nQClkV0dDQSEhJEj9m8eTOioqIwceJEBAcHo02bNpg3bx50OuEHffHiRdSpUweNGjXCiBEjkJZmerAkJSVBo9EIrtuiRQvUr19f8rpFRUXIzc0VfFUYyVuB/FvA9SPAsmhgWW/D9oI76H3oJQxh/zO8L8oDDn4DrOgLPMgCNr4KnxMr8EPGsxiY+bXk6e19BrUM8bWrXHTLYPtOCNgcsl4RPPWVZeveon8viLaomJuy7oTkvpLvO79rTCqAKElm5ssr1GDtYcuASmu23tXpG/b/LF+6lYe9F29bdInxz21+fj3HmXU/2X05q3R6jmYnJtWOPZNdViSV/U8Yh1pq7ty5A51Oh+Bg4UMuODgY58+LT71++fJl7Ny5EyNGjMDWrVtx6dIl/O9//4NGo8GsWbMAAJGRkVi5ciWaN2+O9PR0zJkzB48++ihOnz4NHx8fZGRkQKlUWnRZBQcHIyPDMnkWAObPn485c+Y4cnvl634WcHhZ8eu7hvd/TkbwvSP4VHkE07k1wHyRh9ffbxn+TfgKePw9QOEBObRoxVzFGS4cSoUSjWrb1zUR5KvCrqk9cO++GtfvPcDrv1gm5AKASmF/7FvWBSDdpWRNq7LQ6DkUaXWlXnRzzp9n0SLEx2K72KiDq3cLBF1QW0+lI69Qg6Gd62P72UwcSLmDGf1bInrRf5YHF5+P4zg8/fUBZBWosWtqD+NunZ4TDIEvbdKwWquHQmZKhB7w5T5cyMzD8Vl94K2iMQqkeuDsCBNqIQct2DTs17cphxpVbS4f0q3X6xEUFITvvvsOERERGDp0KGbMmIGlS5cay/Tr1w/PPvss2rVrh5iYGGzduhXZ2dn49ddfS33duLg45OTkGL+uXSv7Q6tU+n8ivn39S8Dtc6b3i1oZFr8sVpux46/xa4Y8i7fk67BZ9R5SPF7AmQaL4MHa91BlGQYNA73wUP2aeIo3qsdTKcMPozoZ3/MnukuZ19/qOStyUPMQcwETZZvAwjV/Ob3+yzF0nLtdkBh8+qb93Xu384pEF7QTa+3ZdloYzP9v9VFM+/0UbmY/wLgfj2DF/lRM+VW6VQkwLFB66kYObmQ/wMVbecbtOo4TdDnZSo7+JTENk9ceg0anB8dxuJiZh1u5hWg7+x9M4gXKZ9NzodVzOGwjv4mQiqo04b09Lee7VbFYrZyPAax4z4Oz62RNxf0Nbh+H/lwKDAyETCazGHWUmZkpmQ8TGhoKhUIBmcyUGNuyZUtkZGRArVZDqbQc1ePv749mzZrh0iXD4oQhISFQq9XIzs4WtNZYu65KpYJKpXLk9lyjyzigw/OA0gtIOwQs72PYfks4wgVa+1ZOFvjxKaBRT7wq32XcxF4/ZAh2wh8RFN3zVg8cTbsHGcsaW2SUcvGY9rGmtdGglqfxfUmg0oM9Dllee6tVkjEMmgR529WVU942qGYDALLgg190rhkRdt9s+KatUVf2EGv5mf/3eTwfWR8+HgpB/gt/jauSeXWk8Ftg+PNu6HSOdT/FbTgFwPBzcye/CPN5C2ZuOZmOJc+bHVDZ27cJcTIfxvD7v6fsuHsrUgU41FKjVCoRERGB+Ph44za9Xo/4+HhERYlPJtetWzdcunQJet6Y2QsXLiA0NFQ0oAGA/Px8pKSkIDQ0FAAQEREBhUIhuG5ycjLS0tIkr1uhKIu7CepHAo0fd+65L++y3JbDm7em+PveoJYXnu5YD0+1r4OXH2mIFiE+GBXVwFDm2mHgyl70ZI9hseIr1NDnQ86bGVfGMHia3YuVyo+Bz1rjQ/kyvCn/FSsUH8ETwiRYOctivQMTC1qjhPMWf/SAKTG3LXPZaectD1J5KIu2XwAA3Oftn7HxlM3zlfwlpuX9n3z+B9OItawCdamGdOc80ODT4jpZY09zvJivdl60GagRUpH0lJ2gGL6cOdyxHRsbixdffBGdOnVCly5dsHjxYhQUFBhHQ40aNQp169bF/PnzAQATJkzAV199hcmTJ+O1117DxYsXMW/ePLz++uvGc06dOhUDBgxAgwYNcPPmTcyaNQsymQzDhw8HAPj5+WHs2LGIjY1FQEAAfH198dprryEqKqpyjXwCALmThlf7NwCyr4rv2/iK4YuVAwov4MlFQMZJoNNYoCgX77bJAZ58zFBWpzUkKwNYURxjNi9cjqAb9zBKthPZnDee1nijueJn4+lHyE3B5QrmY3ysGYokrjkAgGUBHw8l3ml8Ba/cmIEszht9iz7CLUhPfueHfLRk03BQ3xIlj9zGzA38pZyBVbo+WKA1/Klfj7kNFdRI4cwnouPwumwj1JBjqe4pi/PXQg62qUwj8zyZyjXDZ6pEa8+K/amYNaA1XlppWgXenokW5SwDjuMk5/rZcOwGXuwabnxvb1DDMPbN41OawVTH0u7hk38NAZO1CRAJqWhkRdkAattVtmIHQJWjY8rhoGbo0KG4ffs2Zs6ciYyMDHTo0AHbtm0zJg+npaWBZU1/5YeFheGff/7BlClT0K5dO9StWxeTJ0/GtGnTjGWuX7+O4cOH4+7du6hduzYeeeQRHDx4ELVrm34QPvvsM7AsiyFDhqCoqAgxMTH4+mvpEUAVVr6dEwY27QO0eBLY/h5QKJKXMWE/sP8L4L+Ppc+h1wJFOcDvYw3vbxwFUvcaXvvWBcIigQZdLQ5rmb4J2LgJc4tHlOMCJH+eI9nz+F01Bx0Kv8V7ip+gSkoDWvTBKzdmAAACmHwkekzEH7quOKtvgLCIfng3Ufhj96NyAdqzl/Gqegr+0XcGALwl/xU1GDXGy//CAu3zCGfSsVM5FQDQR/0RLnH1TN8q5gZiFesBAMNku5CJmjikb4FF2ucAAM/J9qA2Y/oeyh3IqWnBpKEXexTLdX3xAOU33w8AyKHFCFk8duvb4yon3s165mYOEq3Mxiwm+4EGD8+Pl5wSAIDFPDW5hRos3Z2CpzrUQQuJUXMMDHk69riR/QB1/DwEsynvOJsJhgF6tQzGt3tScDj1Hr4Z+RAUMhZ38i0nMCSkcqgcwUBVUaohCJMmTcKkSZNE9+3evdtiW1RUFA4ePGhZuNjatWttXtPDwwNLlizBkiVL7K5nhdR+OHAjyXqZzi8D0bMBlQ/QZghwOxn4wazbSuUDPD4DOLIcuG+ZXCqqJKABgNwbwJkNhi8neE2+CUNk+4Dt+4DL/1rsHyg7gIGyA1Cf24r38TkmyTdht649XpdvRHvW0B30nGw3/tF3Rgjuog1rWp5grnwFRsm3G993Zc9gLPM36jJ3ME3zCsIZU9JsOJuJcGQikj2PDK4Wsjgf1GCEXWRPyg7iB21/HOea2LyvOYqViGTPY6BsP4ao5yAPnjaO4FCPuYMbXC1wZcjDZ6DHN4rP0VuWhCv6YPRUfyZa7nx6nuj2EiqooYUMOphy2nYnG9aosra8xv0iU5fWwct3sWzfFWw8dgNf707Bmpcj0bWJISDit8xItShlFajhX0NhfL/28DVsP5uJkQ/XxweD2uJWXiGm/nYS/10w1GvL648Y83K2nkrHwA51LVqACjU66PQcvGgUFSlHpWll1DO0xGJ5ou92eev8MvDiX0DseaDTS4ag5ZEpgIyX1Nz/E0PQAgAqbyCopfAcKt5fyl5mzZo1GxrOX87Gyv82vUnZKVlOqcnBUsVneE2+Cb+r5qC77KRxnx4sAA57VW+gHmMK1PgBDQDMVazCcPkuPCY7hQSP1/C9cpHoteYplmGpcjHGy/602LdJNdP4WgEtZslX4R/l2xgr2yooF8kaHq7N2Bv4TWmYIuAx9gQ+ln+Ldcq5mCpfJyg/XvYn9qkmY7hMJNfJAeNlf6G3zBD8NmQzEcZkooZZ/pIP7qP1tTUIguWcNwDgiULsVb2Btcr3jdsY6DFbvhKjZdvwNLsXdSAeEPNnhf5gyzlBAPT8D4eMeT78dbL4I6j4Pt9xQVBu+1lDa+XPBw1z8sz644wxoAGAId8cML4uKA6uzJ8lEe9vR+tZ/zg8782d/CIs23cF90SWriirrAI1Dl6+a1cXHKlGOGqpKU/0Z055YxigYfFssE/y/vp+eCKwpAvQtLflxCSKGkC9LsCNI0DnccAjb5j2DfgcWD8GUHgCdy8a3jc0m22WkRmWZ7DFM9D+Vp8y6CkTH2rcW5aEVNkIp19PyVi/90GyfRgj/wcA8B77MwbIEnCb88clTpi70YK9hmdlu7FQ8Z1xWyR7Hl9oB0MNBRjoMV1haHX8n/wPrDEbYdWRuYjushNYpu0PDxThBfl21GXuYKn2KVzkdacBwDSFsPVyr2oKkvX1EKM2dTdOk/+CFsfjsU4ZjDx4Yr++DT7SDjfuf5Q9hSAmG0FMNsKZdCxQ/IDT+nCMlpta0jI5f3yoGYkvlF8BAGKKFiCZE85G3Zi5gSj2LFbz7ifngQYeChmKNKZgRWqiwdxCLZbsuiS6T6/nLIa9F/LOKZbPw3EcCopHmaXeLZDsDhPzyo9HcDQtGzvPZ2L1y87Nx3v8093Ivq/Bty9EIKa1eHchqX4cS4ynAKisKKipKLxrA1MvGJJ7zTEM8NI2Q9unzGx//Ugg9qxhPakH9wCv4jyJiDFA0gqgSTQwcIlh9uKDXxu6vrTFf/F3GGHIq/lnBhDzIdDxBWB5DHBdZIHSRj3FR1pZseOx9Yj+7xmHjrEmk/NHMJPttPP9rZyOlboYhDG3BNs7sCkAgN6w7CbkBzQlLni8aLHNDwVQQgM/5KMTewG3OH/8rjK09LwhF3b5PcaeROeipRbnMNecvY6vFYuxQDscaVww+skMn1ND1tDy0Y69gkXaZ6Ep/m/tx5iG1X+r+AzN2et4mD0nOGcwk20MaADgH9V0NCtcBTVM3UVble9AxWjwtnwtfIuHnt4+/imutxmGSb+YAlTzAEQGHRgYhoeXtM6Y67Voj3EtMzEl5+Sf2toQ87xCDU7fyEVkwwCwLIM7+UWo6ak0TktQkki9/5LjCxPakl08LP61NcdwcnYfeCikF5sl1Yn9QQ1HQU2ZUfdTRSJTiE8fCxgWwDQPaMz3e/ESP3vNBAZ9AwxbA/iEAC2fBMZsBd66ZGjVAYCe7wARLwLT0wz/siww5m9g2lXg0TeF539+HfDQKMPrdkOR/4qNRSsVXoh+vDfQ9TXr5RzwvfYJp50LAFqyafhI8T0myf9w6nkBw7wTFzxexGGPifhG+bkxoBFTm8nFV4ovwEAPBnp8ofhSsmx/WSL+U01BDHsYtRjL7p5E1f8QzqQDAEJ43VLN2et21/2Cx4uYKl8Hb9yHHFqoGMPDuiSgAYDaO9/EoR/ewPFr2cZtwungOWxUzsQO5VuATi1IPOa7cqfAal1Mc/DYN8R85A+HMPz7g1iTmIbTN3LQ6YMdGP69dD5fidM3chC9aI9o8HX8WjYe+3gX/jkjPnu5ObVOj0/+SbarLKn6qDeyfFFQU1V5Bhgm/ZObTUCo8jEEN+P3AX7FXR680WqQyYEa/oag6J10Q0tP9BzDeXq/bwiSBi0FU6sJhha9h+fV7+DWU6strz+5+C/4Ph8Ab1/BfWUt3FXVAzcjAxj4NfDEImxv8i72MhG4/cIuxKrH4wPNCOzTtRa9ne+0T2CFri8Kh/+OB82fBt68ALx9BQjtICj3q7a74H3bwh/QsPBnXNPbN6TSXZ6UHcQVj5F4T/4znpLZnlX0W6V44nBNJh8vyv7F67INxhFhpTFJ/gfeV6yAH6SDjiH3f4MMpq69iPv7EM0aWrc8UYR27BWEs5kILEwVTBAIcMW5PLZ/25ccxn8w8OfQMV/a40TxAq2bj980rqNlz+iwV39KwqVb+Rj34xGLfWNXHkZa1n28+pONBH+ebXYGQKRyKc0cS64Oapx9fqm/qysLCmqqozodgZC2tsspPYGRv5tyeGr4Ay2eAFgWDAMc4lrigL4NChs8bkiA5uO3GnkGwDMuBbWmnQSjqAF0HAF0HoveI9/CIzPjUbvxQ9igfww/6J7ASM0MjFe/ITjVtcbDMU87AjrIoGrWCzWGrwR8gg2B2yhTK8tczQt4W/sqlgS+BwBYpu2HPHiCA4saDs5No5dI7vtH1wkfasynyBVK0Yc6dC2+l+TbLLYNLpqN0/pwu88RyOSUKaAp8bRsP/wY6y0pixWG0YhBuIe4vA/xg/JTKKFBAK8VKTLjF+TeMU2aN5jdiwMer+M12UbjtoeYC4hXvokerDBIua/W4uDlu9DwAhn+DMsXMvNF16byraEAy/vtrNXp8cdx6dFeuYWWEz3eyH6A/CIt8gptr/xujq3sTwbiPA5EHRWhVaci1KEsKKeGlAo/KZRhADzxqWHU1vE1QN0Iy3CfYQwJy+bnEfnlv1PfEX/pIpGob4FkfX2MaT0IOJMsXr6GPzBqM3b8ugS/FPYEAIx7dQpw70nMW2Sa3fYr7SDMVvyIi/q6GK95Aypo0JpNtciROapvgima/yEY91CfvYU/dN3QnT0BBhz+07dDERQAGMxQrAEAFHIKeDDCB+Jc7Sh0ZU/jVfkWK99B+/Qrmo9zXANc5YLQBqkW+4s4OVSM8KE7QGa9u+UGVwuFnBKN2XTB9lyuhqCLCQDqm+UbmRsgO4irXLCgC68FkwY97+cjRrsLMR678K5mDIqgMH7P31Ssx5e6wQA4fKv8DLWZHKxULkR44Rp4oAhayIwT7vEX+jSfNLBQo7MY2u3rIRcEFj8mXMXcv85a1P/6vfs4eDnLIjC6kf0A3RbshFLOCmZe5jgOuYVa+PGGqIuhmIZUNZXlZ5qCGlIqoj/gDGNohSkjNRSYpJlsfL+oUV0AVnIUGnXHikAVHmQbkj+VChkQ1AI6pBiL/Kjrg2P6JjjHNTAmwZ7VhSOMuYXX5ZsAANf0tTFC/Q4ewANXEYJEnWEo/Q59hPE8XRoGoFWoL/473BaPyU6hv3o+1gSvQUj2UQCGIOesvj726NvjOdke1OQl6/LN0byAACYPjZmb8Bi4GD573kXnPMuh8HmoAQCSk++1KFqJmsjHX6p3UIex7GZJ0YdiumYcWHCowRRioOwAZmlGowAeSPF4QVB2t76DRdfXSqVptNXgotm4ztVGgmoSZIwpCDDPSfpa+Tl+1Pa2qMsHihUW275XfIJQJkswOaIKavynmoIszgd91R8BAM5nmFp+NHrh5In31ZZBjYxlBD+je3hDxvl6L/oPD0SGhSdeMfwsCfOEgIlrjmLrqQz89dojaFPXT/ScgHhLzYXMPKTeKUAfGhlVaZWmFYPjXLOArqtUluBFCgU1pEL4eWwkFu+4gCNXLedcqetfA7un9oC/p/Rfx3obvzf0YNG4Y3ecOCrsglikfQ7NmBvozR7BJM1reAAPvN23OU5cy8aZm7m4fk/YcjGxZxPU8fPAkwfehK+mALdREyGv78D6797HhrQauKwPxfRne+DN307gOfVMbFe9LVqff3WdcKN46vRlXoFYGfoeDt3zsQgQbnP+AIA1ul7o7nMTW3IboSl7A0+xBzBLOxocWGTBF/2L5mOZ8hNEsBeNx67U9sE87QjTSCYO2K3vaNzfq2ghnpIl4KS+IRox6UjjgiXzeQ7oWuEo1wwA0Ef9MSLZ85inWCZath5zB+8ofhHdZ6637KjFtibMDeNQdB/chwoa3IEpgOjyYbygfKFGB5zfAty7CqCBcTs/sEgS+bnS6znRgMb8WL6tpwy5Mk9+uQ+pC57AA7UOSjlrsTq92NF9PvsPAPD7hK6IaCC9bAipWkq71pkjZNAJJtisziinhpSKgrfgZaB32VdDf6RpINZPMC3ZUPJLP6a1YfmN8EAv+HuKL4AK2F6fqGfz2hjcsZ7ovvGaN9Cx6FucKJ5h+H89muDbFzqhY33Tg+e9J1vhmYh6eLRJIDgARVDiNmrCSykDWBm6DpuGe8FdMXlwD8hlhkfaRa4eni0yTfKHJr2BUZtxpM8G5KpMeTdNg3wADvhCO9iibkUw3PN1rjY+rj0fX+sGYYpmIloUrcLPOlNrSDZ88JL6LcGxl7i6gqHZ5lK4uvhM+wzi9RH4XvckLnDi3x8AUPC6uFK4ulij64XBRbMly5cFP6/oQ8UyHPGYgF6sKUlXDi34ScYPNDpg7fPAP3GCxUr5cUZ+kWVezIoDqZJ1KCiyPa9T9n01Ws7chgFf7rPcaeWv3eQM67NAk+rLkSHdGTmFyHmgQe17x3BeNRovyf62fVA1QC01pFRkLIND7/SCTs+hhtL5fyE8VN8f34/qJJhe3xqxkGZ6vxZYUDzdvthf3i8/0hB9WodgfdI1vPZ4U0xeewzNgk25G3Oeag0vpQzPdgoT/GXN7+pQFc9FUse/Bv6ebJj0cBNv9t1ULth0wZZPAo26o1Mj4MTDHFJu5yOrQI36tTzBsgzUUKBX0UL86xEHGadFDidckoHfFaIR+a+bA2+8pXkF42V/4hjXFL/qegj2j3u0Ib7fe8XiuBJXuFAMU7+Lp9l9GCrfLdiXordcRPIE1xi3OV/UZnIlz/m3rjO6sWfgy4gvoSBmiMy0nEdJy9H7ihWIL4pAY+YGtirjsEoXg3laQ1fng0LT7MB1mLs4xTXCjnOZeK5TmNXrrNgv/r3IzC3EO3asdh5/zpBvdDY9Fz/sFa78bi1RuLI37xMHuSDz9m5+ER6eb2ixPBkwEwpGh5mKnwB8Zf3AaoCCGlJqwb6uW+CRYRgEeEm3zFgQ+b0xvntjY1Bj/iDpHF4T7/RvCZZl0KVhAABgw/+6CcoEeCmxYEg7i/PW9a9hfN0kyNtiP7/V6A7jD9SPAq4dAuqbWqJYlkFTXgD1dkxzHEnNQu8Oj4Htk4FpM+OwS9cB3iq5sZWhU3hNJFw25HqMiKyP1YfSLK79m64HfjMLZkporc1aV+ygvhUO6lthuvZlyKFHFHsGL8m24XPtEIuyOsjwcNESTJBtxlTFb6Lne0/zEvyYfMSr3hLdby/v4iUinpIlQMVo8Yp8C5L0TfGm/DcUprxnLMcWL1Z6775GtCtTUH+J78fiHRdFt5vjt/58sEU4qSHFLZXDtSxDsB0WYGtNt7JwflBzNp33h4SDQdOxtHtIzylE/7alH6VZkVFQQyokRx8K9WrWQGKq9H5PpfBH/bfxlquTO2Lj/7pi+f5UxPVrYbGP/7DcP60X4N0HKLgN+NWVPF9YgCcOTH/cOLprnc4wkitQITM+PJ+NCEPDQC88VL8mWIYRDWpKNKrthcu3hcOxezYPwor9qXbdHwcWGrD4T98e/+nbS5bTQYavdE/jWdkeNGCFI6WeKZqJO/CDhhO25D1dNAcbVbOM71P1wQhnra9eX9LSwz/Xe4qfDWuE/TfeuG2i/A/sV7dBLrxE82j4pII8rc6+xE6xLq0SGp0eaxPT8Giz2oIgGBB2ixH3KdTo8OjHhlnSL37YT9ClLqU04Qlnxx8TpvO7/ofj6a8Na6v9PflRtAy1f4mRyoJyakiF5FArDYB3n2yFgR3qYM3LkYLt855uixYhPojr3wIeCuf9uHesXxNfDu+IOmYPLADo3syQABxey9OwX660GtCUEBvezq8zywKDH6qH8EAvqKzcy7hHGxq7wvgebRqIFWM626xHaQxWz8GL6mn4R9fJuO0cZ0jazYE3ftT2hp5j8JJ6Ko5xTbFS28dYboPuUfQqWogszrLVi08J4dB5/qKnJdqwqXhP/pNddb6dJz530f5L9q1/Zm3+mtS79zF9wyn0LU4O5pNaI6ugSIvTN3JoQcxycu++qdtSKmG8Krt61/4uYaDytD5SSw2pUBYP7YDtZzPxYtdwh44L8FLi82EdLbY/H1kfz0caFmgM9vHAE+1C0bCWlzOqKinI1wPHZ/a2aB0qDZXcFLzwn3X87QAQ1aiWsWsq2NcDKrn4nEBdwgOM7x9pEoh9dj7AbbkLP+zRt0dN5CFGZpiVtwCmgG+mdgxmascY33+oHYmmzA0oGQ1W6fogB94YoZ6BifJNeFImvgRHG+YKvJhC0X18A2X78ZZ2vM1yUm7m2L4GACzdk2KzTJ5Ia87bv59EVONa8PGQC5LfBy3Zj4u38vHDqE6IbhVscRxxHbsf2KUIOF0RokoFxmXRlLlePL9UU9H9lSXUpqCGVCiDOtbFoI62WzVKg2UZLHn+IZec25y1kVqO4AdG/CHtSrOgZtLjTYxBjViLTwn+0ONeLYMwoUdjjPjBxjpeNuyI7Y43fzuBE9eysUnfDSqNxuYMyBrIEefzIdKyTH8tnuMaYJJmMp6Uic/YPFH+BzK4ANF9fFJDWz1RiJbMVRzlmoLjNVIroAULPRTQIh+uzK0wKen2aB/mjz8mGnK5Lt4yzGm08fiNCh3U6PQchn9/EI1re2H+YMucs8qi3BrEHJlR2OppOOy9eEcwEaXto+xUlG+cfuILve1lWioy6n4ipAJTyBhsef0RbJrYDT4evKDGrP+/W5NADO0UhmBfFZ55yDA0e6VIVxN/VI5SzqJbk0D8PiEKHgoW7/S3zA+yR5Mgb94vbgbrdD1xhmto8zjzwEzMoKK5mKF5CQDQS3YMA2QHbB7DgsPD7FkEQDgqa7FiCX5XzcEw2S60Zy7hZdkWNGAycEI1Dskeo7Ff9Trq2ZhBuTSu37uPiWss5+MBgBPXspF4JQsDl+w3brM3p6c0DqdmoduCnZKrptsj6eo9JF7Jwi+J15xYM/ey9oeAWUHXVsSKf89mYtTyROOopxKMM4Ka+6ZV62V68W7ZytL9REENIRWYjGXQuo4fOoT5C7bLeUFNdEvDX/UfPdMOCdN7wa+4RadH8yC88HADwXH8lhpF8UKmEQ0CcHp2DF55rHGp6+lALqRRs2DxHJpftD1RxBmGtx/nmmCLzpQnZb6MgxgVo8Fa5QfYonoHL8n+xp/KdxDBJKOPzDDXzXzFMvyhmol3FauxRxULz+J1wfyY++jBnjCe5wvFl9isnAEFHF/7ie/1X45hy8l0yf3PfZuAE7zVzvnLQOSJrElVFi8sO4Qb2Q9EF+60l9SosWqhNN1PDswobC1ReN9FQ1exq7/9DFO5w4LKXXtCqjh7FkYc1tk0HwtrNrSmqVngwN9dMkmg4bXwV0EnB2e8DfQ2dbcF+4pPxvjDqE6C9xO6N4FCxqBn89p4/fEmxu1x2pfRsehbpHCGbshs+OB3nWXiM98pke6uUCYLMxU/oS2bit9Vc+y6jw8UK/Ce/CeooMZTsgS0Y6+gA3MJAFALOWjMSC+KKeVipvhSGVISUw3LXfx18ibazv4XX+++5PA1pRRqKteU/WVVpNXh0i3x73/59T4550rlMTNxeV7HVSioIaQCM59+n8+zeNLD9matOHzPdQpDZMMATOtr6FriN7NbO3dsn2b4fUIUZg9oZbHv0aaBFtuGdq4PljHMDRTZsJboOevWFI4UaxDoiVOzY7B8dGfE9mmOix/2K97DoGmYcH2kU3pTd9ZczQt4XzMS3Qo/N25boB2OjzTDJO/HEWPlf6M/a8oz8i5uHdqregPxqrcQDMs1tqwRSxa2Wr54VNVbv50EAHy8zbDu2fmMXPx18qbkcYBhRNexNOtD2auTkT8cQvSiPfj7lGVLGY0y46s63wtKFCakArMWeByeEY2CIi1q+0gvU+GhkGHdq1Gi++Ss5d80/+vRGCm38/Fww1pgWQZn0y2n9GcYBq92b4Rv91zGx88YEkX7tgnB2bl94aGQSeaPKGTCe/FWygUtS/x5QhRm953MmVqjduo7IJUzTBz2uXYw6jJ3kKBvjRNojGmKtaLXdlS0zLQswwrlQvQrmm/spnpOtrt4dXHXeXfTKYthxn0XG2ZaDvBS4vLtAnyzOwVvRDdFx/r+aBJkSB6NnLcDeg6Y2LMxch9o8d6TrSBjGaRl3Ud4LeckQVemGZEPpxoCvDWJaehnZbI5ewOc0j36nR8wCD4DJwdnUl1gducduRkFNYRUQHKWgVbPoVsTy1aREl4qucXq1A5dQ2b5S+rtvsJkYalf9nH9WiKuX0vBNo/iJSN0OvFjZGZBlHlXGZ/5RGhH9U1x078T9tzxMQY0APCZ9hnj6wI4b4brJ2SJgvfj5X8aX7+pWI9jXFPs07d12vXM/XxQemLF9UnXsaF4Yda31htac1IXPAHAlG+xZJdhuHmDWp44eT0Hm0/cxMcis2OXRuV4tNnG/9F2ZTtFVWkRqiz3Qd1PhFRAu6b2wMdD2mHsI7ZHEZVWSRBizWNNa1tsszUjrtRMvXKWQULc4/hgUBsceTdatMzHQ9qhfoAnPni6jWB7EZSo80Y8Ap//VvK6nAO/zlL0wr/al2oHWC0/0GzU1dMykUUsy8mGo5Z5Pfx1wfiu33uAzScMXVYzNtlez8oe/L/YK8uDjj91QEVmfUh3+dTBFXPglCdqqSGkAgoL8HTZejQvRjVAcmYeujUWz33hCw/0wv7pjyMrX40BXxke5LZ+5UmtmK6QsQjx88BIsxFZfM91DsNznaUXoqzlbX3+n2XafhgrN61WrOZkaF/0Pd6U/4Z9+jbYrTdM0DiQ3YfPlV8by/2j64Re7FE0Ze1LBO7MnIcvCpAL107kWMLWiKNm7/5tXMOMT8MbHq6RaEErC46rHN1RtmbPdWXAwDh08tJ8M51QeTvqWFm6n6ilhpBqZs7ANlj7SpTFiCcpdf1roG09P7vPP6l4JNPgjnXRlRc4eakcW8198dAOFtvMZ1I29772BTxS9DkwcAk+0IxAL/UneAAPfKB9wRjQAIaWH+N1tINxjGuKIepZeKJonl11q8/exjS5c/J37LHyQKrNMolXLBOYzdf/EsNxnGiLi1QrDP/ZVjnaaezgwhtxRcDk/PCCX8nKEbxIoaCGEOIQ/uriYh6qXxOnZvfBp8+1F7TKOLpsxKCOdbHoOeFimmLLP5i7ztUGOo7EO+8vwVM9xBcuzeMt4VAyXDwX3jjDhaNz4RJkcv4o4hT4TyedNzNCHi+5zxYWerRjUiC3cw6cP09YH/UkpWSWaWteXnUET365T9Aa9Nn2C3jko124lWe5ZAT/kSfVKlcZCHNq7EwULsXtcqhsw+jFb7KydDVSUEMIscvvE6LwUreGmNxLfG0YPh8PBRiGEeR6WBvJZS9bLTV8LMtgQo8m8PGQo1sTYVdbJmeah+cOJ2yFuo2aiCxaguZFKzFO86bVawShdMOnX5dvwGbVe3hfvsKu8sd5k/M5W/z5WzhzMxfn0k0zMH8efxE3sh/g613W17eq1EFNec374qTLSJ2mvNpVKssnTUENIcQuEQ0CMHNAK4dGXDn7weHo6u3eKjmS3u2Nn8cKV2+/xNXFXtVjWKPtiQeio6YYAAyKoMRCzXP4S/cwtusiLEp9oliKZsw1u1tcSrwh3wAAGC7f5dBxzqa3kasjlssj6H6qLE86G1yaU+PA/wFrMwqXF6csu+BGFNQQQlymb+tQtAr1LfUorhpmI7T4AdXXI0yLk47vLr3Eg1LOiiQ5MviiZhze0Y6zWYclukGYpHkdx/RNLPY9JjuFf1XTcMljFFib3Qwchsl24iHmgs1rlhf+xIAsw+BiZh7yedv0HId9F+/gTj5/PSD+6KfyqKVrVOoh3YIf5/JJFK4snzWNfiKEuEwNpQxbJ1tf4sCa6FbB6NUiCB3r+xu3dW9WGyevZ+ORpoFY83Ik7haoMaB9HdzMNg1ftoc9Q9r5ftT1xgDZAVzngtCbNzlfib2qyRiEz3C7SPzXaicmGQsUPzh0TVd6oNah/Zx/je+TrmbhvT/OINTP1HK19VQ6Vh9Kg7dKjtNzYgAIW2oqc/cTnyvzRdzxHVp3OA3nM/Iw88lWjo9aquSfKQU1hJAKSyFjsWy0cLXxlWM6Q63TQyWXoStvcsIirc78cEldwgPw6XPt0euTPXYvY5APT/RTfwRPFOKs7CWL/XWZu/ih/g5cunIFx/RN8LMuGv7IRzZ80Iy5hhmKNXbXrzycuZkjeL/tTAYAID3HlBx8775hQc38Ii3uq7UWyd6VOaixt+YfbzsPjU6PGU+0KlXw48gxpZqnRmT7tN8NcxI92jQQj7cItvv61hkupNbqMWXdcTzSNBDDu9R30rmdh7qfCCGVCsMwoqOgAr2ll4sADL/gfTzkSHynF34dH4UgHw8ceU98EkBr7sMDR0W6ogCgfdqPGCLbiw8UK/C+fAWOe7yKd+Sr8a9qGjqy4gtT2u62co2NxxxbnPORjwz5P4IZ+h04XqPT4+mv92P67ycduq6r8IMNqfu4r9bi690p+H7vFdzOK5Io5W7Sn8L1e7ZXtbf/Mobr/JZ0DVtOpSNug3Mmc3Q2CmoIIVXCm32ao2/rECx7sZPo/uWjO+PwjGgE+Zq6V1RyGcZ3byzoUnk2op7Naw1Vz7RZ5gX5DgDAK/ItVst9pvja6n5XWX1IuBSDrQaFrAI1ALMZhR2IxxJS7uJYWjbWHr5m/0EuxM+Blrp3fqK0Vq8Ho9egP3sQAcgVlNPrOdwr/v5YcEFrFsMBrZhUqCBxzWI5xS1tfKG4C19Iz18klShcchs5DyzPWZFQUEMIqRICvJRY+kIEerUUb25XyFjRPJrp/VrgYFwv4/uJPZtg99Qe6Nq4FpaP7oR2IhMPaiBHr6KFeFczxupcNvYoWYIhhj2MZoz7HvilefY60v1U8bqq+C019iXKtr/8Hb5WfoH1ytmCfWNWHkbH97fj9I0ci+MW/H3OgRrZl/9S6+oWbFW9Y1EPcxZdq3mZSPB4DSc9bCfIW9atcqCghhBS7bG81gcZyyA80Atrxj2Mx1sE48NBlkHLWzHNkcLVxc+63nhJ8xY+1gwt0/U7MefxrfIz/KuaVqbzlIXOzqCjtJPvuWOafRZ6dGQuQiEy5N6eqgtapQCEZ24HADRiM4zb9XoOey7cBgD8fPCqYZtLhmabKhx06TcAQFs21eoRFkPybx51yvUrMgpqCCHVnrWJAdvW88PaVx4WbGtdx9f4Wgs5vtYNBKLniB7/nmY0+hXNt3r99uxlB2rrGqVKgnWgrDtmYHlT/is2qmZhoWKpxT5O8o19Sr5fb6w7brFPKxiD4+p5akofbBQUaQ1dVLzPXir2rHANbRIoqCGEVHu2ZjtuGWIKYur610CU2GKgXV8D5y9crDNZ1QY/6foghatj9fzvKX7mvXPP08PWopkl+KXsaanR6zmk3ilwy8KX42V/AgAGma2yDgjrLnUXgjIS9yo2jQA/L8Wdk9lZ+3gYBmg96x+0n/svHmjsyJOpJFENDekmhFR7/KBG7He3XGba/8GgNuJrULEyMK8dRebJHdj6+3Ks13VHcFgHICcbaijsrosH1CiECmFMJgKRi2Oc7WUpnOFoWrZd5QSjhux4zs3YdAq/JF5DTGvrQ4s5joNWz0Fh50KrZSWYfE/iPsy38wMUV6xQ/rwsHhzHlUtXHf/ebmYXwjR9pfW1nyp6bFOqn54lS5YgPDwcHh4eiIyMRGJiotXy2dnZmDhxIkJDQ6FSqdCsWTNs3brVuH/+/Pno3LkzfHx8EBQUhEGDBiE5OVlwjh49eoBhGMHX+PHjS1N9QggRsLUsFT+osdqiIZOjsP6jmKN9EWe4cGhK8Xfjd4pFAIC9qinYqJqFaZGOLQ3hSpdu5TncUvNLoiH5+Z8zmVbLjVqeiC4f7kCBnfMGlZVdC1paCXzsfbY7Ep7IGb3kz5fUt5qx8hlYS4DmB6esHUFUBY9ljBwOatatW4fY2FjMmjULR48eRfv27RETE4Nbt26Jller1ejduzdSU1Oxfv16JCcn4/vvv0fdunWNZfbs2YOJEyfi4MGD2L59OzQaDfr06YOCAuGws3HjxiE9Pd349fHHHztafUIIscDwp/4X+fWtYE2/Km0l1PInqOMX/Z/6dWg427MYPyY7BS+Y5heZ0CzfosxQ2S48wpb/PCEfbDlnVwtHaey9eAf37muw9+Jt553UCnsCMntGRUWzSVirfB914Zx625WwbZbAbDfeufnX4Yc00kFS5QhrHP4zYtGiRRg3bhzGjBkDAFi6dCm2bNmC5cuXY/r06Rblly9fjqysLBw4cAAKhaEJNjw8XFBm27ZtgvcrV65EUFAQkpKS8Nhjjxm3e3p6IiQkxNEqE0KIVR4KFo1qe+F+kQ51/WtY7Gd5TTm2FoGs7aPCnKdaw0PBQqvnsO/SHfh7KtCi2ygkN3sDbfQXgDodgA+lf5e1YVJNb7RqAKbWmk7MeXyk+B4AEF5YvrMUa3Wc4C98scDg1PUcTPrlKEZE1sfTHcXn/Cm3LhYwsOdhLPUct/yozXNsGPyg/BQAMF/xA7bCcs4hR3Nq9C6ci5HjpSLzW4Ts+SgqerdTCYdaatRqNZKSkhAdbZqFk2VZREdHIyEhQfSYzZs3IyoqChMnTkRwcDDatGmDefPmQaeTntI8J8cw1j8gIECwffXq1QgMDESbNm0QFxeH+/fvS56jqKgIubm5gi9CCBHDMAy2T+mOvdN6Qm4jp8OefNoXu4ZjaOf6GNa5Ppa92Ak7Yrvj9V5N0SasFtAgClBYBk5861Tvm95sfAV/Kt9BXdyGDDr8qnxf8ri9b/cUrN3kbHpO2Hax4ajlrMSxvx7H1bv3MW/reXT+cIfEeVxUQQfYs6ClI/lDNZk84+uyJArbO7TeHpanEs8d4//If737Eq5lST9bKzqHgpo7d+5Ap9MhOFiY8BUcHIyMjAzRYy5fvoz169dDp9Nh69ateO+99/Dpp5/igw8+EC2v1+vxxhtvoFu3bmjTpo1x+/PPP4+ff/4Zu3btQlxcHH766SeMHDlSsq7z58+Hn5+f8SssLMyRWyWEVDMylrErSVWsdeKHUeKzGMtYBr1aBosv4eAZaLlNQls2Ffs9JuM7xSKwDC8XwmyJBZWCFSQ912Nuoz97EM7qOjiQclewXMCi7ReQmWtYKyq/SIvnvk3AxVuW3WXmKsJEfPaMbOJvzcgtlNwH2J4zxl72jUJjeK+E5edbmeyPf5uClhqzcu/9cVrkaPcs5+Eol49+0uv1CAoKwnfffQeZTIaIiAjcuHEDCxcuxKxZsyzKT5w4EadPn8a+ffsE21955RXj67Zt2yI0NBS9evVCSkoKGjdubH4axMXFITY21vg+NzeXAhtCSJmZP5C9lDJEtyrFooGTDuPOtWQE/tLX7kN6yY4J3tdAEQpgavVhwCCDtyDlPtVkAMDr6knYrO/qeB1F/G+1cAK37PsaBPt6YP2Ra0i8kmXXOXR6Dg4uku509oQO/M/6uW8TkOClRcn80mJxkJf2HgDzlhrHSHVvSseBph33CtT4do9pziPzYI3/jt8ixE+UnyJfj61FU+ytboXjUEtNYGAgZDIZMjOFWeyZmZmSuS6hoaFo1qwZZDLTT3DLli2RkZEBtVq4bsWkSZPw119/YdeuXahXz/r6K5GRkQCAS5fEF4lTqVTw9fUVfBFCSFmV/IU7rW8LAMDHz7Qv3Yk8AxDYPAoIagUAeLpoDjoVfuPQKZ6XxcMTpiCGZQCtyEMxkrV/qv7SkjkwFPuJL/bi1Z+O4HZeEaasOy4IhsqrEceuriWz7YUa6yvBe2rLnuZQlu4ntc5WawovH4r3c8LPGRst/xfNNCI/LyLVKplBuSJxKKhRKpWIiIhAfHy8cZter0d8fDyioqJEj+nWrRsuXboEPS/76cKFCwgNDYVSaUh+4zgOkyZNwsaNG7Fz5040bNjQZl2OHz8OwBA0EUJIeWkZavgDaUKPxjgzJwZPtCvj76Cx2zHa8ysc45riDvzwWNFn0DzzI9DgEZuHzlCswTzFDwhALnxwHwzDYER7f/Rkj2EAa5pwzpVxQkmWja+H/Q3/KbcL8M+ZTLy36TQ2HruB574Vz8kse92k20ns+Z5YK2PPyCigNInCtsvrJBKCzLuurJ1JavQTAPjoLYMz0zw1puPe3STWTeVeDnc/xcbG4sUXX0SnTp3QpUsXLF68GAUFBcbRUKNGjULdunUxf75hWvAJEybgq6++wuTJk/Haa6/h4sWLmDdvHl5//XXjOSdOnIg1a9bgjz/+gI+PjzE/x8/PDzVq1EBKSgrWrFmD/v37o1atWjh58iSmTJmCxx57DO3atXPG94EQQqza81YP3MwuNAY1AOClckIPvsobV9kwoHjl5DQuGLJW/YH9i0xlxvwNBDQGPm1mcfgg2QE8yR7EA6ig457E2Osz0Egp7KbSu3Dy+JvZDyBnGXy1U7zV3Joz6ZYLQDqTtYDCnpYa865G/sNf7BhOZBhRWROFdXoO9+4LezXOpedCLOS1lasknGNIfHtl5/D/yKFDh+L27duYOXMmMjIy0KFDB2zbts2YPJyWlgaWN6dDWFgY/vnnH0yZMgXt2rVD3bp1MXnyZEybZlq47ZtvDE2uPXr0EFxrxYoVGD16NJRKJXbs2GEMoMLCwjBkyBC8++67pblnQghxWINaXmhQy8sl5+Y/YF94uIGhOyBmHrBuBBAzH2jQ1epYXzmjhw8eAJ+EwF/s/M6vstFLK4+U+ti8QpGFJh09yZEVwN1LQJ8PHJri155eHkd7gqxNhGcv89aWUcsPYf+lu2gW7G3cptVxgEhOkvmPiMWEgRy/LC+os2MceWnWBnOHUv2ZMWnSJEyaNEl03+7duy22RUVF4eDBg5Lns/XNCgsLw549exyqIyGEVBb834DvDyoe9RneDXj7iulBzbJA0z7IvbAPvoxjQ25LWmre7N0Mn26/4IQaO0e+SFDjsL/eMPzb8imgfqRgl73dT1JdSaV9jJdlvSfz+GL/pbuG7bfO43vFWizWDpE8uyP5OPau9VXZ0IKWhBDiZpLPIvOWh+d/xUNFS9G/aJ7D1/hgUBuMfdR2vmJ5EktqLnWDQJFjSbqClgqJa5r/wW0rWBHrfnKUVGCyWjkPvWVHsVE50/yqxleODJXX25MoLbhKSU6NaZut5UXcgYIaQghxM3uTTsEw0EJuc9Vvc2Pk/2BkMz08lXJM79fCZvl3n2jp0Pkrg4OX7wrecxKvBWWsfCxi+8S6nxzOqZFoQQlmsgEASkZ6BJZ5krH5zxU/SHNGS42tiSrdoeLViBBCqpkB7QxBSosQH7vKF0GJ1Q+tdewi6w2DOcZ3b2wz9aRXy1LMu+MCO85mYvxPSbhXoLZd2EZzw4vLhQsvlzWnxlogypZlnpoy5K441P3k4HVKivN/dmTlsNSFoyioIYQQN3sjuhm+GfEQfhn3sN3HeNRtC7x+HPk+jbFdF2H7gJvHgCt7AQCTejaxWlTGMHisWW276+JM/GDh5R+PYNuZDHy6Pdnh8+y/dEfw3mK4s10zCruh+8mOFhSpXCHLezQvIbGGmV2Le1oWlVfA/icKagghxM2Uchb92oaippfSZtlVL3XB/3o0xqCOdYGAhkjo9zfGad7ECX0jQTm12Irgq54EAEzu1dS4aUy3cHz6rHACQZYFvnvBjkDJBc6n51ls4y/NYK/3/zprY54Z8dd81uKLMyeTLLa5svtJCv+aJUnG3rgPBURGlgkWI+Vtt6OOYvcml1FQQwghpAy6N6uNt/u2MK7xVPLX8ni1aWr7bbrOOMU1Ej0eJ3+FXMaiB3sM8+Q/QKYrgkohfBTIWAYeblrH4KtdlvPdsHa0gFy8LVxzynz2X/NHMmdHQ4W1kbl/J56xWafSKEv3k57j4IsCnPZ4GXtVk0VCFYmcGvOEaJFvt9j3QkYtNYQQQpyp5MGSjlrQvnkJmkHfYU/b+fhYM0z8gA3jAAArlQvxvHwnOt/+3eKhLhZEtK3r59R6O4K14+H54ZazKCgytU48sLGkgT2tE+YlbNXCKZPvlaH7Sc9xeIi9CAAIYe5ZBmu8+llf0NO+YMWeYLO8UVBDCCGVGD+vgfUKhKLDUMx/rjMOcS3Rt2iB+EHH1xhf+qpvWTx2xR5W7eq5L6ixNyGVP/Nuocb6hHLC2EEip6Y0k+9ZmYXYHo4OShLOEsxZn5tH0P1krQNOrI2Hs9hDQQ0hhBCn4ncBmD9jznP18abfZ8Cr/wl3bJpgfBl1+1e0PP0pasI0z4uMZQC9HsEwLTQZFuCJHbGPObfydrK3m6NIawpkbLbU2DFPC6fXY6hsF1oxqQAAhimPCetsX0MO070xgi4l86Ol3zk8oruSzNVHQQ0hhFRi/LlCGJG/nC8qmgGh7S228zW9+AO+UnxpOg8A/Pk6DnlMQj/2EABDa0mTIB/U9FQ4pd6OsL36tKHO/Dwardkx5l0sYu0U6TkPkHqnwLjd6/IWfKT4HltV79hVT45hRFpqSjd02pruspP8I4yvdPrStdRYLpMgdg7p1puKhIIaQgipxDwU1n+Nd2oQYHjxym6r5brJzkAFNeoxtwwtPsd+AgBMka8HYFqd3NUTrj3aNNBi25aT6XatXm2eHGyNWEtN1Pyd6PHJbuQ80AAAlHfOWTnecpsz1n4qyxk4s+4nq9VxuJvLibM/uxAFNYQQUom1CvVFvzYheDGqgWD7rqk9ML1fC0yNKV7Zu05HoMMIq+faqozDPtUbkN06bdxWMpHcI8XBRnnMTTL3z7NIzhAO7f5o23lcy5Je84oDcF+tE7y3xtoD+ca9B3aexbbStNScuJZt9V6l6Dj7206ELVX217EiBjJ8pVrQkhBCSMXAMAy+GWk5p0zDQC+M795YuFHhafVcjdl0AIDHxb+M27yYQkEZVyeH7r14B3sv3sHy/VcE27/97zI2HLuBwzOiJY/V8LqcLFaoNisrGNINTtByU3KLpVuZumyJwlfvFuCt9YbupdQFTzh0rE7PGRcvBWys0s3vnrPjNjOyCy22VcT4hlpqCCGkutDY99e/Qm76ezeUycIA9oDxvTsnXONPwleo0WHqbyeM7xkAGp153oxlV0xJoMIveST1Hg6kmNaGcmbc1pxJc6j82XTHFuZkJEc0CZnnGAm+A3YEb3P/OmuxrSK22lBQQwgh1YU3b02niDHS5RjhxHuT5RuMryvK1PhL96RgfdJ1wTatzvpT9t1Np9Dr0z0oKNIKAoB3N53GiB8OWZS3tkq3ZJeN2TGLlEsFLUi2OBooCEY06c33GfYev5aNVjP/wbYzmaayguvYX7+KjoIaQgipLrq+BtTrDPT5AHg0VrocI3w0NGFvAmkHAQBy1r2Pjc0nbgIALmbmW+zTWoziEfr5YBou3ynA5hM3rQYPTEkLj/mkhPygxoHgY9f5W/YXLgMOZhPzFVfynQ2noNbp8fepdN4ufledHcskGOepqYDNMzwU1BBCSHXhGQC8vMMQ3PjXB17YKF5OrDHmnxkA3D81/uu/HAMA5BZqLPaZdz9J0eoNj38pxpwaJz3AtQ5MCuNoHg+/9UjPceA4xmKf2BkdTWDme0H2LybINkuc2b0oqCGEkOqqUU8gcoLl9p0fWG5TGpKM5TIGT7IJ2KqMQziTblmuHHAcJ5hor4R53oiKsVzUseR4RnMf3yoWYTD7n8V+qbDNViBgCIbK9qB3eFI8Ho4zuzpnNlePtQPtvoge7ytWYppiLYL0d2yXL2cU1BBCSHXFMED3t+0rK69h+Idl8JXyS7Rir+IjxfcurJy0hnFbcTffcuVujZ0RgU7PIfziKsTIjmCRcqnFftPoJ+F2QfeTyHmlYgNH2rbK0jpkPk+NtXoIW4TMEqzF5uARqVcNWI6IcjcKagghpDrzDACe+8nQFdVqoHQ51pA8zM+p8cYDqdIul3K7wGKb5QgfcTo9B0VRlpUSJY9/awGGRPAgEhE4MpqqLCOKOAB6QU6NvvicIhPn6fV4Q74ePdhjlrMtW8034kRfVxQ0Tw0hhFR3rZ4y/Htlr3SZ4qCGn1NjrVWgfAgfqrZGP5XQ2zlJnXmZ8niIl21GYeFnYq2+LXP2YGjxqLZUPGJWB5HAzHgN/lDwijdqilpqCCGEGChqSO879yegLbI6T41fjfJfF6oEAw4aG6OfStjIE5ZsWREGCa4JcEo34Z+BxTw1Vs7lX5RuVzlr2ArYUkNBDSGEEAO5h/X9/32CbnX4LTUGDZl0TJevQU0u267L/DGxG4Z2CsPuqT1KVc0S5i0R65Ou45wdk9fpbI1+Kv7X/Flf+kRh+1u0+NcUyxuyeiyELTVBRVcky7Icb50si8U+reTl8IoyFXB+GwpqCCGEGJh3J/jVB5r3N73/72OMP9Tb4rC/a8zEePlfWB240q7LtA/zx0fPtEPdmlZahuxg/ui9fLsA/T630oVWzHxxzL+U76A7y5udWKKpRjj5niVnzLDLb215eH68zfL8OnnlXsYy5ULj+9grr0ofxwtqLFuHxLqfKl6rjBgKagghhBjo+UOgGWDSYWCwtRFODEZ3DYeH3pC0WzfPtBBmyareIyLrSx6tKOOK36V90Oo5YQDShk3FKuVHxvfGh7xZkGdXd0sZE4X57Jl3h1+iy8GJCGAsJyUUIwhqLEY/SV+XX5ahnBpCCCEVVssBptcTEwGFB6Dylizeuq4/Zj/VmrfF9MCbEt0UFz7oh8hGtVxQUetu5VkfamxoDbH24C7+19rDXXSXeHlHYppfj1y3XUiC1337j2U4UwCr1uqslDQ7TjD6qeKhoIYQQohB7ebAxMNA7HmgdjPT9ic/Ey0uNrnw9H4t0L9tCHq1DIZSziLIR2X1konv9Cp1daVaaoo0elgLWmyNfjI21Nh5PXv3uwJ/QUvObM0u68eZWlk++zdZsM/egI1yagghhFRstZsBvqHCbR1fAGo1FSlsGdWM794YX4+IMA79jmwYgDHdwiUvF+RrIznZCqmWArmMsdpVpDPvf7LA4eT17OLgiH+90iUKS+XoiGnE3LS7LACoeXPz6CWCGrFb5ScK3ytQC8tbbYMxnexBkQbXsuxb+b28UFBDCCHEOpkCGLWpVIcyDIMJPRo7tz4l55YIMmQMYzUA0VmsJyC07+IdPPXVfvx7NsPseiauapP5UvGlQ+UFdXKopUa6y8navcl1pq49Bhwe/XiX3dcsDxTUEEIIsc0n1HKbnS0QstJmyjrAfGSStZYajdZ6Ts3sP8/avIYoTrwFyOrdm5WvyeRZv4a1UzH2P9L5LTWW9ZO+h8dSv+Btq3gjoiioIYQQYhsr0Qrw4J7ptUSXToCX0gUVkn6o6jkOrJV8jwcaLR6ILIhpi63RT3+fzhDdXl4Pf8daakyJwgxjX/2SM/LQ+tZfpuMoqCGEEFJlFOYCH4XbLMYwDOr4lT53xlGDluy3+sD9JfEajl21tvaTbVo9sPfibcE26WtaefiXcXIb/jUlc2rEWl54icIW9ZZY0PKfMxmCYJFmFCaEEFJ5jdkGhLQzvb970ayA9EOOFRsqVUbCLifT+TNzi/AIe1rsEAfPL329Cxl5eGFZokh5ke+BjaRkZ/Esum27UDF+95PMrFXLzsXOaUg3IYSQSqxBFDDg81IdKnNBUMNn3trwg/JTJ5xVeE5+y4QjXS+v/HTEyiWsL1EQwx7G06ztWZIdxW+pGSnbYd8xZu9ZhoZ0E0IIqczqdARUfuL7rLRIWAtqlr3YqVRVcSSw8IZw6HHpQizb89RwIrPsMuBwM/uB6DE6G91P3yo/w2fKb+yvogjxId2mnJqOrLDFTXz1qsqxdAIFNYQQQuzHMMCIX8X3aQqAbx8Dbh6z2GVtBFSvlsGY1reF41VxoOxLsm0On9/yeuLdXfz9Yl03DACt2ZIHej2H+X+fQ8v3tlq5ou2gobSBBb+lxjypOi3rPkavSDQ/xGnXdiUKagghhDjG08rSB+kngNXPWmy21f1kfY5fcY48VD0Ytc0yA9gDVvfbkxirFx3SzeGP4zdQVLwcwd38IvT8dDe+3XPZ6krg9txfaTv1WOh4ry2vszvZMj/HPC6tMonCS5YsQXh4ODw8PBAZGYnEROsRXXZ2NiZOnIjQ0FCoVCo0a9YMW7cKo1Nb5ywsLMTEiRNRq1YteHt7Y8iQIcjMzCxN9QkhhJSFtaAGAAosH4g2g5oyPh9tPdztWfLgS+VXZa5Dz4W7RbZz+HT7BSz4+zxWH7qKmMV7cfWu7Zl4nZWFJNqdZG30k4j6zC3Lc1SFoGbdunWIjY3FrFmzcPToUbRv3x4xMTG4dcvyhgFArVajd+/eSE1Nxfr165GcnIzvv/8edevWdeicU6ZMwZ9//onffvsNe/bswc2bNzF48OBS3DIhhJAy8fB3+BBXJAq7+qFqfn7b1+Nw7750i9CK/amYsfE07uQXSZ6T363lyvvjn9meFpc/VDMtZiGuEi01ixYtwrhx4zBmzBi0atUKS5cuhaenJ5YvXy5afvny5cjKysKmTZvQrVs3hIeHo3v37mjfvr3d58zJycGyZcuwaNEiPP7444iIiMCKFStw4MABHDx4sJS3TgghpFRYFuj6umOH2JhVWGpF7ObBPoL3df1rGF/zz9iVPeNQfUpDZsckdY4m1JZ2X9mZzm1vcMLqNYL3lb6lRq1WIykpCdHR0aYTsCyio6ORkJAgeszmzZsRFRWFiRMnIjg4GG3atMG8efOg0+nsPmdSUhI0Go2gTIsWLVC/fn3J6xJCCHGhHtMdKi5jGQQjS3KmX6nuJ/P5bfixEf+h+pLceiKweWJvWR/IjgQvpW3RsKdtq/SJwo4PT2dYYchQ6YOaO3fuQKfTITg4WLA9ODgYGRni00NfvnwZ69evh06nw9atW/Hee+/h008/xQcffGD3OTMyMqBUKuHv72/3dYuKipCbmyv4IoQQ4iRKL0DlK70/RbjQYYT6CA55TMI3isWixaUej+a9VrZafNzpMfaU6PZSBx4uHP3E/46X9hyNHVxRvDy4fPSTXq9HUFAQvvvuO0RERGDo0KGYMWMGli5d6tLrzp8/H35+fsavsLAwl16PEEKqnbHbpff9NAjQmOZmGabdBACIkYlPRCfZUmMWxAhzc8qvpaAeY3u23rcV60RbVxzpYnLF6CfRrj3eJrtbkszOM0Oxxr7jypFDQU1gYCBkMpnFqKPMzEyEhISIHhMaGopmzZpBJjOtSdGyZUtkZGRArVbbdc6QkBCo1WpkZ2fbfd24uDjk5OQYv65du+bIrRJCCLElqAXQc4b0/uw048v6ATWkywEI9RdfG8qypcb02pE2G8vuJ9v4Zdoyl8322R9QWbuWZVDjqLK31Fhb/JOvInY3mXMoqFEqlYiIiEB8fLxxm16vR3x8PKKiokSP6datGy5dugS93vRNu3DhAkJDQ6FUKu06Z0REBBQKhaBMcnIy0tLSJK+rUqng6+sr+CKEEOJk7YdL79ObZq2V2+g2GtyxLl55rJHFdvOcGn7LjSMP2dKU5J+/FiNMYZC6dlln3nU0cHBn91OJ6/dsD08vLw53P8XGxuL777/HqlWrcO7cOUyYMAEFBQUYM2YMAGDUqFGIi4szlp8wYQKysrIwefJkXLhwAVu2bMG8efMwceJEu8/p5+eHsWPHIjY2Frt27UJSUhLGjBmDqKgoPPzww2X9HhBCCCmtGv7S+9T2P+zkMhbv9G+JCx/0w7H3ehu3W+9+cj57u2Icq4W17ifz9y7ofhI7juO31JgPK5e6lvie4d9XnFHIckcPGDp0KG7fvo2ZM2ciIyMDHTp0wLZt24yJvmlpaWB5GdJhYWH4559/MGXKFLRr1w5169bF5MmTMW3aNLvPCQCfffYZWJbFkCFDUFRUhJiYGHz99ddluXdCCCFlpfIBXv0PkCmBoJbAN92AzOIVsoscH6ChlLNQypXG92E1ayDp6j3j+9K21NjLNecs3fWckSh8K68QbbRnEaf4DQn61sbtuQ/UgEz8HJL1lUh8upb1AM8tTUC/tiEY062hzTq7ksNBDQBMmjQJkyZNEt23e/dui21RUVE255Oxdk4A8PDwwJIlS7BkyRKH6koIIcTFQk3zjqFxT15Qk2f4l+OAVMdWml71UhecuJaNpkHe2HTcNMqG31JTtpwa6eHXOtE9QtLBRNnmqWEkXjteD4Ovdl7CFw/iABnQW3ZUtIzcztW2GSvz9CSmZiExNcvtQQ2t/UQIIcR5Hp1qeq3ON/x7N8Xh03RvVhuvP6RElHe6YLswUdh9LTWOBFSO5dQ4tnyBrQkBCzXiIZq1c0vt+WLHRYk9FQcFNYQQQpynhj/QungJm6I84PIe4KsIYZkL/9i32NPn7eC/qid2jTet4M24eJ4axwIlsVYZsXNau54Q68QEXgDQii0bXkpVbvQTIYQQYpOqeGmDrMvAj09Z7l/zHHBus92nCyi8bnwdXsvT+Nqx8Ma8tP2jl0TLMZwDrTqlnaem7HQSQU3pAhQKagghhFQ3vsULFid+J13GbMZha/hdTv/r2QTPRNQDALwY1aA0tbPK3tFHzpqnxt66lJZ0UOO4ijuXswkFNYQQQpwrrLNTT8efq8ZLJccnz7ZH6oIn8NrjjQXl3uzdTPIcJY92WyPCpYZ0d2KTLbbZO3uw9eDE2sgjJ3Q/6ZzXUkPdT4QQQqofn1DbZU6stft0wsUXpb3Wq6nkPnnxmKbnOoWhfZi/5Hmkun8GyQ5YLWtdaeepKbttZ8TXRyxdSw0FNYQQQqobz1q2y2gfAL+NAebUBA6JdFPxAhn+o1SQJyySbPzBoDail5sk/wMA8ES7UMx8spVkteyffE88p0Z8m/XzSL13ZRBhbXi25DEuqIezUVBDCCHEuWoE2FfuzAaA0wN/v2W5jxewqBSmtQNreir5hSwOG/mw9TybR5vWttoF9YjEStvmXLX0gXCeGhcGNS7qftI7cbRVaVBQQwghxLlkZvO6PrHI9jH5t4CzfwC6kvWiTA9HOcsi8Z1eSIh7HB68AEdqWHj7MH/r1WMZyQf018ovbNcVhuDD3pYLxxKOndv95Ez21Eejt28iP1ehoIYQQojztSweyu1VG2jax3b573sBv44CDhbPGs8JH45Bvh4I9bO+0neJhrxh32LM15OSYqtlwt6uJkfmqZE5OPleebKnPhqJxOTyQkENIYQQ53vuR+DdW8BblwD/MNvlc9IM/54tnr+Gs+cvfomlDmwMcZLLyt4GIpVTI1XWXl5MEWbKfyw+znVcNU+N1BDy8kJBDSGEEOdjGECucvw4rnhaf/OgxtgtxS8r/gCViW4FnmpfBwAQXsurzAGDVFDg6JBusX0vybfZPK6srNfJse18lFNDCCGElMjLAPR6YVCTshOYFwoc/cmssPgDVM6Kb//0OcPCmx4KGbo2sT1C69GmgZL7HFr7yUphd+XNuGpIt86e5S9ciIIaQgghrtf2WfvK5aUDv74gDGr+Wwjo1MDmSXadomTGYXMKmemRF1bTdn5O0yAfq/vtbUl5T24ejNl7Dne11JR+wj5qqSGEEFL1dR5nf9nzf9nOqbmy1zBaSkREmJ/4MfxWhDI+e6XnqbEUIztSqmu0Yy+X6jh72BPU3OO8zbbb5swFNEtDbrsIIYQQUkbBrQGZ0tDiYg9bQc2qJ60dLLGZs94XZO95ivc5p+tI+hrLlJ865QpiXNb9RC01hBBCqjyVt2Ek1MMT7StfltwMyYCIk3gtFMWewXz590BhrmQZe5ZZsIf7cmpsJwpbm+1Yit7NOTXUUkMIIaR8ePgBeo19ZcsU1Ei11OhhHBtl5fy/KD80vDhh/TIVbR4ZZ7MIauyIwNzd/UQtNYQQQsqPp/SIIgFr3U+SQQtn/Vi75r6xjyPz1Ng6j3s4nihsTyISJQoTQgipPh6eYLmt91zLbdZybySDlpIHqsSD1d58HjtE1Jda6dvR7if3BAH2dHtZW0FcCg3pJoQQUn14+Fpuq1HTctvGV6XPYaslRmr//HrA9SRgzTAgw76FK6VM7NHY4YBEBTU6MhfBCJZCEBfDHi5D7Wwr3ZBuS8/Kdgvea2mZBEIIIdVKF17A4lUbUIis1ZS6V/p4vU58uzGosfJg/eFx4MLfQGbZghopJQ9+HWcZAixRfI6NqlmYIPvT5nm+VX7m5JoJsXYFZLYThRcqvhO8p0RhQggh1UvfBYBPMHD1ANDnQ0Dp5djxtkY3OTF3xkolYK2ryTDgW7g/WnYMADBa/g++1g0E4M7uJ3tGP9l/TAka0k0IIaR6YVng0TeBkb8DQS0MC14O/t7+4zkbLTXlgXPOPDUVM6fG/u4nc+4OaqilhhBCiPu1ew64kQQcWmq93MKmQPth4vv0OiB+LnBqvfPrZ0FqRmHOuNeec4SzGU6ul/OUZp4adwc11FJDCCGkYuj3EdDvY8Nrn1DxMgW3gANfiO/Ta4C9nwLZV11TPzNlbWWZKv8Vq5XznVQb5ynL5Hs0+okQQggp4Rdm+Fdb6Pix2iLn1sWas5tFN9cPEF8ok+WNeCp57E+Si69dVR74I7CciVpqCCGEkBJypeHf0gQopQmESuvUr6IdTCXbzB/t+zrEu7hCjrHWOVbSIlMZE4Upp4YQQkjFISsJakoRoFxNcG5dbBB9yEtEC3XOr3BtZRzEWmmp6SU7hnAmU6T7yTYa0k0IIYSUKAlqSjOSadN459bFBrGHPOtQorD7yKwENc/I/jMukcUn1VJTF7dxA7UBALpyHIAmhrqfCCGEVBxetd1dA7t1YpMttjXW25+kfFDf0pnVcYi1lhopUkHNd8pFxtc6vXujGgpqCCGEVBw1w91dA7stVS622PbOg09sHlfSitOurp+zq2Q3eamCGnGtWVMgRy01hBBCSAlWpN/DXq0GOq8epaSEpviVdPeTj0qOGf1bwlPhvkcwyzivpYaPhnQTQgghzqD0cXcNhI/9J8XXb/JSyTHusUYunwH5or6u5D5rOTVSpIKafM7D+Jq6nwghhBC+ji+U7jhdOc5TYwMHAK2ftlHItQGAtTaT2l6OjxOSanviJ0VT9xMhhBDC138h8NyPwGtHgYgxQNjD9h2XIbLydlikc+tmgxJa0xvGxiNWag0rJ7E2/qo0LTVSYRL/XNtOp5fivM5DQQ0hhJCKRVHDkB9TqzEwYDEw6Gv7jrt93nLbC5ucWTPH2AxqXNusYTUHRq+V3ufg+fgjqXacu+XweZ2JghpCCCEVm9K7dMf51weUns6ti504MNJBTVE+cH4LoHng0joEe1oLahwPqJ70viC6vTTDw12lVEHNkiVLEB4eDg8PD0RGRiIxMVGy7MqVK8EwjODLw8NDUMZ8f8nXwoULjWXCw8Mt9i9YsKA01SeEEFKZePha399prPh2pngk1ZQzzq2PvRiJkVzqPGDt8+ItS05UQ30Xkpk1pWipGa/5UXQ7W8aFPZ3J4aBm3bp1iI2NxaxZs3D06FG0b98eMTExuHVLusnJ19cX6enpxq+rV4WTE/H3paenY/ny5WAYBkOGDBGUmzt3rqDca6+95mj1CSGEVDYK8UUijWI+FN/OFGeV+NUD2g11bp1ssNpSU07kejV8INEa5MR8Hnkphoe7isPpz4sWLcK4ceMwZswYAMDSpUuxZcsWLF++HNOnTxc9hmEYhISESJ7TfN8ff/yBnj17olGjRoLtPj4+Vs9DCCGkilP6AB1HAIeWGt7Xbikd9GRdNr32DnJ93cy5OagBAJVx3hwzetcmKbuLQ99xtVqNpKQkREdHm07AsoiOjkZCgvRCYvn5+WjQoAHCwsIwcOBAnDkj3RSYmZmJLVu2YOxYy+bEBQsWoFatWujYsSMWLlwIrVa6+ayoqAi5ubmCL0IIIZWUb/GcK2GdgX4fAW9eALpPA0aut+/40A4uq5okmfuXV2zKXhff4eKRV+7i0Hf8zp070Ol0CA4OFmwPDg7G+fPifYPNmzfH8uXL0a5dO+Tk5OCTTz5B165dcebMGdSrV8+i/KpVq+Dj44PBgwcLtr/++ut46KGHEBAQgAMHDiAuLg7p6elYtGiRxTkAYP78+ZgzZ44jt0cIIaSiGvM3kLQSiHzV8N4nGOj5jv3Hq8p3Yj5jlonSG1Dnl+u1+X5SzHfbtd3B5W1jUVFRGDVqFDp06IDu3btjw4YNqF27Nr799lvR8suXL8eIESMskoljY2PRo0cPtGvXDuPHj8enn36KL7/8EkVF4pMtxcXFIScnx/h17do1p98bIYSQclKzARA9C/ApZQqCXCW+vdNLpa+TPcqy7IMTlFe+y3T5LwCAYF+J73M5cSioCQwMhEwmQ2ZmpmB7Zmam3bkuCoUCHTt2xKVLlyz27d27F8nJyXj55ZdtnicyMhJarRapqami+1UqFXx9fQVfhBBCqim5h/h23zouuZxxll2pEVBVzHj5n4hoUBMrx3Rxaz0cCmqUSiUiIiIQHx9v3KbX6xEfH4+oqCi7zqHT6XDq1CmEhoZa7Fu2bBkiIiLQvn17m+c5fvw4WJZFUJAbkr8IIYRULKzC+n6plhpXBx2s+/NqysvvQ0PRMtS9DQgOdz/Fxsbi+++/x6pVq3Du3DlMmDABBQUFxtFQo0aNQlxcnLH83Llz8e+//+Ly5cs4evQoRo4ciatXr1q0xuTm5uK3334TbaVJSEjA4sWLceLECVy+fBmrV6/GlClTMHLkSNSsWdPRWyCEEFLVPDzB+n6pkUi2houXVTUKarDZ/dOsOPzdHjp0KG7fvo2ZM2ciIyMDHTp0wLZt24zJw2lpaWBZ0w/PvXv3MG7cOGRkZKBmzZqIiIjAgQMH0KpVK8F5165dC47jMHz4cItrqlQqrF27FrNnz0ZRUREaNmyIKVOmIDY21tHqE0IIqYoef8+wztO6EeL7dRKjZWVKQOULFDl3hKxcVvwcrE5BTeped9cADMdxFWcqQBfKzc2Fn58fcnJyKL+GEEKqqi1TgcPfm97PzjH8W3AHWNjYsvyTnwFNooHFbZ1aDU7pA+ad68Dn7YF7qU49d4VW8v12Ikee3+6fGYgQQghxlv4LAe/iaUdi5pm2ewUCvWZZlmdYwxpRs3OAEInApuNIGxe1XA+bKZnNuAJMwFedVKN2MUIIIVUewwBvJgM51wC/MOG+R2MN3U3/zuAfYHqp8BI/Z2669WvWqAk8yJKqkK0au1Q+5wFvptCtdShPFEISQgipWhjG0PrCiAQU3sGWZUtwEnO6yGyMrHJ1snEZ/Kvv5O4qlCtqqTGj0+mg0UislUFsUigUkMmqx7wMhJBKyDxw4XcPSSX12kr2Fe1icm8LTYnBsn1lP0nbZ4FTv5X9POWAgppiHMchIyMD2dnZ7q5Kpefv74+QkBBTnzIhhFQUnrXMNjihpYZhgJrh4gnBVeH3YPN+FNRUNiUBTVBQEDw9PemBXAocx+H+/fu4desWAIhOsEgIIW4V1FL4XtD9JLHIo61kX0YGhHcTBjVV6RFSiWZFpqAGhi6nkoCmVi3zKJ44okYNQ9/yrVu3EBQURF1RhJCKxa8u8OhUYO8nhvf2jE7S21jRWl3AW8HSXBWIbirRCK7KU1MXKsmh8fT0dHNNqoaS7yPlJhFCKqTm/UyvNQ9Mr5USo5/0EhP3lZDqtqoqHFmU88Q619XDDhTU8FCXk3PQ95EQUqHx55ytwVtqx8NPvLxeCwxfB9QIAJ7/DZCbjXa6f0fkoOLfg5VpRmGpujrSUnPqV+fUpZQoqCGEEFK9PLhnet3iSdPr6Dni5fVaoHlf4O3LQLM+QN2HRApJ9D/JlaWuZrlrP0x8uyM5NW7uqqKghhiFh4dj8eLF7q4GIYS4Fr91RsZrnQhoCLxxyrJ8SfdTSSv0k4sty5g/zEvKyj1KXc3yJ9HKzjoQKlBQQ8qiR48eeOONN5xyrsOHD+OVV15xyrkIIaTCqtcJ6LsAGPm75T7/+kD754XbzBOFazezDGwadhe/lszOlppGPe0r50pSqQOOBCoU1BBX4jgOWq2NJLditWvXpmRpQkjVxzDAwxMMC1mKeXwG4OFveF2jJtDvY8sy5utBtX1G/FxylfB9g0fEyzmSjFtCalkHZ6PuJ1IeRo8ejT179uDzzz8HwzBgGAYrV64EwzD4+++/ERERAZVKhX379iElJQUDBw5EcHAwvL290blzZ+zYsUNwPvPuJ4Zh8MMPP+Dpp5+Gp6cnmjZtis2bN5fzXRJCSDnzq2fIn5mdA7x1GQhuZVnGfEI+hgFCO/A3GP7xDhGWq9tR/JqMDHjqK8PrpjHW69fiSWDg18CoTdJlPPzg+HByaqmpsjiOw3211i1fHCc54YHA559/jqioKIwbNw7p6elIT09HWJhhAbfp06djwYIFOHfuHNq1a4f8/Hz0798f8fHxOHbsGPr27YsBAwYgLS3N6jXmzJmD5557DidPnkT//v0xYsQIZGVJLdxGCCFVREnLSVnzSaJn23+9h14ApqcBz66QLhfUGhi2Gug4wnoLyrhdjrf+SHU/OXKe/EzHrulklWisWfl6oNGh1cx/3HLts3Nj4Km0/dH4+flBqVTC09MTISGGvwbOnz8PAJg7dy569+5tLBsQEID27dsb37///vvYuHEjNm/ejEmTJkleY/To0Rg+fDgAYN68efjiiy+QmJiIvn37lureCCGkyhILarxrC9dOkvqjtSRwMB9W3iQaCH8U2DHL8P75tbxjeNcLexi4dtD03reuYYi2rTl2hDcgsdmBoObaIQeu53zUUlNFdeokXJk1Pz8fU6dORcuWLeHv7w9vb2+cO3fOZktNu3btjK+9vLzg6+trXAaBEEIID7+lw9H5uqQCB0UNQ2JzCZbX7cU/hj8B4Pj9gMLDecsbVKIZhamlRkINhQxn59ro13ThtcvKy0uYQDZ16lRs374dn3zyCZo0aYIaNWrgmWeegVqttnoehULYb8wwDPT6Kj57JiGElIbUw5/f+mKrpcacTgMU8Cb38w6yfUxwa+v7pVpwJLufKKip9BiGsasLyN2USiV0OhvrkgDYv38/Ro8ejaeffhqAoeUmNTXVxbUjhJBqhB/U8FtOuk8HMk4BjR8HCnMljpUKatRAePGIqcBmwkBF6piS4EQqqKnTEbh+2HJ75hlg2C/A2uFm5xMJajqMBI7/LH5+N6r4T21iVXh4OA4dOoTU1FR4e3tLtqI0bdoUGzZswIABA8AwDN577z1qcSGEEGfiP/z5sxZ71wbG/mt4ffRH8WP55fl0GsArEHj7CqD0Fu4TBC0iLUCSQY9Ey8u1Q0CL/pbbVb6W255cVCGDmsrTpkRETZ06FTKZDK1atULt2rUlc2QWLVqEmjVromvXrhgwYABiYmLw0ENiU30TQgixy5OfGf7tOcPwb+3mto/pMMIwIqr1YOH2xhKT7+mKFwb2DLBccoEfnIit2yTVUuNojgx/BmZr16sAKmatiN2aNWuGhIQEwbbRo0dblAsPD8fOnTsF2yZOnCh4b94dJTa0PDs7u1T1JISQKqfTS8BDL5qCh5ZPAUeWWz+GlQGPTAH0eqDb64B3MJB2ULgGFWAYvZR7A6gbIX0ufnCi8hG5VmkXqGQgaPkRW728giYPV8xaEUIIIZUBvzVE4cCM7CxryG3xrQO0GWzZCjP8F6Dnu8BjU6XPwV++QSyAkawPLyF44mHAzzC/mXEWZYsZlEUSiB0d3VVOKKghhBBCnEHpxGVmQtsD3d8ydDtJ0WtMr2uIlFN5W24DhAFJ7WbAC5uAVoOAF/80bGv3nOUxYmtYPbFIum5uQkENIYQQ4gyOtNQ4Q+0Whi6vyPFAzzjD6Krh60z7zROLS9RqLHwf2AR4bhUQWjwvmXkuDsMArx21PI95l1kFQDk1hBBCiDPwF68sSR52JYYBhv5kev/CRuF+sTwbAPAKAl7ZI73foiuLAfzDRK5f8dpFKKghhBBCnIE/SuiRWPfVo4RnLeF7VmHosmoSDdTpIH2cvTMRV8C8GgpqCCGEEGdQegGTjhhW8JZVgMereTfTlNNAXrohQdka85YaqeCF3zJVQVS8tiNCCCGksgpsCtQMd3ctDMxzajwDbQc0gP3LIqh8gIFfO14vF6KghhBCCKmKZMK1+xzqLhKsFm52XNfXTK87jgDkHg5XzVUoqCGEEEKqItYsqBGbb0aKdzDvMBvHvX7M/vO6GAU11Vx4eDgWL15sfM8wDDZt2iRZPjU1FQzD4Pjx4y6vGyGEkDLgt9So/BxbbVtqOLiY8h7KbkUFyGQiFUl6ejpq1hRZ54MQQkjlwk/4rVnfsWP5SyOUtNR0mwycWAtEvSYsW8Ofd03z1qHyRUENEQgJCXF3FQghhDiDoKVGZKVta26dtdzWey4QPcd6d5TYfDbliLqfKrHvvvsOderUgV6vF2wfOHAgXnrpJaSkpGDgwIEIDg6Gt7c3OnfujB07dlg9p3n3U2JiIjp27AgPDw906tQJx45VnL5TQgghVvBbTRwdfn3/rvh2qYBm7A6gSW/hjMZuQEGNFI4D1AXu+RJZHVvMs88+i7t372LXrl3GbVlZWdi2bRtGjBiB/Px89O/fH/Hx8Th27Bj69u2LAQMGIC0tza7z5+fn48knn0SrVq2QlJSE2bNnY+pUK4urEUIIqTj4c+XIHAxqHnvLsfJhnYGR6w1rSbkRdT9J0dwH5tVxz7XfuSm+1LuZmjVrol+/flizZg169eoFAFi/fj0CAwPRs2dPsCyL9u3bG8u///772LhxIzZv3oxJkybZPP+aNWug1+uxbNkyeHh4oHXr1rh+/TomTJhQ+nsjhBBSPvgtNZoCx45t0NW5dSkn1FJTyY0YMQK///47ioqKAACrV6/GsGHDwLIs8vPzMXXqVLRs2RL+/v7w9vbGuXPn7G6pOXfuHNq1awcPD9McBFFRUS65D0IIIU5WlGd6ff+eY8cK5qmpPErVUrNkyRIsXLgQGRkZaN++Pb788kt06dJFtOzKlSsxZswYwTaVSoXCwkLj+9GjR2PVqlWCMjExMdi2bZvxfVZWFl577TX8+eefYFkWQ4YMweeffw5vbweGnTlC4WloMXEHB4bHDRgwABzHYcuWLejcuTP27t2Lzz77DAAwdepUbN++HZ988gmaNGmCGjVq4JlnnoFarXZVzQkhhFQU/AUnOb10OTGhHYFGPYTz1VQCDgc169atQ2xsLJYuXYrIyEgsXrwYMTExSE5ORlBQkOgxvr6+SE5ONr5nRBKN+vbtixUrVhjfq1TC/r8RI0YgPT0d27dvh0ajwZgxY/DKK69gzZo1jt6CfRjGri4gd/Pw8MDgwYOxevVqXLp0Cc2bN8dDDz0EANi/fz9Gjx6Np59+GoAhRyY1NdXuc7ds2RI//fQTCgsLja01Bw8edPo9EEIIcYGmfUyvOZ1jx7IsMOoP59anHDjc/bRo0SKMGzcOY8aMQatWrbB06VJ4enpi+fLlkscwDIOQkBDjV3CwZeSnUqkEZfhzpZw7dw7btm3DDz/8gMjISDzyyCP48ssvsXbtWty86abWlApkxIgR2LJlC5YvX44RI0YYtzdt2hQbNmzA8ePHceLECTz//PMWI6Wsef7558EwDMaNG4ezZ89i69at+OSTT1xxC4QQQpxNJgeC2xheN+/v3rqUE4eCGrVajaSkJERHR5tOwLKIjo5GQkKC5HH5+flo0KABwsLCMHDgQJw5c8aizO7duxEUFITmzZtjwoQJuHvXNJwsISEB/v7+6NSpk3FbdHQ0WJbFoUOHRK9ZVFSE3NxcwVdV9fjjjyMgIADJycl4/vnnjdsXLVqEmjVromvXrhgwYABiYmKMrTj28Pb2xp9//olTp06hY8eOmDFjBj766CNX3AIhhBBXGPk70PcjIMr24JCqwKHupzt37kCn01m0tAQHB+P8+fOixzRv3hzLly9Hu3btkJOTg08++QRdu3bFmTNnUK9ePQCGrqfBgwejYcOGSElJwTvvvIN+/fohISEBMpkMGRkZFl1bcrkcAQEByMjIEL3u/PnzMWfOHEdur9JiWVa0xSo8PBw7d+4UbJs4caLgvXl3FGc2nPzhhx+2WBLBvAwhhJAKyicEeHi8u2tRblw+pDsqKkowYqZr165o2bIlvv32W7z//vsAgGHDhhn3t23bFu3atUPjxo2xe/du41BlR8XFxSE2Ntb4Pjc3F2Fh7p3pkBBCCCGu41D3U2BgIGQyGTIzMwXbMzMz7Z5eX6FQoGPHjrh06ZJkmUaNGiEwMNBYJiQkBLdu3RKU0Wq1yMrKkryuSqWCr6+v4IsQQgghVZdDQY1SqURERATi4+ON2/R6PeLj4+2ev0Sn0+HUqVMIDQ2VLHP9+nXcvXvXWCYqKgrZ2dlISkoyltm5cyf0ej0iIyMduQVCCCGEVFEOj36KjY3F999/j1WrVuHcuXOYMGECCgoKjHPRjBo1CnFxccbyc+fOxb///ovLly/j6NGjGDlyJK5evYqXX34ZgCGJ+K233sLBgweRmpqK+Ph4DBw4EE2aNEFMTAwAw9Divn37Yty4cUhMTMT+/fsxadIkDBs2DHXquGnWX0IIIYRUKA7n1AwdOhS3b9/GzJkzkZGRgQ4dOmDbtm3G5OG0tDSwrClWunfvHsaNG4eMjAzUrFkTEREROHDgAFq1agUAkMlkOHnyJFatWoXs7GzUqVMHffr0wfvvvy+Yq2b16tWYNGkSevXqZZx874svvijr/RNCCCGkimC4ajKUJTc3F35+fsjJybHIryksLMSVK1fQoEEDeHraP5svEXf//n1cvXoVDRs2FCyxQAghhDjK2vPbHC1oCUOuUMmw6Nq1a0OpVIrOekys4zgOarUat2/fBsuyUCqV7q4SIYSQaoSCGhjmeWnYsCHS09NphmIn8PT0RP369QXdkIQQQoirUVBTTKlUon79+tBqtdDpHFwjgxjJZDLI5XJq6SKEEFLuKKjhYRgGCoUCCoXC3VUhhBBCiIOof4AQQgghVQIFNYQQQgipEiioIYQQQkiVUG1yakqm48nNzXVzTQghhBBir5Lntj3T6lWboCYvLw8AaKVuQgghpBLKy8uDn5+f1TLVZkZhvV6PmzdvwsfHx+nDjXNzcxEWFoZr165VydXAq/r9AVX/Hun+Kr+qfo9V/f6Aqn+Prro/juOQl5eHOnXq2Jz/rNq01LAsi3r16rn0Gr6+vlXyB7VEVb8/oOrfI91f5VfV77Gq3x9Q9e/RFfdnq4WmBCUKE0IIIaRKoKCGEEIIIVUCBTVOoFKpMGvWLKhUKndXxSWq+v0BVf8e6f4qv6p+j1X9/oCqf48V4f6qTaIwIYQQQqo2aqkhhBBCSJVAQQ0hhBBCqgQKagghhBBSJVBQQwghhJAqgYKaMlqyZAnCw8Ph4eGByMhIJCYmurtKdpk/fz46d+4MHx8fBAUFYdCgQUhOThaU6dGjBxiGEXyNHz9eUCYtLQ1PPPEEPD09ERQUhLfeegtarbY8b0XU7NmzLereokUL4/7CwkJMnDgRtWrVgre3N4YMGYLMzEzBOSrqvZUIDw+3uEeGYTBx4kQAle/z+++//zBgwADUqVMHDMNg06ZNgv0cx2HmzJkIDQ1FjRo1EB0djYsXLwrKZGVlYcSIEfD19YW/vz/Gjh2L/Px8QZmTJ0/i0UcfhYeHB8LCwvDxxx+7+taMrN2jRqPBtGnT0LZtW3h5eaFOnToYNWoUbt68KTiH2Oe+YMECQRl33aOtz3D06NEWde/bt6+gTGX+DAGI/p9kGAYLFy40lqmon6E9zwVn/e7cvXs3HnroIahUKjRp0gQrV650zk1wpNTWrl3LKZVKbvny5dyZM2e4cePGcf7+/lxmZqa7q2ZTTEwMt2LFCu706dPc8ePHuf79+3P169fn8vPzjWW6d+/OjRs3jktPTzd+5eTkGPdrtVquTZs2XHR0NHfs2DFu69atXGBgIBcXF+eOWxKYNWsW17p1a0Hdb9++bdw/fvx4LiwsjIuPj+eOHDnCPfzww1zXrl2N+yvyvZW4deuW4P62b9/OAeB27drFcVzl+/y2bt3KzZgxg9uwYQMHgNu4caNg/4IFCzg/Pz9u06ZN3IkTJ7innnqKa9iwIffgwQNjmb59+3Lt27fnDh48yO3du5dr0qQJN3z4cOP+nJwcLjg4mBsxYgR3+vRp7pdffuFq1KjBffvtt26/x+zsbC46Oppbt24dd/78eS4hIYHr0qULFxERIThHgwYNuLlz5wo+V/7/W3feo63P8MUXX+T69u0rqHtWVpagTGX+DDmOE9xbeno6t3z5co5hGC4lJcVYpqJ+hvY8F5zxu/Py5cucp6cnFxsby509e5b78ssvOZlMxm3btq3M90BBTRl06dKFmzhxovG9Tqfj6tSpw82fP9+NtSqdW7ducQC4PXv2GLd1796dmzx5suQxW7du5ViW5TIyMozbvvnmG87X15crKipyZXVtmjVrFte+fXvRfdnZ2ZxCoeB+++0347Zz585xALiEhASO4yr2vUmZPHky17hxY06v13McV7k/P/OHhV6v50JCQriFCxcat2VnZ3MqlYr75ZdfOI7juLNnz3IAuMOHDxvL/P333xzDMNyNGzc4juO4r7/+mqtZs6bg/qZNm8Y1b97cxXdkSeyBaC4xMZEDwF29etW4rUGDBtxnn30meUxFuUepoGbgwIGSx1TFz3DgwIHc448/LthWWT5D8+eCs353vv3221zr1q0F1xo6dCgXExNT5jpT91MpqdVqJCUlITo62riNZVlER0cjISHBjTUrnZycHABAQECAYPvq1asRGBiINm3aIC4uDvfv3zfuS0hIQNu2bREcHGzcFhMTg9zcXJw5c6Z8Km7FxYsXUadOHTRq1AgjRoxAWloaACApKQkajUbw2bVo0QL169c3fnYV/d7MqdVq/Pzzz3jppZcEC7ZW5s+P78qVK8jIyBB8Zn5+foiMjBR8Zv7+/ujUqZOxTHR0NFiWxaFDh4xlHnvsMSiVSmOZmJgYJCcn4969e+V0N/bLyckBwzDw9/cXbF+wYAFq1aqFjh07YuHChYKm/Yp+j7t370ZQUBCaN2+OCRMm4O7du8Z9Ve0zzMzMxJYtWzB27FiLfZXhMzR/Ljjrd2dCQoLgHCVlnPHsrDYLWjrbnTt3oNPpBB8cAAQHB+P8+fNuqlXp6PV6vPHGG+jWrRvatGlj3P7888+jQYMGqFOnDk6ePIlp06YhOTkZGzZsAABkZGSI3n/JPneKjIzEypUr0bx5c6Snp2POnDl49NFHcfr0aWRkZECpVFo8KIKDg431rsj3JmbTpk3Izs7G6NGjjdsq8+dnrqQ+YvXlf2ZBQUGC/XK5HAEBAYIyDRs2tDhHyb6aNWu6pP6lUVhYiGnTpmH48OGCxQFff/11PPTQQwgICMCBAwcQFxeH9PR0LFq0CEDFvse+ffti8ODBaNiwIVJSUvDOO++gX79+SEhIgEwmq3Kf4apVq+Dj44PBgwcLtleGz1DsueCs351SZXJzc/HgwQPUqFGj1PWmoIZg4sSJOH36NPbt2yfY/sorrxhft23bFqGhoejVqxdSUlLQuHHj8q6mQ/r162d83a5dO0RGRqJBgwb49ddfy/QfpqJatmwZ+vXrhzp16hi3VebPr7rTaDR47rnnwHEcvvnmG8G+2NhY4+t27dpBqVTi1Vdfxfz58yv89PvDhg0zvm7bti3atWuHxo0bY/fu3ejVq5cba+Yay5cvx4gRI+Dh4SHYXhk+Q6nnQkVH3U+lFBgYCJlMZpH1nZmZiZCQEDfVynGTJk3CX3/9hV27dqFevXpWy0ZGRgIALl26BAAICQkRvf+SfRWJv78/mjVrhkuXLiEkJARqtRrZ2dmCMvzPrjLd29WrV7Fjxw68/PLLVstV5s+vpD7W/r+FhITg1q1bgv1arRZZWVmV6nMtCWiuXr2K7du3C1ppxERGRkKr1SI1NRVA5bjHEo0aNUJgYKDgZ7IqfIYAsHfvXiQnJ9v8fwlUvM9Q6rngrN+dUmV8fX3L/EcnBTWlpFQqERERgfj4eOM2vV6P+Ph4REVFubFm9uE4DpMmTcLGjRuxc+dOi6ZOMcePHwcAhIaGAgCioqJw6tQpwS+hkl/CrVq1ckm9Sys/Px8pKSkIDQ1FREQEFAqF4LNLTk5GWlqa8bOrTPe2YsUKBAUF4YknnrBarjJ/fg0bNkRISIjgM8vNzcWhQ4cEn1l2djaSkpKMZXbu3Am9Xm8M6KKiovDff/9Bo9EYy2zfvh3NmzevEN0WJQHNxYsXsWPHDtSqVcvmMcePHwfLssZum4p+j3zXr1/H3bt3BT+Tlf0zLLFs2TJERESgffv2NstWlM/Q1nPBWb87o6KiBOcoKeOUZ2eZU42rsbVr13IqlYpbuXIld/bsWe6VV17h/P39BVnfFdWECRM4Pz8/bvfu3YJhhffv3+c4juMuXbrEzZ07lzty5Ah35coV7o8//uAaNWrEPfbYY8ZzlAzd69OnD3f8+HFu27ZtXO3atSvEsOc333yT2717N3flyhVu//79XHR0NBcYGMjdunWL4zjDsMT69etzO3fu5I4cOcJFRUVxUVFRxuMr8r3x6XQ6rn79+ty0adME2yvj55eXl8cdO3aMO3bsGAeAW7RoEXfs2DHjyJ8FCxZw/v7+3B9//MGdPHmSGzhwoOiQ7o4dO3KHDh3i9u3bxzVt2lQwHDg7O5sLDg7mXnjhBe706dPc2rVrOU9Pz3IbDmztHtVqNffUU09x9erV444fPy74f1kyauTAgQPcZ599xh0/fpxLSUnhfv75Z6527drcqFGjKsQ9Wru/vLw8burUqVxCQgJ35coVbseOHdxDDz3ENW3alCssLDSeozJ/hiVycnI4T09P7ptvvrE4viJ/hraeCxznnN+dJUO633rrLe7cuXPckiVLaEh3RfHll19y9evX55RKJdelSxfu4MGD7q6SXQCIfq1YsYLj/t/O3bKoEgZQHHeD8zgiiqKITBDEYrNZxCIIRtNgEoPFKkar+BX8KKb5BAajICgWkyAIGgxnw76wg7t7w73cXR/+vzivHJ55OQMzI2m/36vRaCiTycgYo3K5rPF4HPrPiSTtdju12225rqtsNqvRaKTb7fYDicJ831ehUJDjOPI8T77va7PZvM+/Xq8aDodKp9OKx+PqdDo6HA6hbfzWbB8tFgtFIhGt1+vQ9EccvyAIPj0me72epJfPuieTifL5vIwxajabd7mPx6O63a4SiYSSyaT6/b7O53NomdVqpXq9LmOMPM/TbDb7XxG/zbjdbr88L9/+PbRcLlWr1ZRKpRSLxVSpVDSdTkOl4Cczfpfvcrmo1Wopl8spGo2qWCxqMBjcPQQ+8hi+mc/ncl1Xp9Ppbv3fPIZ/ui9I/+7aGQSBqtWqHMdRqVQK7eNvPL0GAQAAeGi8UwMAAKxAqQEAAFag1AAAACtQagAAgBUoNQAAwAqUGgAAYAVKDQAAsAKlBgAAWIFSAwAArECpAQAAVqDUAAAAK1BqAACAFZ4BhSvWv66OL5EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(train_loss_list, label=\"train\")\n",
    "sns.lineplot(valid_loss_list, label=\"valid\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_relu_stack.0.weight',\n",
       "              tensor([[-0.2830,  0.1957, -0.0081,  ..., -0.0258, -0.0954,  0.0659],\n",
       "                      [-0.1152,  0.2442, -0.0166,  ..., -0.0026, -0.2242, -0.1237],\n",
       "                      [-0.0109, -0.3634, -0.0698,  ..., -0.4647,  0.1918,  0.1510],\n",
       "                      ...,\n",
       "                      [-0.2202,  0.1945,  0.0955,  ..., -0.2615,  0.1702, -0.2131],\n",
       "                      [-0.2510, -0.0249,  0.1965,  ...,  0.4044, -0.0166,  0.0779],\n",
       "                      [-0.0851,  0.2594,  0.0551,  ...,  0.4425, -0.0125,  0.0204]])),\n",
       "             ('linear_relu_stack.0.bias',\n",
       "              tensor([ 0.1921, -0.1965,  0.1484, -0.2310,  0.0946,  0.2134, -0.0498,  0.0638,\n",
       "                      -0.1831, -0.1369,  0.2777, -0.1241, -0.1821, -0.1907, -0.0377, -0.2240,\n",
       "                       0.1121,  0.1531,  0.2074,  0.0972, -0.2738, -0.0802,  0.0410, -0.0779,\n",
       "                       0.0885,  0.0010,  0.3402,  0.0684, -0.1931,  0.0494,  0.0184, -0.2270,\n",
       "                      -0.2041,  0.2281, -0.0517,  0.1258,  0.1375,  0.2002, -0.1106, -0.0189,\n",
       "                      -0.1329,  0.2179,  0.1103,  0.0902, -0.0814,  0.0934, -0.0821, -0.0573,\n",
       "                      -0.1566,  0.0212,  0.2740,  0.1423,  0.0147,  0.0711,  0.1435,  0.0017,\n",
       "                      -0.2383,  0.1194,  0.1749,  0.1803, -0.2147, -0.2519,  0.1490,  0.2022,\n",
       "                      -0.1532,  0.1824, -0.2807,  0.1724, -0.0848, -0.0817, -0.0844, -0.2010,\n",
       "                       0.0328,  0.2398, -0.2235, -0.1264,  0.1335, -0.1246, -0.2528,  0.2906,\n",
       "                       0.1154,  0.0617,  0.0688,  0.2215, -0.0872, -0.3031,  0.1400,  0.1976,\n",
       "                       0.0953, -0.2834,  0.1320, -0.0347,  0.1527,  0.1849, -0.1513, -0.3055,\n",
       "                       0.0126,  0.2159, -0.1073, -0.0148, -0.3154, -0.2565, -0.1707, -0.2739,\n",
       "                       0.1850, -0.2853, -0.2592,  0.1576,  0.0610, -0.1080,  0.0831,  0.0956,\n",
       "                       0.2919, -0.1334,  0.2520,  0.2984,  0.2207, -0.1347, -0.2066,  0.1036,\n",
       "                       0.1392, -0.2865,  0.0880,  0.1917,  0.2850, -0.2122,  0.1752, -0.1894,\n",
       "                       0.2912, -0.1309, -0.0787, -0.0511, -0.0806, -0.0164,  0.0999, -0.1537,\n",
       "                       0.2307, -0.1587,  0.1493, -0.0141, -0.2164,  0.0403,  0.0284, -0.1060,\n",
       "                      -0.3014,  0.2279,  0.0015,  0.1998, -0.2895, -0.1991, -0.1394,  0.0771,\n",
       "                      -0.1494, -0.1847,  0.1635, -0.0006,  0.2939, -0.1495,  0.2880,  0.1159,\n",
       "                       0.0015, -0.3003,  0.1776, -0.1284, -0.2804, -0.2353, -0.0211,  0.0475,\n",
       "                       0.0915, -0.1657, -0.3023,  0.0834, -0.0970,  0.2427,  0.1017,  0.0765,\n",
       "                       0.1079,  0.2777, -0.2486,  0.0767,  0.2136, -0.1423,  0.1361,  0.0309,\n",
       "                      -0.2863,  0.1991,  0.3171,  0.1726, -0.0962,  0.1906, -0.1446,  0.2788,\n",
       "                      -0.2610, -0.1991, -0.2465, -0.3037,  0.2999,  0.2526,  0.1275,  0.1087,\n",
       "                       0.2087,  0.3364, -0.0023,  0.1685, -0.2332, -0.1680,  0.2776, -0.1614,\n",
       "                       0.1294, -0.2502, -0.1111, -0.1095, -0.1349,  0.1294, -0.1454, -0.2098,\n",
       "                       0.0014,  0.1749,  0.0017,  0.3449,  0.1840, -0.0067, -0.0971,  0.1986,\n",
       "                      -0.1020, -0.0115, -0.1672,  0.1112, -0.0337,  0.3208,  0.1913, -0.1986,\n",
       "                      -0.2504, -0.2990, -0.0828, -0.0341,  0.3161,  0.0107, -0.1584, -0.2479,\n",
       "                       0.2083,  0.0958, -0.0971,  0.2669,  0.0445,  0.1416, -0.2858, -0.0622,\n",
       "                      -0.0405, -0.0046, -0.2513, -0.3173,  0.2649, -0.0703, -0.0316, -0.1629,\n",
       "                      -0.3321, -0.2662, -0.2248, -0.2209, -0.1664,  0.0580, -0.2175, -0.0670,\n",
       "                      -0.0177, -0.1554,  0.1907,  0.2240, -0.0975,  0.0825,  0.0553, -0.0830,\n",
       "                       0.1253,  0.2129,  0.0374,  0.2794, -0.0733, -0.0216,  0.1874, -0.3038,\n",
       "                      -0.1320,  0.3207, -0.1567,  0.2802, -0.2121, -0.1729,  0.1351, -0.1029,\n",
       "                      -0.0784, -0.1841,  0.1124, -0.0209, -0.2415,  0.2909,  0.1218, -0.0219,\n",
       "                       0.0828,  0.2442,  0.0584,  0.0152, -0.2051,  0.2116, -0.1774, -0.0138,\n",
       "                       0.0114, -0.2175, -0.2325, -0.1488, -0.0245,  0.2352, -0.0521, -0.1939,\n",
       "                       0.1437, -0.0572,  0.1177,  0.2241,  0.2531, -0.0979, -0.1974, -0.0898,\n",
       "                      -0.1653,  0.2873,  0.0011, -0.0705,  0.2388,  0.1615, -0.1216, -0.0725,\n",
       "                       0.0574,  0.0366, -0.1409, -0.2074,  0.0288,  0.0129, -0.1074,  0.1937,\n",
       "                       0.2889,  0.1966,  0.2009,  0.0249, -0.2207, -0.2969, -0.2859, -0.1763,\n",
       "                       0.2854, -0.2327, -0.2894, -0.1574,  0.2402,  0.0254, -0.2473,  0.0122,\n",
       "                      -0.2342,  0.1075,  0.1414, -0.2088, -0.2456, -0.0702,  0.0811, -0.2430,\n",
       "                      -0.0278,  0.2219,  0.1434, -0.0937, -0.2892, -0.2957,  0.2769,  0.2163,\n",
       "                       0.2984,  0.1937, -0.0305,  0.2398,  0.2007, -0.0887,  0.2582,  0.1908,\n",
       "                       0.0857,  0.2009,  0.2689,  0.1412,  0.1753, -0.1680,  0.1304, -0.3090,\n",
       "                      -0.2959,  0.1681, -0.2474,  0.2883, -0.0594,  0.2528, -0.2558,  0.2068,\n",
       "                      -0.0337,  0.0585, -0.0741,  0.0198,  0.2675,  0.0507, -0.0134,  0.2947,\n",
       "                      -0.0037, -0.0753,  0.0635,  0.0353, -0.2558,  0.2585, -0.3132,  0.2930,\n",
       "                      -0.2762, -0.2512,  0.2676,  0.2112, -0.2251,  0.1160, -0.1595,  0.3021,\n",
       "                       0.0640,  0.0647,  0.3179,  0.1576, -0.1643,  0.1766, -0.2539, -0.2729,\n",
       "                      -0.0270, -0.2971, -0.2326,  0.2374,  0.0709, -0.0195, -0.1364, -0.1143,\n",
       "                       0.1084, -0.1782, -0.1434, -0.1406,  0.2988, -0.1824, -0.1467,  0.2081,\n",
       "                      -0.0131,  0.0067, -0.1017, -0.2795, -0.2078, -0.0352,  0.2465,  0.0931,\n",
       "                       0.1725, -0.2094, -0.0068,  0.0158, -0.1554,  0.1933, -0.2214,  0.2817,\n",
       "                      -0.2101,  0.1162,  0.1990,  0.2652, -0.1417,  0.1943,  0.0565, -0.2516,\n",
       "                       0.0018, -0.0402,  0.0283,  0.0914, -0.0565,  0.2138, -0.0566, -0.1852,\n",
       "                      -0.0658, -0.0329,  0.2243,  0.2530, -0.0056,  0.2197, -0.0658, -0.2168,\n",
       "                       0.2932, -0.2094, -0.0059, -0.0081,  0.2770,  0.2841,  0.0474,  0.2750,\n",
       "                      -0.2073,  0.3894, -0.2632, -0.0069,  0.1826,  0.1665,  0.2241, -0.1698,\n",
       "                       0.0891,  0.0016, -0.0038, -0.2567,  0.1870,  0.0747, -0.1997, -0.1824,\n",
       "                       0.1234, -0.2187, -0.1322, -0.2195,  0.0580, -0.0642,  0.1863, -0.1317])),\n",
       "             ('linear_relu_stack.1.weight',\n",
       "              tensor([1.0017, 1.0000, 1.0546, 0.9299, 1.0114, 0.9535, 0.9686, 0.9118, 1.0000,\n",
       "                      0.9949, 0.9842, 1.0004, 1.0097, 0.9482, 0.9960, 0.9296, 1.0163, 0.9999,\n",
       "                      0.9946, 0.9511, 0.9940, 1.0001, 0.9970, 0.9530, 0.9998, 0.9761, 1.0071,\n",
       "                      0.9640, 1.0000, 0.8582, 1.0821, 1.0100, 1.0111, 1.0130, 0.9998, 1.0071,\n",
       "                      1.0000, 1.0023, 1.0000, 1.0293, 1.0168, 0.9992, 1.0025, 0.9942, 1.0017,\n",
       "                      0.9983, 1.0030, 0.9795, 0.9316, 0.9921, 1.0119, 1.0120, 0.9537, 1.0000,\n",
       "                      0.9996, 1.0002, 0.9906, 0.9921, 0.9995, 0.9876, 0.9837, 0.9999, 0.9992,\n",
       "                      0.9989, 1.0150, 1.0017, 0.9611, 1.0025, 0.9715, 0.9986, 1.0054, 0.9890,\n",
       "                      0.9978, 1.0015, 1.0087, 1.0000, 1.1164, 1.1049, 0.9642, 1.0054, 1.0005,\n",
       "                      0.9774, 0.9932, 1.0097, 1.0184, 1.0030, 0.8854, 0.9996, 0.9999, 0.9767,\n",
       "                      0.9817, 1.1480, 0.9993, 1.0114, 1.0001, 1.0221, 1.0007, 1.0005, 0.9986,\n",
       "                      1.0051, 1.0249, 1.0014, 1.0231, 0.9949, 1.0162, 1.0013, 1.0345, 1.0284,\n",
       "                      1.0019, 1.0000, 0.9952, 1.0327, 1.0003, 1.0008, 0.9604, 0.9476, 0.9926,\n",
       "                      1.0024, 0.9501, 0.9799, 1.0180, 1.0025, 1.0064, 0.9900, 1.0011, 1.0094,\n",
       "                      1.0016, 1.0352, 0.9895, 0.9947, 0.9616, 0.9525, 0.9991, 0.9975, 0.9676,\n",
       "                      1.0000, 1.0291, 0.9999, 1.0000, 0.9932, 0.9673, 1.0012, 1.0017, 0.9690,\n",
       "                      0.9411, 0.9627, 0.9858, 1.0000, 1.0099, 1.0012, 1.0001, 1.0028, 1.0097,\n",
       "                      1.0000, 0.9998, 1.0000, 1.0008, 1.0007, 1.0000, 0.9969, 1.0284, 0.9832,\n",
       "                      1.0014, 1.0120, 1.0068, 1.0018, 1.0043, 0.9555, 1.0714, 0.9740, 0.9704,\n",
       "                      1.0010, 0.9939, 1.0242, 0.9441, 1.0343, 1.0289, 0.9886, 0.9982, 0.9857,\n",
       "                      1.0408, 1.0110, 1.0014, 0.9734, 0.9797, 1.0000, 1.0284, 0.9813, 0.9999,\n",
       "                      1.0000, 1.0413, 1.0000, 1.0090, 1.0308, 1.1450, 1.0591, 1.0393, 0.9803,\n",
       "                      0.9224, 1.0141, 1.0636, 1.0524, 1.0001, 0.9999, 1.0147, 1.0000, 0.9921,\n",
       "                      0.9999, 0.9991, 0.9405, 1.0000, 1.0075, 1.0623, 0.9561, 0.9997, 1.0077,\n",
       "                      0.9969, 1.0019, 1.0001, 1.1700, 1.0033, 0.9351, 1.0049, 1.0031, 1.0003,\n",
       "                      0.9509, 1.0000, 1.0049, 0.9694, 1.0389, 0.9452, 1.0008, 1.0000, 0.9982,\n",
       "                      1.0123, 1.0000, 1.1083, 0.9999, 1.0002, 0.9837, 1.0006, 0.9993, 1.1885,\n",
       "                      0.9935, 1.0301, 0.9130, 1.0002, 1.0129, 1.0056, 1.0000, 1.0003, 0.9919,\n",
       "                      0.9884, 0.9563, 0.9778, 0.9999, 1.0195, 0.9685, 1.0312, 1.0152, 0.9393,\n",
       "                      1.0020, 1.0085, 1.0208, 1.0000, 1.0000, 1.0197, 1.0012, 0.9993, 0.9989,\n",
       "                      1.0708, 1.0100, 1.0003, 0.9670, 0.9987, 0.9988, 1.0029, 1.0021, 0.9925,\n",
       "                      1.0298, 1.0139, 0.9970, 0.9291, 0.9783, 1.0078, 1.0000, 1.0000, 0.9685,\n",
       "                      0.9671, 1.0004, 1.0000, 0.9916, 0.9882, 1.0089, 1.0002, 1.0096, 1.0106,\n",
       "                      1.0675, 0.9655, 1.0084, 1.0131, 0.9452, 1.0095, 1.0000, 0.9800, 1.0000,\n",
       "                      0.9889, 1.0440, 0.9909, 1.0450, 1.0083, 0.9163, 0.9801, 0.9550, 0.9051,\n",
       "                      1.0002, 1.0000, 1.0300, 0.9780, 0.9648, 0.9991, 1.0173, 1.0000, 1.0001,\n",
       "                      1.0109, 1.0007, 1.0050, 1.0007, 1.0067, 0.9984, 0.9963, 1.0001, 1.0008,\n",
       "                      0.9465, 1.0005, 1.0000, 0.9962, 1.0010, 1.0000, 0.9991, 1.0004, 1.0518,\n",
       "                      0.9998, 1.0013, 1.0011, 1.0042, 1.0019, 1.0593, 1.0125, 1.0001, 0.9518,\n",
       "                      1.0115, 1.0047, 1.0075, 1.0180, 1.0034, 0.9997, 1.0003, 1.0000, 0.9967,\n",
       "                      0.9606, 1.0011, 1.0028, 0.9058, 1.0000, 0.9993, 1.0001, 0.9782, 1.0057,\n",
       "                      0.9868, 0.9260, 0.9314, 0.9448, 0.9848, 1.0605, 1.0019, 0.9946, 1.0118,\n",
       "                      0.9751, 0.9986, 0.9541, 0.9777, 0.9885, 0.9849, 1.0000, 1.0009, 0.9983,\n",
       "                      1.0009, 1.0014, 1.0003, 1.0006, 0.9841, 1.0115, 1.1373, 0.9527, 0.8836,\n",
       "                      1.0008, 0.9604, 0.9982, 0.9999, 1.0029, 0.9992, 0.9414, 0.9839, 1.0941,\n",
       "                      1.0083, 1.0276, 1.0045, 1.0003, 1.0056, 0.9566, 0.9802, 1.0000, 1.0000,\n",
       "                      0.9992, 0.9871, 0.9549, 1.0000, 1.0037, 1.0000, 1.0000, 0.9475, 1.0923,\n",
       "                      1.0000, 1.0065, 1.0014, 1.0227, 0.9928, 1.0182, 1.0000, 0.9988, 1.0113,\n",
       "                      1.0188, 0.9996, 1.0318, 1.0508, 1.0229, 0.9770, 1.0295, 0.9997, 1.0072,\n",
       "                      0.9993, 1.0000, 1.0003, 0.9666, 1.0131, 1.0153, 0.9750, 1.0002, 1.0079,\n",
       "                      0.9999, 1.0000, 0.9998, 1.0000, 0.9842, 0.9945, 0.9998, 0.9951, 0.9364,\n",
       "                      1.0000, 1.0005, 1.0073, 0.9993, 1.0000, 0.9978, 1.0069, 1.0024, 0.9169,\n",
       "                      1.0101, 1.0354, 0.9738, 1.0049, 1.0019, 0.9671, 1.0034, 1.0170, 0.9981,\n",
       "                      1.0000, 1.0000, 1.0732, 1.0001, 0.9782, 0.9999, 0.8792, 0.9994, 1.0000,\n",
       "                      0.9731, 1.0000, 1.0007, 1.0758, 1.0002, 1.1854, 1.0704, 1.1794, 0.9911,\n",
       "                      0.9915, 1.0007, 0.9938, 0.9998, 1.0188, 0.9286, 0.9935, 0.9111, 0.9860,\n",
       "                      0.9765, 1.0078, 0.9830, 1.0091, 1.0003, 1.0148, 0.9945, 1.0352])),\n",
       "             ('linear_relu_stack.1.bias',\n",
       "              tensor([-2.1480e-02,  0.0000e+00, -3.7125e-02, -4.4586e-02, -4.4201e-02,\n",
       "                      -3.6675e-02, -4.7035e-02, -4.9650e-02,  0.0000e+00, -3.1000e-03,\n",
       "                      -3.0544e-02,  2.9309e-04, -2.7657e-02, -4.9410e-02, -1.2436e-02,\n",
       "                      -4.3767e-02, -2.6158e-02, -1.6796e-03, -2.0557e-02, -4.4301e-02,\n",
       "                      -1.5884e-02,  3.0501e-04, -1.6416e-02, -4.3734e-02, -1.3745e-03,\n",
       "                      -3.1303e-02, -3.0030e-02, -3.2132e-02, -7.9892e-05, -5.9293e-02,\n",
       "                      -6.2067e-03, -2.1251e-02, -1.4853e-02, -2.2357e-02, -4.7363e-03,\n",
       "                      -3.3723e-02,  0.0000e+00, -2.0113e-02, -6.4166e-04, -1.9987e-02,\n",
       "                      -2.8703e-02, -2.0265e-02, -1.4812e-02, -1.0220e-02,  1.7259e-03,\n",
       "                      -3.2753e-03, -1.7049e-02, -3.7807e-02, -4.4091e-02, -2.0542e-02,\n",
       "                      -1.1575e-02, -3.3499e-02, -4.1535e-02,  0.0000e+00, -5.0044e-03,\n",
       "                      -7.7679e-03, -2.0753e-02, -1.6211e-02, -1.0567e-02, -3.3985e-02,\n",
       "                      -1.8568e-02, -6.6928e-03, -2.4109e-02, -1.1738e-02, -6.6650e-03,\n",
       "                      -1.6307e-02, -4.7417e-02, -1.0081e-02, -3.8192e-02, -2.8837e-02,\n",
       "                      -8.1196e-03, -2.0300e-02, -1.8537e-02, -3.1237e-03, -4.8986e-03,\n",
       "                       6.6513e-05, -1.2783e-02, -2.1170e-02, -5.0377e-02, -1.2727e-02,\n",
       "                       1.4375e-03, -1.3306e-02, -3.6555e-02, -2.4133e-02, -2.5909e-03,\n",
       "                      -4.2511e-03, -5.7072e-02, -2.9659e-03, -1.8373e-03, -3.3468e-02,\n",
       "                      -1.7131e-02, -4.4868e-02, -2.2317e-02, -2.0510e-02, -5.3875e-04,\n",
       "                      -3.1252e-02, -1.4330e-02,  2.1372e-03, -1.0082e-03, -1.2269e-02,\n",
       "                      -2.1515e-02, -4.5244e-02, -1.4058e-02, -4.7495e-02, -1.7116e-02,\n",
       "                      -9.8276e-03, -1.5318e-02, -1.8480e-02, -3.1828e-02,  0.0000e+00,\n",
       "                      -3.6546e-02, -3.4911e-02, -3.2302e-03, -2.6263e-02, -3.6667e-02,\n",
       "                      -4.3700e-02, -2.5011e-02, -1.1111e-02, -4.5355e-02, -3.2201e-02,\n",
       "                      -3.6951e-02, -1.4763e-02, -1.1961e-02, -4.0589e-02, -5.3836e-03,\n",
       "                      -1.6342e-02, -7.8690e-04, -2.1819e-02, -2.6978e-02, -2.0246e-02,\n",
       "                      -3.5725e-02, -4.0044e-02, -2.7643e-03, -6.7034e-03, -3.0667e-02,\n",
       "                      -7.5605e-06, -2.8236e-02, -8.6230e-04,  0.0000e+00, -4.7392e-02,\n",
       "                      -2.4638e-02, -3.0585e-03, -1.5506e-02, -2.4435e-02, -4.4164e-02,\n",
       "                      -3.5409e-02, -4.1629e-02,  0.0000e+00, -1.6282e-02, -1.2994e-03,\n",
       "                      -1.3856e-04, -5.7923e-03, -1.2918e-02,  0.0000e+00, -8.3983e-03,\n",
       "                      -6.8641e-04, -7.6267e-03, -4.3865e-03,  5.2564e-05, -9.6663e-03,\n",
       "                      -2.8921e-02, -3.5310e-02, -1.1884e-02, -4.7494e-02, -4.4220e-03,\n",
       "                      -3.5381e-03, -1.5847e-02, -3.3364e-02, -1.7225e-02, -2.5472e-02,\n",
       "                      -5.6155e-02, -2.6572e-03, -3.6575e-02, -2.6199e-02, -4.8736e-02,\n",
       "                      -3.0374e-02, -1.7918e-02, -3.5315e-02, -9.2510e-03, -1.9134e-02,\n",
       "                      -2.9615e-02, -1.4377e-02, -9.7596e-03, -3.2951e-02, -3.7914e-02,\n",
       "                       0.0000e+00, -2.4159e-02, -3.3968e-02, -3.1370e-03,  3.3796e-04,\n",
       "                      -2.4404e-02, -5.5859e-04, -1.7868e-02, -3.7196e-02, -3.8024e-02,\n",
       "                      -5.0095e-02, -2.7180e-02, -2.2871e-02, -4.6469e-02, -3.7949e-02,\n",
       "                      -4.3230e-02, -5.0438e-02,  1.8160e-04, -5.4387e-03, -2.5852e-02,\n",
       "                      -1.2843e-04, -3.1939e-02, -8.5912e-04, -5.1436e-03, -3.9546e-02,\n",
       "                      -3.2128e-04, -1.2430e-02, -1.5247e-02, -4.0278e-02, -2.5006e-03,\n",
       "                      -2.2964e-02, -2.2642e-02, -3.4804e-02, -3.0416e-04, -8.3519e-03,\n",
       "                      -3.1385e-02, -5.1030e-02, -6.2829e-03, -1.5943e-02, -1.2673e-03,\n",
       "                      -3.9129e-02, -1.0743e-06, -2.0177e-02, -4.0531e-02, -8.4454e-03,\n",
       "                      -4.5046e-02, -1.9194e-02,  0.0000e+00, -4.4244e-02, -1.6408e-02,\n",
       "                      -6.3906e-04, -8.6082e-03, -4.9811e-03, -5.9483e-03, -2.3492e-02,\n",
       "                      -6.3553e-04, -7.5094e-03, -1.0811e-02, -2.4980e-02, -3.2059e-02,\n",
       "                      -4.6467e-02,  3.2722e-04, -3.9956e-02, -1.4530e-02, -5.2532e-04,\n",
       "                      -8.6514e-05, -4.0933e-02, -2.5880e-02, -4.5235e-02, -2.7011e-02,\n",
       "                      -7.1151e-03, -3.5048e-02, -3.3855e-02, -2.8071e-02, -4.0055e-02,\n",
       "                      -4.6789e-02, -3.4104e-03, -5.4335e-02, -1.7781e-02, -6.2329e-04,\n",
       "                       0.0000e+00, -4.8046e-03, -4.5206e-03, -1.5969e-02, -1.7271e-02,\n",
       "                      -1.2086e-02, -8.5655e-03, -3.3523e-03, -3.0130e-02, -3.9527e-03,\n",
       "                      -1.4417e-02, -1.2243e-02, -1.8613e-02, -1.8001e-02, -1.5774e-02,\n",
       "                      -2.9528e-02, -2.9235e-02, -4.9332e-02, -3.3550e-02, -1.8057e-02,\n",
       "                       0.0000e+00,  0.0000e+00, -3.4637e-02, -4.5148e-02, -4.6452e-03,\n",
       "                       0.0000e+00, -1.5443e-02, -5.9367e-02, -7.7832e-03, -6.1822e-04,\n",
       "                      -1.7710e-02, -5.0692e-03, -2.5828e-02, -4.0812e-02, -7.7939e-03,\n",
       "                      -2.0093e-02, -3.8813e-02, -2.8503e-02,  4.0667e-05, -3.7470e-02,\n",
       "                       0.0000e+00, -2.0964e-02, -9.5823e-03, -1.9551e-02, -2.1396e-02,\n",
       "                      -3.5358e-02, -4.6809e-02, -4.5624e-02, -4.1537e-02, -5.3081e-02,\n",
       "                      -1.6494e-02,  0.0000e+00, -1.7619e-02, -3.4500e-02, -3.5491e-02,\n",
       "                      -4.8017e-03, -2.0678e-02,  0.0000e+00,  9.7468e-05, -3.5501e-02,\n",
       "                      -3.7901e-02, -4.5985e-03,  5.0537e-04, -4.7134e-03, -5.6515e-03,\n",
       "                      -2.2190e-02, -1.2122e-02, -9.5936e-04, -4.1865e-02, -2.1591e-03,\n",
       "                       0.0000e+00, -1.2555e-02, -7.0408e-03,  1.4482e-04, -1.1230e-02,\n",
       "                      -6.9437e-03, -5.4775e-02,  6.5797e-05, -8.8814e-03, -1.6835e-03,\n",
       "                      -8.3802e-03, -5.0765e-03, -2.0021e-02, -3.0407e-02,  1.4420e-04,\n",
       "                      -3.7777e-02, -8.0691e-03, -1.1824e-02, -9.1138e-03, -1.2691e-02,\n",
       "                      -1.8940e-02, -1.3660e-03, -2.3303e-04,  0.0000e+00, -1.2948e-02,\n",
       "                      -4.6227e-02, -3.6291e-02, -9.1274e-04, -5.3176e-02,  0.0000e+00,\n",
       "                      -1.3769e-02, -1.8794e-03, -2.9021e-02, -2.0336e-02, -4.8432e-02,\n",
       "                      -6.3367e-02, -4.9302e-02, -4.5510e-02, -3.2699e-02, -2.5389e-02,\n",
       "                      -1.9299e-02, -6.3449e-03, -9.0497e-03, -1.6163e-02, -1.5372e-02,\n",
       "                      -4.4187e-02, -3.4948e-02, -2.7406e-02, -2.8457e-02,  0.0000e+00,\n",
       "                      -2.3777e-03, -1.9122e-02,  2.5236e-03, -3.4187e-03, -2.1909e-04,\n",
       "                      -5.2516e-03, -2.1057e-02, -8.0126e-03, -4.1050e-02, -4.7197e-02,\n",
       "                      -5.5848e-02, -5.0705e-03, -3.7658e-02, -1.6576e-02, -2.0456e-03,\n",
       "                      -5.5206e-03, -3.2813e-03, -5.5778e-02, -2.3425e-02, -1.7590e-02,\n",
       "                      -9.4241e-03, -2.4510e-02, -4.4484e-02,  6.1750e-04, -9.9285e-03,\n",
       "                      -4.8598e-02, -2.9045e-02,  0.0000e+00, -1.5957e-04, -1.2421e-02,\n",
       "                      -5.2518e-03, -4.8227e-02,  0.0000e+00, -1.5269e-02,  0.0000e+00,\n",
       "                       0.0000e+00, -3.8809e-02, -2.0721e-02,  0.0000e+00, -5.5945e-03,\n",
       "                      -1.3532e-02, -1.8252e-02, -1.9178e-02, -1.6000e-02,  0.0000e+00,\n",
       "                      -1.3328e-02, -2.8901e-02, -1.4678e-02, -2.7337e-03, -3.4264e-02,\n",
       "                      -3.1815e-02, -4.6471e-02, -2.5252e-02, -1.9078e-02, -1.9603e-03,\n",
       "                      -7.1150e-03, -1.6017e-03,  0.0000e+00,  9.0616e-04, -5.5457e-02,\n",
       "                      -2.0911e-02, -2.1370e-02, -5.0882e-02, -2.1722e-02, -3.7872e-02,\n",
       "                      -3.3929e-03, -1.0810e-03, -2.8524e-03, -2.0364e-03, -3.7568e-02,\n",
       "                      -1.9576e-02, -5.1145e-03, -2.4207e-02, -4.7292e-02,  0.0000e+00,\n",
       "                      -1.4744e-02, -5.1168e-03, -1.4557e-02, -2.0756e-02, -3.8114e-02,\n",
       "                      -1.9431e-02,  4.5544e-03, -5.0732e-02, -2.6811e-02, -1.6201e-02,\n",
       "                      -2.7740e-02, -3.9679e-03, -8.3822e-03, -8.6968e-03, -8.4052e-03,\n",
       "                      -1.5770e-02, -1.8554e-02,  1.2053e-04,  0.0000e+00, -2.0604e-02,\n",
       "                       6.8832e-04, -3.1862e-02, -1.1575e-03, -5.3199e-02, -1.2343e-03,\n",
       "                       0.0000e+00, -3.3783e-02,  0.0000e+00, -1.0666e-02, -1.8411e-02,\n",
       "                      -3.9930e-03, -2.1056e-02, -2.8383e-02, -5.4139e-02, -3.4478e-02,\n",
       "                      -1.3603e-02, -2.1952e-02, -1.5493e-02, -8.1594e-04, -1.7049e-02,\n",
       "                      -4.6443e-02, -6.3606e-03, -4.9099e-02, -1.9404e-02, -3.7188e-02,\n",
       "                      -1.3263e-02, -3.6528e-02, -1.1627e-02, -2.3976e-03, -1.5361e-02,\n",
       "                      -4.7892e-02, -2.8502e-02])),\n",
       "             ('linear_relu_stack.4.weight',\n",
       "              tensor([[ 0.0218,  0.0273,  0.0294,  ..., -0.0157, -0.0434,  0.0133],\n",
       "                      [ 0.0343,  0.0232, -0.0398,  ...,  0.0402, -0.0041, -0.0104],\n",
       "                      [-0.0092,  0.0124, -0.0093,  ...,  0.0233, -0.0049, -0.0409],\n",
       "                      ...,\n",
       "                      [-0.0193, -0.0433,  0.0105,  ..., -0.0387, -0.0011,  0.0201],\n",
       "                      [ 0.0033,  0.0127, -0.0452,  ..., -0.0180,  0.0219,  0.0201],\n",
       "                      [-0.0231, -0.0193, -0.0428,  ...,  0.0035, -0.0031,  0.0087]])),\n",
       "             ('linear_relu_stack.4.bias',\n",
       "              tensor([-4.2977e-02,  4.4222e-02,  1.5683e-03,  3.5712e-02,  2.5698e-02,\n",
       "                      -2.6925e-02,  5.8727e-03,  4.0629e-02, -2.8088e-02,  4.0386e-02,\n",
       "                      -1.2070e-02, -9.4527e-03, -4.0534e-02,  1.1540e-02,  4.4116e-02,\n",
       "                      -2.8910e-02, -1.7300e-02,  2.9801e-02,  4.5070e-02,  3.8372e-02,\n",
       "                       1.4519e-02,  1.2684e-02, -9.6971e-04,  3.4626e-02,  2.2120e-02,\n",
       "                      -3.1273e-02,  3.2834e-02, -1.0493e-02, -2.1973e-02,  7.5909e-03,\n",
       "                       9.5809e-03,  1.6884e-02,  1.4216e-02,  3.9134e-02, -2.3866e-02,\n",
       "                      -3.0438e-02,  1.0152e-02,  5.6496e-03, -1.0685e-02,  1.9281e-02,\n",
       "                       2.0397e-02,  3.6724e-02,  4.9676e-03, -4.2339e-02,  1.7428e-02,\n",
       "                      -3.4649e-03, -4.6180e-02, -4.1672e-02,  1.4351e-02, -2.9503e-02,\n",
       "                       1.1371e-02,  1.7899e-02,  3.5698e-03, -3.9672e-02, -4.9805e-03,\n",
       "                       3.3704e-02,  1.5467e-02,  1.1936e-02,  1.0526e-02, -2.6270e-02,\n",
       "                      -1.2689e-02, -1.3213e-02,  1.8520e-02, -1.6993e-02,  1.1085e-02,\n",
       "                      -1.1937e-02, -2.8819e-02, -3.6983e-02, -2.4686e-02, -3.1398e-02,\n",
       "                       9.4901e-03,  4.3892e-02,  1.1129e-02, -3.4195e-02,  1.0441e-02,\n",
       "                      -3.5598e-02,  2.9610e-02,  9.6352e-05,  3.2638e-02, -1.1450e-02,\n",
       "                       1.0317e-03,  6.2485e-04,  2.6554e-02,  1.9047e-02, -2.5816e-02,\n",
       "                      -2.2326e-02, -3.4248e-02,  3.3992e-02, -4.5276e-02, -6.6364e-03,\n",
       "                       3.8312e-02,  1.7861e-02, -4.3996e-02, -2.0958e-02, -3.7081e-03,\n",
       "                      -1.2536e-02,  9.9989e-03,  3.2878e-02, -2.2386e-02, -3.5905e-03,\n",
       "                      -3.9805e-02, -3.3822e-02, -2.2561e-02, -1.1768e-02, -1.8890e-02,\n",
       "                      -2.3649e-02, -1.7535e-02,  3.1219e-02,  1.4259e-02, -2.8486e-02,\n",
       "                      -2.0946e-02,  3.4624e-02, -6.5627e-03,  2.0977e-02, -7.2591e-03,\n",
       "                      -1.4643e-02,  3.9478e-02,  6.1752e-03,  3.0908e-02,  3.1141e-02,\n",
       "                      -1.4109e-02,  1.1513e-02,  2.8362e-02, -1.6257e-02, -1.7954e-02,\n",
       "                      -3.3099e-02,  1.5399e-02, -1.4242e-02, -1.5641e-02,  3.9627e-02,\n",
       "                      -2.3819e-03,  4.0473e-02,  2.3052e-02, -1.6092e-02, -1.1239e-02,\n",
       "                      -2.6836e-02, -3.9679e-02,  2.6093e-02,  2.1293e-02, -2.8941e-02,\n",
       "                       8.4742e-04, -4.0445e-02,  4.3438e-02,  4.0173e-02, -1.6199e-02,\n",
       "                       3.7299e-02,  5.5565e-03,  1.1966e-02,  3.1963e-02,  4.2331e-02,\n",
       "                       7.5953e-03, -3.6617e-02, -1.2996e-02,  1.4894e-02,  2.7263e-02,\n",
       "                      -3.3282e-02, -4.7516e-02, -3.3981e-02,  2.6933e-02,  1.8732e-02,\n",
       "                       5.4753e-03, -3.2434e-02, -3.7374e-02, -4.1147e-02,  4.7582e-03,\n",
       "                       2.7350e-02, -3.0465e-02,  3.3410e-02,  3.0785e-02, -1.0621e-02,\n",
       "                      -3.7572e-02,  3.1115e-02, -1.4032e-02, -2.1441e-02, -7.5466e-03,\n",
       "                      -2.2856e-03,  2.2020e-02, -3.5066e-02,  2.0341e-02,  2.9949e-02,\n",
       "                       1.4195e-02,  1.2786e-02, -1.1755e-02,  3.3627e-02,  4.5647e-02,\n",
       "                       2.1470e-02, -1.3785e-02, -6.9657e-03, -4.0166e-02, -1.7420e-02,\n",
       "                      -1.8482e-02,  1.4487e-02,  3.0006e-02,  2.2685e-02,  4.3696e-03,\n",
       "                       2.2576e-03, -3.4128e-02, -5.1615e-03,  2.9735e-03,  4.1646e-02,\n",
       "                      -2.5595e-02, -2.1666e-02,  2.1792e-02, -1.3336e-02,  1.0798e-02,\n",
       "                       4.7762e-02, -2.0394e-02, -3.0702e-02,  6.9116e-04,  2.2440e-02,\n",
       "                       2.0155e-02,  1.0167e-02, -2.0101e-02,  2.7074e-02, -3.5163e-02,\n",
       "                       2.3682e-02, -4.5399e-02,  7.4449e-03, -2.7149e-02,  4.1489e-02,\n",
       "                      -2.8116e-02,  9.5485e-03,  1.4295e-02, -9.3893e-03,  2.1092e-04,\n",
       "                       3.8366e-02, -1.1666e-03,  3.0855e-02, -3.5175e-02,  5.4319e-03,\n",
       "                      -7.6279e-03,  1.1969e-02,  2.4259e-02,  1.1040e-02,  4.5878e-02,\n",
       "                       1.7850e-02, -1.9112e-02,  4.5668e-03, -2.9359e-02,  1.8195e-02,\n",
       "                       1.5190e-02,  3.6554e-02, -4.3166e-02,  1.7636e-02,  2.6640e-02,\n",
       "                      -2.8421e-02,  2.8911e-02,  3.8935e-02, -3.7300e-02, -6.9011e-03,\n",
       "                       8.0841e-04, -5.8533e-03, -8.8990e-03, -2.6395e-02, -3.0128e-02,\n",
       "                       3.6404e-02])),\n",
       "             ('linear_relu_stack.5.weight',\n",
       "              tensor([0.9974, 0.9954, 1.0498, 0.9995, 1.0229, 0.9937, 0.9978, 0.9962, 0.9964,\n",
       "                      1.0084, 0.9965, 0.9915, 0.9992, 1.0181, 0.9962, 1.0073, 0.9975, 0.9962,\n",
       "                      0.9946, 0.9933, 0.9968, 0.9943, 0.9949, 1.0062, 0.9929, 0.9955, 0.9955,\n",
       "                      0.9834, 1.0048, 1.0023, 0.9912, 0.9935, 0.9936, 0.9976, 0.9957, 0.9956,\n",
       "                      0.9893, 1.0054, 0.9964, 0.9939, 0.9950, 1.0023, 0.9987, 1.0001, 0.9993,\n",
       "                      1.0063, 1.0445, 0.9945, 0.9960, 0.9878, 1.0167, 0.9933, 1.0159, 1.0050,\n",
       "                      0.9980, 0.9966, 0.9958, 1.0172, 0.9965, 0.9945, 0.9964, 0.9914, 1.0096,\n",
       "                      0.9972, 1.0079, 0.9949, 0.9971, 1.0077, 0.9838, 0.9960, 1.0254, 0.9994,\n",
       "                      1.0000, 0.9964, 0.9831, 0.9979, 0.9917, 0.9878, 1.0030, 0.9898, 1.0025,\n",
       "                      0.9969, 0.9992, 0.9929, 0.9933, 0.9946, 0.9918, 0.9959, 0.9962, 0.9979,\n",
       "                      0.9914, 0.9973, 0.9984, 0.9979, 0.9862, 1.0125, 0.9901, 1.0263, 0.9949,\n",
       "                      0.9831, 0.9973, 0.9932, 0.9826, 0.9949, 0.9979, 0.9961, 0.9931, 0.9952,\n",
       "                      0.9820, 0.9957, 0.9985, 0.9949, 1.0320, 0.9949, 1.0133, 0.9936, 0.9949,\n",
       "                      1.0126, 0.9988, 1.0120, 1.0329, 0.9947, 0.9918, 1.0098, 0.9945, 0.9965,\n",
       "                      0.9954, 0.9958, 0.9956, 0.9940, 1.0307, 0.9952, 1.0007, 0.9952, 0.9933,\n",
       "                      1.0060, 0.9939, 0.9960, 0.9950, 1.0256, 1.0231, 0.9971, 0.9985, 0.9877,\n",
       "                      0.9960, 1.0160, 0.9941, 0.9969, 1.0002, 0.9967, 0.9962, 0.9969, 0.9986,\n",
       "                      0.9947, 0.9977, 0.9977, 1.0240, 0.9920, 0.9965, 1.0009, 0.9966, 1.0282,\n",
       "                      0.9959, 0.9956, 0.9957, 1.0023, 1.0006, 0.9918, 1.0092, 0.9929, 0.9956,\n",
       "                      0.9952, 1.0401, 1.0108, 1.0433, 0.9967, 0.9963, 1.0005, 0.9916, 0.9938,\n",
       "                      0.9982, 0.9910, 1.0203, 0.9946, 0.9993, 1.0012, 0.9973, 1.0030, 1.0023,\n",
       "                      1.0040, 0.9975, 1.0242, 1.0161, 0.9964, 0.9940, 0.9947, 0.9923, 1.0060,\n",
       "                      0.9988, 0.9965, 0.9920, 1.0024, 0.9961, 0.9938, 0.9993, 0.9830, 1.0093,\n",
       "                      0.9982, 0.9979, 0.9975, 1.0028, 0.9969, 0.9960, 0.9897, 0.9961, 0.9975,\n",
       "                      1.0308, 1.0056, 1.0013, 0.9945, 0.9928, 0.9968, 1.0036, 1.0080, 0.9917,\n",
       "                      0.9933, 0.9893, 1.0275, 0.9966, 1.0040, 0.9897, 0.9985, 0.9969, 0.9929,\n",
       "                      0.9911, 1.0023, 1.0286, 0.9923, 0.9943, 0.9873, 1.0182, 0.9961, 0.9978,\n",
       "                      1.0053, 0.9875, 1.0014, 0.9977, 0.9945, 0.9884, 0.9992, 0.9967, 1.0248,\n",
       "                      1.0008, 0.9982, 0.9951, 0.9922])),\n",
       "             ('linear_relu_stack.5.bias',\n",
       "              tensor([-5.2083e-03, -9.2482e-03, -2.7558e-03, -3.9014e-03, -5.6147e-03,\n",
       "                      -6.4387e-03, -7.1792e-03, -5.1465e-03, -3.9521e-03, -1.1336e-02,\n",
       "                      -4.5292e-03, -6.1573e-03, -2.8923e-03, -1.1248e-03, -3.6044e-03,\n",
       "                      -2.0026e-03, -2.4054e-03, -5.8547e-03, -5.2201e-03, -6.0671e-03,\n",
       "                      -5.4008e-03, -6.2539e-03, -5.1612e-03, -5.7843e-03, -8.0909e-03,\n",
       "                      -2.2157e-03, -4.6675e-03, -1.5254e-02, -3.5288e-03, -1.4832e-02,\n",
       "                      -1.1400e-02, -1.2614e-02, -4.7973e-03, -4.9082e-03, -3.4154e-03,\n",
       "                      -6.0648e-03, -1.3848e-02, -2.0826e-03, -4.9236e-03, -6.1467e-03,\n",
       "                      -5.0084e-03, -1.7882e-03, -2.6204e-03, -1.2936e-02, -4.2544e-03,\n",
       "                      -5.8584e-03, -3.2861e-03, -5.8372e-03, -4.7600e-03, -8.4318e-03,\n",
       "                      -1.4638e-03, -5.6083e-03,  9.0741e-04, -4.3899e-03, -3.4423e-03,\n",
       "                      -6.7988e-03, -2.9870e-03, -8.5787e-03, -3.6340e-03, -7.7867e-03,\n",
       "                      -4.6415e-03, -1.3929e-02, -4.6170e-03, -4.9345e-03, -3.7603e-03,\n",
       "                      -1.0846e-02, -4.9349e-03, -7.1771e-03, -1.2092e-02, -5.4959e-03,\n",
       "                      -2.3155e-03, -1.7610e-03, -2.4112e-03, -4.2199e-03, -1.1196e-02,\n",
       "                      -2.5083e-03, -7.6510e-03, -1.0429e-02, -1.0474e-02, -1.0189e-02,\n",
       "                      -9.5504e-03, -5.1573e-03, -3.0578e-03, -5.8013e-03, -9.5287e-03,\n",
       "                      -3.2670e-03, -9.8543e-03, -1.1804e-02, -6.7627e-03, -4.5761e-03,\n",
       "                      -7.5557e-03, -3.7388e-03, -4.7737e-03, -3.7330e-03, -9.5076e-03,\n",
       "                      -3.8735e-03, -8.0870e-03, -4.4530e-03, -7.3255e-03, -1.6799e-02,\n",
       "                      -4.4857e-03, -7.2977e-03, -1.0997e-02, -4.6288e-03, -2.7484e-03,\n",
       "                      -2.1282e-03, -8.2614e-03, -2.7663e-03, -1.2819e-02, -2.1243e-03,\n",
       "                      -4.2695e-03, -5.4555e-03, -1.6663e-03, -9.9635e-03, -6.8828e-03,\n",
       "                      -7.7866e-03, -4.0365e-03, -3.1495e-03, -2.9633e-03, -1.1587e-02,\n",
       "                      -1.4183e-02, -5.4050e-03, -6.5128e-03, -2.3238e-03, -1.1516e-02,\n",
       "                      -4.0968e-03, -5.9443e-03, -6.4902e-03, -6.0355e-03, -3.4430e-03,\n",
       "                      -6.4645e-03, -5.6047e-03, -4.1083e-03, -7.9848e-03, -4.8601e-03,\n",
       "                      -9.8536e-03, -8.1036e-03, -5.7876e-03, -8.7204e-03, -9.6945e-03,\n",
       "                      -1.1822e-02, -1.2322e-02, -4.8161e-03, -1.2709e-02, -7.0304e-03,\n",
       "                      -1.5323e-03, -6.9061e-03, -2.6570e-03, -2.1850e-03, -3.9129e-03,\n",
       "                      -5.3739e-03, -3.0867e-03, -2.7662e-03, -1.1831e-02, -6.2674e-03,\n",
       "                      -2.5274e-03, -1.2208e-03, -5.9455e-03, -3.0027e-03, -3.8995e-03,\n",
       "                      -6.9213e-03, -2.3965e-03, -1.0561e-03, -2.7887e-03, -5.8922e-03,\n",
       "                      -4.0827e-03, -8.2775e-03, -8.4726e-03, -1.0692e-02, -1.4615e-02,\n",
       "                      -6.8140e-03, -4.5962e-03, -8.2195e-03, -3.6020e-03, -9.5272e-03,\n",
       "                      -4.8975e-03, -1.0141e-02, -2.0301e-03, -8.5242e-03, -2.5959e-03,\n",
       "                      -1.1660e-02, -7.9248e-03, -8.7295e-03, -6.8259e-03, -2.1397e-03,\n",
       "                      -4.5194e-03, -4.0912e-03, -5.9541e-03, -3.3766e-03, -2.7468e-03,\n",
       "                      -4.5650e-03, -4.4075e-03, -4.7974e-03, -1.5686e-02, -7.8759e-03,\n",
       "                      -4.3394e-03, -7.6005e-03, -4.2872e-03, -8.7515e-03, -7.3500e-03,\n",
       "                      -5.6468e-03, -2.1219e-03, -2.5811e-03, -4.3715e-03, -9.0799e-03,\n",
       "                      -1.2281e-02, -5.1740e-03, -6.2924e-03, -5.2778e-03, -4.9312e-03,\n",
       "                      -4.5806e-03, -3.3966e-03, -4.9109e-03, -9.6775e-03, -4.5611e-03,\n",
       "                      -4.2630e-03, -2.2401e-05, -3.7531e-03, -6.0952e-03, -6.1757e-03,\n",
       "                      -6.4429e-03, -6.1013e-03, -4.5532e-03, -7.5385e-03, -9.7033e-03,\n",
       "                      -8.0179e-03, -1.3700e-02, -7.6221e-04, -3.3348e-03, -5.4566e-03,\n",
       "                      -1.2148e-02, -2.9392e-03, -4.1200e-03, -6.8189e-03, -7.2736e-03,\n",
       "                      -5.6793e-03, -8.0492e-03, -6.3451e-03, -5.5343e-03, -1.3226e-02,\n",
       "                      -1.3181e-02, -4.9709e-03, -7.8796e-03, -5.4786e-03, -1.3554e-02,\n",
       "                      -2.3953e-03, -1.9759e-03, -6.0792e-03, -9.1617e-03, -9.4061e-03,\n",
       "                      -6.5541e-03, -2.6542e-03, -2.9776e-03, -3.7696e-03, -3.2151e-03,\n",
       "                      -9.6673e-03])),\n",
       "             ('linear_relu_stack.8.weight',\n",
       "              tensor([[ 0.0297,  0.0617, -0.0038,  ...,  0.0265, -0.0415,  0.0670],\n",
       "                      [-0.0485,  0.0556, -0.0241,  ...,  0.0319,  0.0062,  0.0625],\n",
       "                      [-0.0195, -0.0464,  0.0098,  ...,  0.0026, -0.0615, -0.0271],\n",
       "                      ...,\n",
       "                      [ 0.0166, -0.0397, -0.0731,  ...,  0.0604, -0.0664, -0.0076],\n",
       "                      [ 0.0036,  0.0050,  0.0244,  ...,  0.0158,  0.0234, -0.0421],\n",
       "                      [-0.0007, -0.0217, -0.0347,  ..., -0.0030, -0.0268, -0.0145]])),\n",
       "             ('linear_relu_stack.8.bias',\n",
       "              tensor([ 0.0716, -0.0077, -0.0181,  0.0064, -0.0435, -0.0516, -0.0573,  0.0606,\n",
       "                      -0.0656,  0.0526,  0.0304,  0.0110, -0.0232,  0.0313,  0.0319,  0.0255,\n",
       "                       0.0534,  0.0016,  0.0176,  0.0449, -0.0781, -0.0102,  0.0527, -0.0644,\n",
       "                      -0.0159,  0.0694, -0.0235,  0.0565, -0.0240, -0.0010,  0.0125,  0.0047,\n",
       "                       0.0478,  0.0232,  0.0570,  0.0027, -0.0258, -0.0382, -0.0321, -0.0050,\n",
       "                       0.0122,  0.0582,  0.0265, -0.0548,  0.0174, -0.0373, -0.0027, -0.0356,\n",
       "                      -0.0003, -0.0637,  0.0662,  0.0693, -0.0143, -0.0603,  0.0194,  0.0450,\n",
       "                      -0.0515,  0.0026,  0.0396, -0.0324,  0.0074, -0.0241,  0.0734,  0.0568])),\n",
       "             ('linear_relu_stack.9.weight',\n",
       "              tensor([0.9615, 0.9948, 1.0018, 1.0045, 1.0000, 0.9889, 1.0061, 0.9968, 1.0009,\n",
       "                      0.9606, 0.9975, 1.0221, 0.9927, 0.9911, 0.9133, 1.0200, 0.9765, 0.9926,\n",
       "                      0.9569, 0.9546, 0.9989, 0.9924, 0.9674, 1.0035, 0.9969, 0.8545, 0.9968,\n",
       "                      0.9957, 0.7878, 0.9983, 1.0002, 0.9976, 0.9868, 1.0189, 0.9490, 0.9946,\n",
       "                      1.0016, 1.0005, 0.9993, 1.0014, 0.9612, 0.9902, 1.0059, 1.0011, 0.9835,\n",
       "                      1.0045, 0.9456, 0.9993, 0.9736, 0.9970, 0.8307, 0.9896, 0.9975, 1.0020,\n",
       "                      0.9929, 0.8832, 0.9922, 1.0026, 0.9925, 1.0054, 0.9882, 1.0011, 0.9743,\n",
       "                      1.0007])),\n",
       "             ('linear_relu_stack.9.bias',\n",
       "              tensor([-3.6874e-02, -4.7618e-03,  1.2525e-02, -2.8875e-03,  1.1451e-02,\n",
       "                      -1.4695e-02,  3.2763e-03,  4.8547e-03, -1.3482e-03, -3.6958e-02,\n",
       "                      -5.2686e-04,  2.3398e-02, -1.4795e-02, -1.5435e-02, -5.6597e-02,\n",
       "                       2.3496e-02, -4.0321e-02, -9.7076e-03, -4.6761e-02, -4.5119e-02,\n",
       "                      -2.6066e-03, -9.4404e-03, -4.7911e-02,  4.1685e-03, -4.2330e-03,\n",
       "                      -7.1756e-02, -4.8572e-03, -6.6152e-03, -8.9086e-02, -2.7745e-03,\n",
       "                       1.8833e-03,  5.5319e-04, -2.3009e-02,  8.8017e-03, -4.3178e-02,\n",
       "                       3.8434e-03,  4.8574e-03,  6.4306e-03,  1.1447e-02, -7.3681e-03,\n",
       "                      -3.6405e-02, -1.2719e-02,  1.7840e-02,  6.9448e-03, -3.1439e-02,\n",
       "                       2.7156e-03, -4.4031e-02, -1.1314e-03, -2.9760e-02, -6.5000e-03,\n",
       "                      -8.1808e-02,  2.1403e-03,  4.3535e-05,  1.9479e-03, -1.3964e-02,\n",
       "                      -6.5839e-02, -5.8333e-03, -7.9226e-03, -4.0928e-03,  6.3653e-03,\n",
       "                      -1.3882e-02,  1.2946e-02, -2.8968e-02,  1.0217e-02])),\n",
       "             ('linear_relu_stack.12.weight',\n",
       "              tensor([[-0.0384,  0.0201,  0.1576, -0.1455,  0.1446, -0.0749, -0.1345,  0.1177,\n",
       "                        0.1391,  0.0333,  0.0912,  0.2350, -0.0649, -0.0694,  0.0160,  0.2334,\n",
       "                       -0.0534,  0.1131,  0.0233,  0.0086,  0.0479,  0.0827, -0.0493, -0.1361,\n",
       "                       -0.1294,  0.0123, -0.1282,  0.0186, -0.0090, -0.1054,  0.0322, -0.1029,\n",
       "                       -0.0936,  0.2351, -0.0150, -0.0391,  0.1481,  0.1259, -0.1352, -0.1120,\n",
       "                       -0.0212,  0.0611,  0.1894, -0.1412, -0.0788,  0.1524, -0.0078,  0.0342,\n",
       "                       -0.0634, -0.0497, -0.0088, -0.0615, -0.0220, -0.1464, -0.0813,  0.0124,\n",
       "                       -0.0904, -0.1310, -0.0516,  0.1746,  0.0662,  0.1426, -0.0136,  0.1293]])),\n",
       "             ('linear_relu_stack.12.bias', tensor([0.1243]))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.721875011920929, f1_score: 0.7081966996192932\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score\n",
    "\n",
    "est_model = MyModel2()\n",
    "best_model.load_state_dict(torch.load('best-model-parameters.pt'))\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = best_model(X_valid)\n",
    "\n",
    "# Convert pred to a float tensor\n",
    "pred = (pred > 0.5).to(torch.float)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = BinaryAccuracy()\n",
    "f1_score = BinaryF1Score()\n",
    "print(f\"Accuracy: {accuracy(pred, y_valid)}, f1_score: {f1_score(pred, y_valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**: My model achieved an accuracy of 72%, wich is not so good. Maybe we need more data or more comlexity model. Compared to ml algorithms for this dataset, my model gives almost the same results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
