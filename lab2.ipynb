{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7068f145-1394-45d8-8fe5-a4fdf4f9e1ec",
   "metadata": {},
   "source": [
    "# Backpropagation handmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d2bc8d1-abfa-467e-aec9-bf58ae3cb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build the class for math expressions\n",
    "# 2. Build some basic operations\n",
    "# 3. Build computation graph\n",
    "# 4. Build some activations\n",
    "# 5. Build backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fe5f0f2-904f-4ab1-ac87-74622c99f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by (and 80% copied from :)) micrograd / Andrej Karpathy\n",
    "# https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e08c21-2059-41c2-8c4d-90686d8f4ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f10e0756-975b-4e33-9ff5-ccaa92435596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2090da17-3cbe-4551-9104-73e02ae1f7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    def __init__(self, value: float, name: str) -> None:\n",
    "        self._value = value\n",
    "        self._name = name\n",
    "        self._grad = 0.0\n",
    "\n",
    "        self._graph = defaultdict(list)\n",
    "        self._graph[id(self)] = list()\n",
    "\n",
    "        self._params = defaultdict()\n",
    "        self._params[id(self)] = self\n",
    "\n",
    "        self._backward = lambda: None\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Parameter {self._name} = {self._value}; dL/d[{self._name}] = {self._grad}\"\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        result = Parameter(\n",
    "            self._value * other._value,\n",
    "            f'{self._name} * {other._name}'\n",
    "        )\n",
    "        def _backward():\n",
    "            self._grad += other._value * result._grad #dL / dself\n",
    "            other._grad += self._value * result._grad # dL / dother\n",
    "\n",
    "        result._backward = _backward\n",
    "\n",
    "        result._params.update(self._params)\n",
    "        result._params.update(other._params)\n",
    "        result._params[id(result)] = result\n",
    "\n",
    "        result._graph.update(self._graph)\n",
    "        result._graph.update(other._graph)\n",
    "        result._graph[id(result)].append(id(self))\n",
    "        result._graph[id(result)].append(id(other))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __add__(self, other) :\n",
    "        result = Parameter(\n",
    "            self._value + other._value,\n",
    "            f'[{self._name} + {other._name}]'\n",
    "        )\n",
    "\n",
    "        def _backward():\n",
    "            self._grad += 1.0 * result._grad  #dL / dself\n",
    "            other._grad += 1.0 * result._grad # dL / dother\n",
    "\n",
    "        result._backward = _backward\n",
    "        \n",
    "        result._params.update(self._params)\n",
    "        result._params.update(other._params)\n",
    "        result._params[id(result)] = result\n",
    "\n",
    "        result._graph.update(self._graph)\n",
    "        result._graph.update(other._graph)\n",
    "        result._graph[id(result)].append(id(self))\n",
    "        result._graph[id(result)].append(id(other))\n",
    "\n",
    "\n",
    "        return result\n",
    "\n",
    "    \n",
    "    def _topological_sort(self):\n",
    "        in_degree = {node: 0 for node in self._graph}\n",
    "        for node in self._graph:\n",
    "            for child in self._graph[node]:\n",
    "                in_degree[child] += 1\n",
    "\n",
    "        queue = deque([node for node in self._graph if in_degree[node] == 0])\n",
    "        sorted_nodes = []\n",
    "\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            sorted_nodes.append(node)\n",
    "            for child in self._graph[node]:\n",
    "                in_degree[child] -= 1\n",
    "                if in_degree[child] == 0:\n",
    "                    queue.append(child)\n",
    "\n",
    "        return sorted_nodes\n",
    "\n",
    "    def backward(self):\n",
    "        queue = self._topological_sort()\n",
    "        self._grad = 1\n",
    "        for i in queue:\n",
    "            self._params[i]._backward()\n",
    "        \n",
    "\n",
    "    def sigmoid(self) :\n",
    "        # f(x) = 1 / (1 + exp(self._value))\n",
    "        # f'(x) = f(x) * (1 - f(x))\n",
    "\n",
    "        val = 1.0 / (1.0 + math.exp(-self._value))\n",
    "\n",
    "        result = Parameter(\n",
    "            val,\n",
    "            f\"σ({self._name})\"\n",
    "        )\n",
    "\n",
    "        def _backward():\n",
    "            self._grad = result._grad * val * (1 - val)\n",
    "\n",
    "        result._backward = _backward\n",
    "\n",
    "        return result\n",
    "\n",
    "    def ReLU(self):\n",
    "        val = np.maximum(0,self._value)\n",
    "        result = Parameter(\n",
    "            val,\n",
    "            f\"σ({self._name})\"\n",
    "        )\n",
    "\n",
    "        result._params.update(self._params)\n",
    "        result._params[id(result)] = result\n",
    "        \n",
    "        result._graph.update(self._graph)\n",
    "        result._graph[id(result)].append(id(self))\n",
    "\n",
    "        def _backward():\n",
    "            self._grad = result._grad * (val > 0)\n",
    "\n",
    "        result._backward = _backward\n",
    "\n",
    "        return result\n",
    "\n",
    "    def SoftPlus(self):\n",
    "        #f(x) = ln(1+e^x)\n",
    "        #f'(x) = e^x/(1+e^x) =sigmoid(x)\n",
    "        val = np.log(1+np.exp(self._value))\n",
    "\n",
    "        result = Parameter(\n",
    "            val,\n",
    "            f\"σ({self._name})\"\n",
    "        )\n",
    "\n",
    "        result._params.update(self._params)\n",
    "        result._params[id(result)] = result\n",
    "        \n",
    "        result._graph.update(self._graph)\n",
    "        result._graph[id(result)].append(id(self))\n",
    "\n",
    "        def _backward():\n",
    "            self._grad = result._grad * (1.0 / (1.0 + math.exp(-self._value)))\n",
    "\n",
    "        result._backward = _backward\n",
    "\n",
    "        return result\n",
    "\n",
    "def sgd(parameters: list, learning_rate = 0.3): \n",
    "    for param in parameters:\n",
    "        param._value -= learning_rate * param._grad        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27fd73e5-da08-4969-9038-935b2d17f2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter a = 3.0; dL/d[a] = 0.0,\n",
       " Parameter b = 2.0; dL/d[b] = 0.0,\n",
       " Parameter c = 5.0; dL/d[c] = 0.0,\n",
       " Parameter d = 5.0; dL/d[d] = 0.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Parameter(3.0, 'a')\n",
    "b = Parameter(2.0, 'b')\n",
    "c = Parameter(5.0, 'c')\n",
    "d = Parameter(5.0, 'd')\n",
    "a,b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2f9a3a6-b195-46df-9697-52b0b61fe6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter a * b = 6.0; dL/d[a * b] = 5.0,\n",
       " Parameter [a * b + c] = 11.0; dL/d[[a * b + c]] = 5.0,\n",
       " Parameter [a * b + c] * d = 55.0; dL/d[[a * b + c] * d] = 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = a * b\n",
    "v = u + c\n",
    "L = v * d\n",
    "\n",
    "L.backward()\n",
    "u,v,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "254b7d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter x = 4.0; dL/d[x] = 14.0,\n",
       " Parameter y = 5.0; dL/d[y] = 5.0,\n",
       " Parameter [[x + y] + [[x + y] * x + w]] = 48.0; dL/d[[[x + y] + [[x + y] * x + w]]] = 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Parameter(4.0, 'x')\n",
    "y = Parameter(5.0, 'y')\n",
    "w = Parameter(3.0, 'w')\n",
    "\n",
    "u1 = x + y\n",
    "u2 = u1 * x\n",
    "u3 = u2 + w\n",
    "L = u1 + u3\n",
    "L.backward()\n",
    "x,y,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6fa6cf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter x = 3; dL/d[x] = 3375.0,\n",
       " Parameter y = 5; dL/d[y] = 2025.0,\n",
       " Parameter y * x * x * y * x * y = 3375; dL/d[y * x * x * y * x * y] = 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Parameter(3,\"x\")\n",
    "y = Parameter(5,\"y\")\n",
    "L = y*x*x*y*x*y\n",
    "L.ReLU()\n",
    "L.backward()\n",
    "x,y,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31be2807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3375.), tensor(2025.), tensor(3375., grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = torch.tensor(5.0, requires_grad=True)\n",
    "\n",
    "L = y*x*x*y*x*y\n",
    "L.relu()\n",
    "L.backward()\n",
    "x.grad,y.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
